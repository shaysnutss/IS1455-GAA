[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS1455-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications.\nThis is the course website of the IS415 mod that I am embarking on this semester. You will find my course materials here. Have fun:)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class-Ex02/In-class_Ex02.html",
    "title": "In-class exercise 2 : R for geospatial data science",
    "section": "",
    "text": "Hey friends! Let’s learn about a few package:"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#loading-packages",
    "href": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#loading-packages",
    "title": "In-class exercise 2 : R for geospatial data science",
    "section": "Loading packages",
    "text": "Loading packages\nThis is a very important step as we have to load the packages before we can use them.\n\npacman::p_load(sf, tmap, tidyverse,lubridate,arrow)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#importing-the-data",
    "href": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#importing-the-data",
    "title": "In-class exercise 2 : R for geospatial data science",
    "section": "Importing the data",
    "text": "Importing the data\n\nImporting Geospatial Data into R\nAs learnt in the previous page, we use st_read() function of the sf package to read in the data.\n\ndf &lt;- read_parquet(\"../../data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n\n\n\nConversion of data type\nHere we convert the int data type to date time data type. We are not using mutate, as we are over writing the data field in the file.\n\ndf$pingtimestamp &lt;-as_datetime(df$pingtimestamp)\n\n\n# get origin\norigin_df &lt;- df %&gt;% #use df\n  group_by(trj_id) %&gt;% #group according to trj_id\n  arrange(pingtimestamp) %&gt;% #sort according to timestamp asc (default)\n  filter(row_number()==1) %&gt;% #the first coordinate for every trip should be the origin\n  mutate(weekday = wday(pingtimestamp, label=TRUE, abbr=TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\neach trip will have multiple rows because every minute the new location one be sent to the server . so when we arrange it, the first row is the origin location.\n\n# get end\ndestination_df &lt;- df %&gt;% #use df\n  group_by(trj_id) %&gt;% #group according to trj_id\n  arrange(desc(pingtimestamp)) %&gt;% #sort according to timestamp asc (default)\n  filter(row_number()==1) %&gt;% #the first coordinate for every trip should be the origin\n  mutate(weekday = wday(pingtimestamp, label=TRUE, abbr=TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n# he writes in rds if he still wants to write in r\nwrite_rds(origin_df, \"../../data/rds/origin_df.rds\")\nwrite_rds(destination_df,\n          \"../../data/rds/destination_df.rds\")\n\n#import data\n\norigin_df &lt;- read_rds(\"../../data/rds/origin_df.rds\")\ndestination_df &lt;- read_rds(\"../../data/rds/destination_df.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "",
    "text": "Hello! In this page, i will be describing how i performed data wrangling - which is basically cleaning and transforming raw data into a more structured and usable format or later analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Installing and loading R packages",
    "text": "Installing and loading R packages\nIn this section, I will install and load ‘tidyverse’ and ‘sf’ packages.\n\nWhat are the sf and tidyverse packages?\nLet me give you a break down.\n\nTidyverse Package\nImagine you have a pile of dirty data that you need to handle. The Tidyverse package helps you handle your data. It actually has a bunch of packages within it to help handle data. It can do the following:\n\nreadr - reading and writing data into or out of a spreadsheet\ntidyr - organizing and tidying up your data\nggplot2 - visualizing your data\ndpylr - mainpulating your data, like doing some basic math to it.\n\n\n\nSF Package\nSF package provides us with tools to work with data related to maps and geospatial data. It can\n\nRead and write geospatial data from and into files.\nManipulate data - like cut out a specific area on a map\nVisualize data\n\nNow let’s load the packages into our environment.\n\n# Loads the p_load function on pacman which checks if packages are available, and then loads them into the R environment.\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\n\nImporting the geospatial data in shapefile format\nHere we import the geospatial data which is in shapefile format as a a polygon feature data frame.\n\nWhat is a shapefile and what is a polygon feature data frame?\n\nShapefile\nShapefile format stores geographic location and attribute information of geographic features.\n\n\nPolygon feature data frame\nThink of polygons as shapes that represent areas on a map.\nData frames store details about the polygons (think area) on tables.\nSo polygon feature data frames store data about areas on the map.\n\n#st_read is a function from the SF package which helps with the handling of data. We read the data into the variable mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n layer  = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\nImporting polyline feature data in shapefile form\n\nWhat is a polyline feature data frame?\nA polyline is made up of connected points and can represent things such as roads, rivers, or hiking trails.\nFeature Data Frames store information about these lines, like what is the name of the road, how long is it, what’s its surface?\nA polyline feature data frame stores information on lines that represent routes or rivers on a map.\nNow let’s import the polyline feature data\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\nImporting GIS data in kml format\n\nWhat is a GIS data and kml format ?\n\nkml format\nIt is keyhole markup language used to describe places and features on a digital map. You can define shapes like drawing a line to show a hiking trail or a polygon to show a lake. You can also attach information to places.\n\n\nGIS data\nA map has information like shapes, paths, data and locations. GIS data is when all this information is organized in a computer friendly way. People use these data to analyse the environment, plan cities and much more.\nNow let’s import GIS data in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Checking out the contents of a simple feature data frame",
    "text": "Checking out the contents of a simple feature data frame\n\nst_geometry\nShapes represent areas on a map. The data.frame in the package sf contains a column, and that column contains a list of those shapes in the specific class called ‘sfc’.\nLet’s execute this command\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThis commands tells you a few things:\n\nThe types of shapes you’re dealing with. Multipolygon means its an area with multiple connected lines.\nThe bounding box/ range of coordinates that coer the same\nAlso the first 5 shapes in the column of the data frame\n\n\n\nglimpse\nLet’s execute this command\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThis command gives you a glimpse into the dataset.\nit tells you the following things:\n\nthe number of rows\nthe number of columns\nwhat columns are there\ndata type of each column\nfirst few values of each column\n\n\n\nhead()\nLet’s execute this command\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThis provides you with complete information (columns and the number of values u want)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Plotting Data",
    "text": "Plotting Data\nNow, let’s plot the data in our mpsz as a visualization. We use the plot() function for it.\nThis provides the entire visualization.\n\nplot(mpsz)\n\n\n\n\nIf you want to just plot the different shapes in the map, we can do this:\n\nplot(st_geometry(mpsz))\n\n\n\n\nIf you want to plot just based off of one column/attribute, you can do this. Each color reprsents the a row.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Working with projection",
    "text": "Working with projection\nThere are multiple ways you can study geography. You can study it if it were on a flat piece of paper or curved 3d way on your laptop screen.\nWhen there are two different ways of expressing geography, the way the data is, is differnet. If you want to use two sets of geospatial data, you want to ensure the data has the same projection, i.e. represents locations on the earth’s surface the same way. Hence, you will have to translate one of the maps to the same projection of another.\n\nWorking with projection\nOne of the common issues that can happen is that the coordinate system of a geospatial data is mising or incorrect. To check and input the correct coordinate system, we execute the following command to check the coordinate reference system.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nthen check at the end of the print if the ESPG code corresponds correctly to the coordinate system. Here, svy21 should correspond to 3414 not 9001. So we change it!\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow let’s double check if the ESPG code is correct\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nWorking with projection\nSometimes we change projection of a geospatial data to one that is congrunet with the type of analysis we are making.\nFor example, geographic coordinate system may not be appropriate if the analysis needs to use distance or/and area measurements.\nlet’s do some transformation here.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\n##Importing and Converting An Aspatial Data\n\n\nWhat is aspatial data?\nLet’s back track. Spatial data refers to physical location, shapes and positions of the objects on the earth’s surface.\nAspatial data refers to characteristics or properties of those objects. Airbnb is asptial data, so it focuses on what kind of house is it, how many bed rooms how many bathrooms, maybe its rental per night.\n\n\nImport spatial data\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nLet’s explore the data.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n###Creating a simple feature data frame from an aspatial data frame\nLet’s do some conversion : transform one coordinate system to another.\nFirst code line, we convert the aspatial data from to a simple feature data frame. Then we change the coordinate system.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\nHere, we will be learning about buffering and point in polygon.\n###Buffering\n####What is bufferring\nLet’s say there is a point of interest like a cycling path You want to analyse a certain amount of area around it, and the amount would be the buffer. Let’s say buffer is 5, you would want to study the area in a 5 mile radius around it.\nLet’s have another working scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nLet’s create a data frame with a buffer zone around the cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nYou created the buffer in the previous command , now you can calculate the total area of the buffer by doing so.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nNow the summation of the buffer land and the exisiting cycling path- total land involved.\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n###Point-in-polygon count\n####What is Point-in-polygon count\nIt refers to counting the number of points in an area (polygon)\nLet’s say, a pre-school service group wants to find out the numbers of pre-schools in each Planning Subzone.\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nZone with most preschools\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nCalculate density of presch\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n##Exploratory Data Analysis (EDA)\nLet’s visualize our data to get a better idea of it.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\n\n\n\nHello! In this page, i will be describing how i performed data wrangling - which is basically cleaning and transforming raw data into a more structured and usable format or later analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Installing and loading R packages",
    "text": "Installing and loading R packages\nIn this section, I will install and load ‘tidyverse’ and ‘sf’ packages.\n\nWhat are the sf and tidyverse packages?\nLet me give you a break down.\n\nTidyverse Package\nImagine you have a pile of dirty data that you need to handle. The Tidyverse package helps you handle your data. It actually has a bunch of packages within it to help handle data. It can do the following:\n\nreadr - reading and writing data into or out of a spreadsheet\ntidyr - organizing and tidying up your data\nggplot2 - visualizing your data\ndpylr - mainpulating your data, like doing some basic math to it.\n\n\n\nSF Package\nSF package provides us with tools to work with data related to maps and geospatial data. It can\n\nRead and write geospatial data from and into files.\nManipulate data - like cut out a specific area on a map\nVisualize data\n\nNow let’s load the packages into our environment.\n\n# Loads the p_load function on pacman which checks if packages are available, and then loads them into the R environment.\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\n\nImporting the geospatial data in shapefile format\nHere we import the geospatial data which is in shapefile format as a a polygon feature data frame.\n\nWhat is a shapefile and what is a polygon feature data frame?\n\nShapefile\nShapefile format stores geographic location and attribute information of geographic features.\n\n\nPolygon feature data frame\nThink of polygons as shapes that represent areas on a map.\nData frames store details about the polygons (think area) on tables.\nSo polygon feature data frames store data about areas on the map.\n\n#st_read is a function from the SF package which helps with the handling of data. We read the data into the variable mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n layer  = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\nImporting polyline feature data in shapefile form\n\nWhat is a polyline feature data frame?\nA polyline is made up of connected points and can represent things such as roads, rivers, or hiking trails.\nFeature Data Frames store information about these lines, like what is the name of the road, how long is it, what’s its surface?\nA polyline feature data frame stores information on lines that represent routes or rivers on a map.\nNow let’s import the polyline feature data\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\nImporting GIS data in kml format\n\nWhat is a GIS data and kml format ?\n\nkml format\nIt is keyhole markup language used to describe places and features on a digital map. You can define shapes like drawing a line to show a hiking trail or a polygon to show a lake. You can also attach information to places.\n\n\nGIS data\nA map has information like shapes, paths, data and locations. GIS data is when all this information is organized in a computer friendly way. People use these data to analyse the environment, plan cities and much more.\nNow let’s import GIS data in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Checking out the contents of a simple feature data frame",
    "text": "Checking out the contents of a simple feature data frame\n\nst_geometry\nShapes represent areas on a map. The data.frame in the package sf contains a column, and that column contains a list of those shapes in the specific class called ‘sfc’.\nLet’s execute this command\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThis commands tells you a few things:\n\nThe types of shapes you’re dealing with. Multipolygon means its an area with multiple connected lines.\nThe bounding box/ range of coordinates that coer the same\nAlso the first 5 shapes in the column of the data frame\n\n\n\nglimpse\nLet’s execute this command\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThis command gives you a glimpse into the dataset.\nit tells you the following things:\n\nthe number of rows\nthe number of columns\nwhat columns are there\ndata type of each column\nfirst few values of each column\n\n\n\nhead()\nLet’s execute this command\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThis provides you with complete information (columns and the number of values u want)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Plotting Data",
    "text": "Plotting Data\nNow, let’s plot the data in our mpsz as a visualization. We use the plot() function for it.\nThis provides the entire visualization.\n\nplot(mpsz)\n\n\n\n\nIf you want to just plot the different shapes in the map, we can do this:\n\nplot(st_geometry(mpsz))\n\n\n\n\nIf you want to plot just based off of one column/attribute, you can do this. Each color reprsents the a row.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection-3",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection-3",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Working with projection",
    "text": "Working with projection\nThere are multiple ways you can study geography. You can study it if it were on a flat piece of paper or curved 3d way on your laptop screen.\nWhen there are two different ways of expressing geography, the way the data is, is differnet. If you want to use two sets of geospatial data, you want to ensure the data has the same projection, i.e. represents locations on the earth’s surface the same way. Hence, you will have to translate one of the maps to the same projection of another.\n\nWorking with projection\nOne of the common issues that can happen is that the coordinate system of a geospatial data is mising or incorrect. To check and input the correct coordinate system, we execute the following command to check the coordinate reference system.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nthen check at the end of the print if the ESPG code corresponds correctly to the coordinate system. Here, svy21 should correspond to 3414 not 9001. So we change it!\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow let’s double check if the ESPG code is correct\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nWorking with projection\nSometimes we change projection of a geospatial data to one that is congrunet with the type of analysis we are making.\nFor example, geographic coordinate system may not be appropriate if the analysis needs to use distance or/and area measurements.\nlet’s do some transformation here.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\n##Importing and Converting An Aspatial Data\n\n\nWhat is aspatial data?\nLet’s back track. Spatial data refers to physical location, shapes and positions of the objects on the earth’s surface.\nAspatial data refers to characteristics or properties of those objects. Airbnb is asptial data, so it focuses on what kind of house is it, how many bed rooms how many bathrooms, maybe its rental per night.\n\n\nImport spatial data\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nLet’s explore the data.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n###Creating a simple feature data frame from an aspatial data frame\nLet’s do some conversion : transform one coordinate system to another.\nFirst code line, we convert the aspatial data from to a simple feature data frame. Then we change the coordinate system.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\nHere, we will be learning about buffering and point in polygon.\n###Buffering\n####What is bufferring\nLet’s say there is a point of interest like a cycling path You want to analyse a certain amount of area around it, and the amount would be the buffer. Let’s say buffer is 5, you would want to study the area in a 5 mile radius around it.\nLet’s have another working scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nLet’s create a data frame with a buffer zone around the cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nYou created the buffer in the previous command , now you can calculate the total area of the buffer by doing so.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nNow the summation of the buffer land and the exisiting cycling path- total land involved.\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n###Point-in-polygon count\n####What is Point-in-polygon count\nIt refers to counting the number of points in an area (polygon)\nLet’s say, a pre-school service group wants to find out the numbers of pre-schools in each Planning Subzone.\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nZone with most preschools\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nCalculate density of presch\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n##Exploratory Data Analysis (EDA)\nLet’s visualize our data to get a better idea of it.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "here we are doing spatial point analysis where we are basically studying and analysing the spread of points in a space.\nIt helps us answer tje following questions:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "IS415-GAA",
    "section": "",
    "text": "here we are doing spatial point analysis where we are basically studying and analysing the spread of points in a space.\nIt helps us answer tje following questions:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#data",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#data",
    "title": "IS415-GAA",
    "section": "Data",
    "text": "Data\n\nchildcare\nMP14_SUBZONE_WEB_PL\nCostalOutline"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#installing-and-loading-the-r-packages",
    "title": "IS415-GAA",
    "section": "Installing and loading the R packages",
    "text": "Installing and loading the R packages\nWe need to install and load the R packages into the R environment to use them\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)\n\nIf you aren’t able to install maptools, do this:\n\ninstall.packages(\"maptools\", repos=\"http://R-Forge.R-project.org\")\n\nWarning: package 'maptools' is in use and will not be installed"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#spatial-data-wrangling",
    "title": "IS415-GAA",
    "section": "Spatial Data Wrangling",
    "text": "Spatial Data Wrangling\n\nImporting the spatial data\nWe will use the st_read() function of sf package to import geospatial datasets into R.\nLet’s import the first one of ChildCareServices:\n\nchildcare_sf &lt;- st_read(\"data/ChildCareServices.geojson\")\n\nReading layer `ChildCareServices' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe can see that the CRS is not what we want let’s transform it to SVY21\n\nchildcare_sf &lt;- st_transform(childcare_sf, crs = 3414)\n\nLet’s print out childcare_sf to see what is the CRS.\n\nst_geometry(childcare_sf)\n\nGeometry set for 1925 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (40985.94 33848.38 0)\n\n\nPOINT Z (28308.65 45530.47 0)\n\n\nPOINT Z (17828.84 36607.36 0)\n\n\nPOINT Z (25579.73 29221.89 0)\n\n\nPOINT Z (38981.02 32483.41 0)\n\n\nLet’s import coastal outline.\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nWhen we look at the coordinate reference system of coastal outline, we see that the user input is SVY21 but the correct EPSG code is 9001 instead of 3414.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSo here we change it to 3414.\nReminder we don’t use st_transform() because the CRS is already SVY21, it’s just the ESPG code that is wrong!\n\nsg_sf &lt;- st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow let’s recheck if the coordiante system and ESPG code match.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNow let’s import MP_14_SUBZONE_WEB_PL.\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nLet’s check the coordinate system, it has to be SVY21 so that it is projected coordinate system, and the ESPG code has to match the SVY21.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince it’s 9001 and not 3414, let’s change the code.\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nLet’s check.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nMapping the Geospatial data sets\n\ncol_names &lt;- names(childcare_sf)\nprint(col_names)\n\n[1] \"Name\"        \"Description\" \"geometry\"   \n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +\n  tm_shape(childcare_sf) +  \n  tm_dots()"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "title": "IS415-GAA",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\nAlthough simple feature data frame is gaining popularity again sp’s Spatial* classes, there are, however, many geospatial analysis packages require the input geospatial data in sp’s Spatial* classes. In this section, you will learn how to convert simple feature data frame to sp’s Spatial* class.\n\nConverting sf data frames to sp’s Spatial* class\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\n#print(as.data.frame(childcare))\n\n\n#childcare\n\n\n#mpsz\n\n\n#sg\n\n\n\nConverting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. \nSpatial* classes -&gt; Spatial -&gt; ppp\nLet’s do spatial* classes -&gt; spatial first\nRemeber to use the correct type of shape\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nWhat are the differences between Spatial* classes and generic sp object?\nIn summary, you would use Spatial* classes when you have simple spatial data without additional attributes, and you want a straightforward representation of points, lines, or polygons. On the other hand, if your spatial data includes associated attributes and you need to perform in-depth analysis, you would use generic sp objects like SpatialPointsDataFrame or SpatialPolygonsDataFrame.\nFor example, if you only need to plot the locations of childcare centers on a map, you can use the SpatialPoints class. However, if you want to perform statistical analysis on the childcare data, including attributes such as capacity or age group, you would convert it into a SpatialPointsDataFrame, which allows you to work with both spatial and attribute data seamlessly.\n\n\nConverting the generic sp format into spatstat’s ppp format\nsp -&gt; ppp. And now you can put it into spatstat.\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1925 points\nwindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\nwhat’s the difference between plotting a geojson with spatial points and plotting the same data thats converted to ppp format\nPlotting a GeoJSON file with spatial points typically results in a standard spatial point map. Each point is displayed as a symbol or marker on the map, and you can customize the appearance of the points, such as color, size, and shape.\nConverting data to ppp format is typically done when you intend to perform spatial point process analysis. In this context, a point pattern represents the locations of events or objects of interest (e.g., tree locations, disease cases). ppp objects are used in the spatstat package for advanced spatial point pattern analysis. This includes tasks like assessing spatial clustering, estimating intensity, performing K-functions analysis, and simulating point patterns under different models.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\nHandling duplicated points\nDuplicates, in this context, are multiple points that occupy exactly the same location in space.\nCoincident points are points that are so close to each other that they are considered to occupy the same location within a certain tolerance threshold.\nThese duplicates or coincident points can occur for various reasons, such as measurement errors, data collection methods, or the nature of the phenomenon being studied.\nLet’s check if there are any duplicates in the data:\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nThe multiplicity() function is a function or method typically provided by spatial point pattern analysis software or packages like spatstat. Its purpose is to calculate the multiplicity of points in a point pattern. Multiplicity refers to the number of points that occupy the same location (coincident points) at each location where such coincidences occur.\n\n# Count the number of coincident\n#points in the childcare_ppp point pattern\nmultiplicity(childcare_ppp)\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\nThere are three different approaches to address the issue of duplicate points in spatial point pattern analysis:\n\nDeleting Duplicates: This is the simplest approach, where you remove the duplicate points from your dataset. However, this method comes with a drawback, as it may result in the loss of valuable point events. If each point represents a meaningful observation, deleting duplicates can lead to the omission of important data.\nJittering: The second solution involves adding a small random perturbation to the duplicate points. This perturbation is often referred to as “jitter,” and it introduces a slight variation in the spatial locations of duplicate points, ensuring that they do not occupy the exact same space. Jittering is a way to retain all points while avoiding the issue of perfect overlap.\nAttaching Duplicates as Marks: The third solution is to treat each point as “unique” and then attach the duplicates of the points as marks or attributes of the points. In this approach, duplicate points are not removed or perturbed; instead, they are associated with additional information or attributes. This allows you to preserve all observations while acknowledging their duplications. Analytical techniques that consider these marks can be applied to study the spatial pattern or relationships among points.\n\n\nJittering\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nLet’s check if there are any duplicate points\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nCreating owin object\nThe owin object is essentially a spatial window that limits the analysis to a specific polygonal region. It provides a framework for handling point patterns within this spatial window. This is particularly important when you want to account for the geographic boundaries of the study area in your analysis.\n\n# this is from generic spatia lclass to owin\nsg_owin &lt;- as(sg_sp, \"owin\")\n\n\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\n\nCombining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "IS415-GAA",
    "section": "First-order Spatial Point Patterns Analysis",
    "text": "First-order Spatial Point Patterns Analysis\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics\n\n\nKernel Density Estimation\n\nComputing kernel density estimation using automatic bandwidth selection method\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\n\nCode walkthrough:\n\ndensity: estimate density of a dataset\nsigma=bw.diggle\n\nsigma refers to the bandwidth / radius of the circle/base of the hill. remember, each hill would be given a weight at its peak and it slowly gradually decreases as it goes to the sides.\nbw.diggle is how we calculate the bandwidth\nkernel=gaussian refers to the smoothening method. we know the density is the top of the hill, and how it smoothens out to the edges of the hill is controlled by the kernel method\n\n\n\nplot(kde_childcareSG_bw)\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nHow do you recover bandwidth:\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n306.6986 \n\n\n\n\nRescalling KDE values\nkde_childcareSG_bw stores the density information / the density at different parts of the geographic space.\nNormally, density in the context of kernel density estimation is expressed in terms of “number of points per unit area.” Since the unit here is meters, the density is being expressed as “number of points per square meter.” This means that the value you see (like 0.000035) represents how many points you would expect to find in a square meter of space.\nWhy the Values are Small: Given that a square meter is a relatively small area for most geographical data (like locations of childcare centers, if that’s what your data represents), it’s common for the density values to be very small, especially if the points (childcare centers in this example) are not extremely densely packed.\nIn practical terms, when dealing with such small values in a large area (like a city or country), we might consider transforming the scale of your data or adjusting the units of measurement to make the data more interpretable. For instance, we could convert the densities into “number of points per square kilometer” by multiplying the densities by 1,000,000 (since there are 1,000,000 square meters in a square kilometer). This could make the values more comprehensible in a broader geographical context.\nIn the code chunk below, rescale() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp.km &lt;- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nplot(kde_childcareSG.bw)\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend).\n\n\n\nWorking with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.159749 1.396455 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.3066986 \n\n\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\nWorking with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\npar(mfrow=c(2,2)) plot(density(childcareSG_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=“gaussian”), main=“Gaussian”) plot(density(childcareSG_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=“epanechnikov”), main=“Epanechnikov”) plot(density(childcareSG_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=“quartic”), main=“Quartic”) plot(density(childcareSG_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=“disc”), main=“Disc”)"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "title": "IS415-GAA",
    "section": "Fixed and Adaptive KDE",
    "text": "Fixed and Adaptive KDE\n\nComputing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nplot(kde_childcareSG_600)\n\n\n\n\n\n\nComputing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, you will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\nConverting KDE output into grid object\nA grid object in spatial analysis represents a regular tessellation of a surface into cells or squares, each with its own value. In the context of KDE output, each cell in the grid would represent the estimated density of points within that cell.\nWhy do we do this?\nCell-wise Comparisons: Once the KDE output is in a grid format, you can perform cell-wise comparisons or calculations. For example, you might want to find areas where the density exceeds a certain threshold or calculate the total area that has a density within a specific range.\nIntegration with GIS Tools: Many Geographic Information System (GIS) tools are optimized to work with grid data. Converting KDE output to a grid format makes it easier to use these tools for further analysis, modeling, or mapping.\nLet’s convert\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\n\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\nConverting gridded output into raster\nWhy do we do this?\nBoth raster data and gridded outputs represent spatial information using a grid format, but they serve slightly different purposes and have varying degrees of compatibility with Geographic Information Systems (GIS) and third-party tools.\n\nInteroperability with GIS and Tools: While both gridded outputs and raster data are grid-formatted, raster data is specifically formatted for and thus more directly interoperable with GIS software and third-party tools. Raster formats are designed to be easily imported, manipulated, analyzed, and visualized in GIS platforms.\nMetadata and Georeferencing: Raster datasets typically include metadata and georeferencing information, making them immediately useful for spatial analyses without requiring additional steps to define the spatial extent, projection, or coordinate system.\nEfficiency and Compatibility: Raster formats often support compression, pyramids for efficient zooming, and spatial indexing, which enhances their performance in GIS applications. They are widely supported across different platforms, ensuring compatibility and ease of use in various analyses and application contexts.\n\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -1.014191e-14, 32.45281  (min, max)\n\n\ndimensions: 128, 128, 16384:\n\nnrow: The raster has 128 rows.\nncol: The raster has 128 columns.\nncell: The total number of cells (or pixels) in the raster is 16,384, which is the product of the number of rows and columns (128 x 128).\n\nresolution: 0.4170614, 0.2647348 (x, y): This specifies the size of each cell in the units of the raster’s coordinate reference system (CRS). The first number is the width of each cell (x-direction), and the second number is the height of each cell (y-direction). This tells you how much geographic area each pixel represents.\n\n\nAssigning projection systems\nWe saw that there was no projection system on the raster variable. So let’s assign it!\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.014191e-14, 32.45281  (min, max)\n\n\n\n\n\nVisualising the output in tmap\nFinally, we will display the raster in cartographic quality map using tmap package\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nVariable(s) \"v\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nif i did not put tm_raster i would have put tm_fill or tm_polgon.tm_raster, tm_fill, and tm_polygon are functions used within the tmap package in R to add different types of layers to a map,\ntm_raster is specifically designed for adding and visualizing raster data layers on a map.\n\n\ntm_fill and tm_polygon\n\ntm_fill: This function is used to add and visualize areas on a map by filling them with colors based on their attributes. It’s often used with spatial polygons data where each polygon represents a distinct area, such as countries, states, districts, or other regions.\ntm_polygon: Very similar to tm_fill, tm_polygon is used to add polygon layers to a map. It can fill the polygons with color based on their attributes and also allows for the customization of border colors and styles. Essentially, tm_fill is a shortcut for tm_polygon with a focus on filling the polygons rather than styling their borders.\n\n\n\nComparing Spatial Point Patterns using KDE\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas\n\n4.7.5.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\nplot(pg, main = \"Ponggol\")\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\nConverting the spatial point data frame into generic sp format\nso mspz, and any data from it was converted from sf to sp’s spatial* class\nIn summary, you would use Spatial* classes when you have simple spatial data without additional attributes, and you want a straightforward representation of points, lines, or polygons. On the other hand, if your spatial data includes associated attributes and you need to perform in-depth analysis, you would use generic sp objects like SpatialPointsDataFrame or SpatialPolygonsDataFrame.\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\nCreating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\nspatstat cant take generic sp obejcts and tehy need to be converted into owin objects\nThis is so that we confine our geospatial analysis to that area.\n\nConverting sp Objects to spatstat Objects\nTo use sp objects with spatstat, you generally need to convert them into a format that spatstat understands:\n\nFrom sp to owin: If you have a spatial polygons object from the sp package that defines the study area or observation window, you would convert it to an owin object to define the observation window in spatstat.\nFrom sp Point to ppp: Similarly, if you have point data in an sp format, you would convert it to a ppp object (point pattern object) for analysis in spatstat.\n\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\nchildcare_ppp_jit was made when we tried to remove duplicated points. And that was made from childcare_ppp that was made from an sp object, as ppp objects were needed to put into the spatstat object for spatial analysis.\n\n\n\nCombining childcare points and the study area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\n\n\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\n\n\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\n\n\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\nComputing KDE\nLet’s compute KDE in each location!\n\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\n\n\n\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\n\n\n\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\n\n\n\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\nComputing fixed bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth\n\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\n\n\n\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\n\n\n\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "title": "IS415-GAA",
    "section": "Nearest Neighbour Analysis",
    "text": "Nearest Neighbour Analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\nTesting spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.5062, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\nClark and Evans Test: Choa Chu Kang planning area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.87454, p-value = 0.03896\nalternative hypothesis: two-sided\n\n\n\n\nClark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.69577, p-value = 3.068e-10\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Hello! In this page, i will be describing how i performed Thematic Mapping and GeoVisualisation with R. I will mainly be trying to create a choropleth map using the tmap package!\nWe also use pivot_wider() of the tidyr package, and mutate() ,group_by() , select() and filter() of the dplyr package, which i will be explaining in detail.\nI hope you can follow along, and be able to create choropleth maps!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#loading-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#loading-packages",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "Loading packages",
    "text": "Loading packages\nThis is a very important step as we have to load the packages before we can use them.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\nWhat is the tmap package?\nThe tmap package provides you with many handy functions to create your own thematic maps like choropleth maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "Importing the data",
    "text": "Importing the data\n\nDownloading the data\nThe links of the data i used are here (download shp format) and here\n\n\nImporting Geospatial Data into R\nAs learnt in the previous page, we use st_read() function of the sf package to read in the data.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWhen we realtiple features (geographical entities), with 15 fields, or attributes (such as temperature, precipitation for example).\nLet us examine it further by just printing mpsz (the variable we have stored the data in, that is of sf data object).\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nWe can also use glimpse() or head().\n\n\nImporting Attribute Data into R\nNow let us import the aspatial or attribute data into R.\n\nWhat is aspatial/attribute data?\nIt is data that’s not related to shape/location or coordinates but provides more context to the data. For example, if the data is about Airbnb, it tells you the number of rooms, the pricing, the number of people living in each Airbnb house.\nLet’s import it:\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nNow, let’s view it:\n\nlist(popdata) \n\n[[1]]\n# A tibble: 984,656 × 7\n   PA         SZ                     AG     Sex     TOD                Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 1- and 2-Ro…     0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 3-Room Flats    10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 4-Room Flats    30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 5-Room and …    50  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HUDC Flats (exc…     0  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Landed Properti…     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Condominiums an…    40  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Others               0  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 1- and 2-Ro…     0  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 3-Room Flats    10  2011\n# ℹ 984,646 more rows\n\n\n\n\n\nData Preparation\nWe need to prepare data to be in the form of a data table (like a normal sql table) before we can prepare a choropleth map.\nTo prepare the data, we use a few methods. i will go through them here before we actually execute them.\nThese are the methods we will go through:\n\npivot_wider() - tidyr package\nmutate() - dplyr package\ngroup_by() - dplyr package\nselect() - dplyr package\nfilter() - dplyr package\n\n\npivot_wider()\nIt helps transform data from long format to wide format.\nLong format: There are more rows and less columns. Here data is normalised and there are many rows for one subject. This can make it hard to compare the different subjects, and is not very good for visualization.\nHere is how a long format table could look like:\n\nHere there are multiple rows if you want to see the amount of sales in a particular month , or for a particular product. It is not very conducive for comparisons.\nWide format: There are less rows and more columns.\n\nHere there are lesser rows (usually there are more rows but in this case it worked out to still being 3 columns). And it is clearer as to how much sales there is per product per month.\nHow it’s used:\nwide_data &lt;- long_data %&gt;% pivot_wider(names_from = Product, values_from = Sales)\nnames_from: is the argument where you specify the column that will be used to create columns in the wide format\nvalues_from: specifies the column containing the values that will be used to file the new wide format columns\n\n\nmutate()\nmutate() is used to execute operations on existing columns and transform them, create new columns, or transform/create data using conditional statements.\n\nHere we see that we create a new column called Grade and if the score is greater than 90, we populate it with A , if not B. We then process existing data by increasing age by 1.\n\n\nfilter()\nThis method is used to filter rows based on a condition. Here is how it is used:\n\nHere we filter the rows and include rows in the data frame ONLY if the score was equal to or greater than 90.\n\n\nselect()\nThis is like the select query in sql, and you use this to select columns you are interested in.\n\n\n\ngroup_by()\nHere you group the data into groups due to a column, like gender for instance. You can then do group wide operations.\n\n\n\nData Wrangling\nNow this is the code we are supposed to run to prepare the data. Before we prepare the data let’s take a step back.\nOur purpose here is to build a choropleth map that shows you the distribution of the dependency variable across the country/ per region. The dependency variable is calculated like so: DEPENDENCY = (YOUNG + AGED) /`ECONOMY ACTIVE. Thus, we need to know the number of people who are young, aged and economy active in each region. Hence, we have to make sure we make rows that tell us these values per region - that requires group by the two values PA and SZ. We can also group_by AG first so we can see the number of people per age group in each location.\nI have added the explanation for each line of code above that code.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  # we then just want to display columns that are these\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\nCode walkthrough\n\nfilter(Time == 2020) %&gt;%\n\nHere, we are only selecting the rows that have the value 2020 under the time category.\nHere’s a sample data set to help you understand.\n\n\ngroup_by(PA, SZ, AG) %&gt;%\n\nIn group by, we make different groups, each with a unique combination of PA, SZ, and AG. Any row in the dataset that matches that group’s combination of PA, SZ, and AG will be in that group. Hence, each group will have different number of rows. All of the columns of the row will still be there when just executing a group_by(). When grouping, we can do group wide operations, instead of data wide.\n\nsummarise(POP = sum(Pop)) %&gt;%\n\nWe now have the data in groups, with each group having different number of rows.\nWe then add up all the population figures of all the rows in each group and store them in a new column called pop. Now, since the population values in all rows in each group are added together, we have one row per group. Each group has its own combination of pa, sz and ag and its aggragated total summary for population. All the other columns like sex and tod are discarded. You chose to add the population values of all rows together, and did not mention what to do with the other rows, hence they are discarded!\nIn the picture below, you can see that the number of rows have decreased as there were some groups with more than 1 row, and when the population values were added, they were summarised into a row.\nWe now know the number of people per age group per region. This is vital because we have different categories such as young, aged and economy active that we need to compute. Each young, aged and economy active category would consitute of different age categories. Having various different age categories allows us to pick and choose the varying age categories we want to compute to find out the population for each of the young, aged and economy active categories for each region.\n\n\npivot_wider(names_from=AG, values_from=POP) %&gt;%\n\nTo make it easier to compute the population values for each young, aged and economy active category per region, we should make the age categories column names. Then, we can make the population the values under each age category. As illustrated below, we can easily see the number of people per age category per region.\n\n\nmutate(YOUNG = rowSums(.[3:6]) +rowSums(.[12])) %&gt;%\n\nAs we said before, there are different age categories , like 0-4 being one column 5-9 being another column. Hence, we add up populations under columns 3 to 6 in each row as that is the age range that we think is young. After calculating that for each row, we create a column called young and populate it.\n\n\nmutate(ECONOMY ACTIVE = rowSums(.[7:11])+ rowSums(.[13:15]))%&gt;%\n\nnext we want to find out what is the total number of pople in each subzone that are economically active. so we want to add up the values under age range categories that we think are eco active in each row and then make a eco active column and populate it underneath that\n\nmutate(AGED=rowSums(.[16:21])) %&gt;%\n\nDo the same thing for total number of people for each subzone\n\nmutate(TOTAL=rowSums(.[3:21])) %&gt;%\n\nDo the same thing for total number of people for each subzone\n\nmutate(DEPENDENCY = (YOUNG + AGED) /ECONOMY ACTIVE) %&gt;%\n\nwe then calculate the dependency\n\nselect(PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY)\n\nwe then just select the columns we want\n\n\n\n\n\nJoining attribute and geographical data\nThe values in PA and SZ are made up of lower and upper case so lets make them all uppercase\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNow let’s join them based on one common column that is SZ - it is present in both the geospatial and attribute data.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nLet’s write it into a file. Remember to create the directory and file data/rds/mpszpop2020.rds before executing this.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "Choropleth Mapping Geospatial Data using tmap",
    "text": "Choropleth Mapping Geospatial Data using tmap\nYou can do this two ways\n\nPlotting a thematic map quickly by using qtm()\nPlotting highly customisable thematic map by using tmap elements\n\n\nUsing qtm()\nWhen we say fill = “DEPENDENCY”, we mean that the colors of the choropleth map would vary based on the values of dependency.\nThis method is quick but reduces the scope for customization.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\nUsing tmap()\nWe can start of with learning about using tm_shape() and tm_fill().\nWe are showing a geographical distribution of dependency.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nIf we wanted to customise more, and use tm_borders,\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nIf we wanted ultimate customisation, these are the functions and arguments available.\nstyle= quantile shows that we use quantile to classify the data and come up with categories/classes. This means there are four categories with the number of data points each category being equal.\nThe palette=blues is the theme of the map.\nThe layout method often focuses on the aesthetics of the map and is quite self explanatory.\ntm_compass() adds a compass to the map.\ntm_scale_bar() adds the scale to show the relationship between the real measurements to the measurements on the screen.\ntm_grid() adds grid lines to show longitutde and latitude.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nHere we have used tmap and used tm_shape() + tm_fill(). tm_fill() automatically draws out polygons in your map and fills them with the color necessiated by its relevant value.\nLet’s say you wanted to draw other shapes in your map other than polygons. You could do that with tm_lines() or tm_raster()\nBut let’s say we wanted to say outright that we wanted to draw out polygons. We can use tm_polygons()\n\n\nUsing tm_polygons()\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\nRemember: we have to do tm_shape first to load our data in.\nIf we wanted to also say what variable we wanted to show a geographical distribution of :\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\nDrawing a choropleth map using tm_fill() and *tm_border()*\nWritten right underneath the tmap section for better flow.\n\n\nData classification methods of tmap\nThere are different ways to classify data into categories.\n\nPlotting choropleth maps with built-in classification methods\nHere we are using jenks, which means it looks for natural clusters in the data and then groups them together. And we are looking to divide the data into 5 natural clusters.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can also use equal, where the interval in data values is equal. But this will not be good when the data is skewed in one direction as there might not be any data points in many of the intervals.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nDIY (1)\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\nLet’s try sd:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s try quantile:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nI can see that quantile shows more of a geographic distribution. sd shows a lesser range- perhaps the sd was too huge. Hence, there were large number of data points per category and consequently, the number of categories was also less - showing less of a range.\n\n\nDIY (2)\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\nLet’s try quantile.\nLet’s start with 6 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s start with 6 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 7,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can see the map when the classes are 5,6 and 7. As it increases from 5 to 6, we get a greater nuance in the geographic distribution of the dependency column. However, when we go from 6 to 7, there is not much of an increase in nuance. The difference in category boundaries are very minimal. Hence, the ideal number of classes would be 6.\n\n\nPlotting choropleth maps with custom breaks\nIn the methods we used before, the breakpoints were set automatically by them. If we wanted to define the boundaries of each category ourselves, we can do that too. However, to do that, we need more information about the data to understand it. Getting the data’s mean/quantile values, minimum, median, can help with setting those boundaries.\nSo let’s get those values through the use of this method.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nNow let’s choose our breakpoints and plot the choropleth map.\nOur breakpoints are at 0, 0.6. 0.7, 0., 0.9, 1.00.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nColor Scheme\nNow on to the fun part! We get to delve into the color scheme of things\n\nUsing ColourBrewer palette\nLet’s try the blue palette.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s try the green palette.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nMap Layouts\nWhen we talk about map layouts, we want to control how a map looks. We want to ensure that all aspects of a map are present. This includes the title, the scale bar, the compass, legend, margins and aspect ratios. We also can control the style of the map.\n\nMap Style\nThis refers to tmap_style(), not the style argument in your tm_fill where you declare the type of data classification you choose to employ.\nIt controls how your map would look like. These are the arguments you could use:\nThe available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \nIf we were to use classic:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\nIf we used dark,\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"cobalt\")\n\n\n\n\n\n\nMap Legend\nLet’s try adding the legend first.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s go through what the legend part of the code means.\nlegend.hist= TRUE means that we are going to include a histogram like legend. This will allow the viewer to see the distribution of values in the form of a histogram as well.\nlegend.is.portrait = TRUE means that the legend/histogram will be in portrait orientation.\nlegend.hist.z=0.1 means the legend will be slightly behind the map.\n\n\nCartographic furniture\nThis refers to adding of the compass, scale bar and grid lines that we talked about earlier.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\nDrawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arranged side-by-side or vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\nBy assigning multiple values to at least one of the aesthetic arguments\nHere you want both to have the data classification of equal.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nNow, you want each of them to have different data classifications, and different looks.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nIn these two sets of graphs (4), the two maps in each set are showcasing different variables across Singapore . In the first set, we show the distribution of young and then the distribution of old.\nNow what if we wanted the maps to be linked to each other, as in, show the distribution of the same variable?\n\n\nBy defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nHere, we show the distribution of the same dependency variable across multiple regions.\n\n\nBy creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\nMappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html",
    "title": "Hands-On Exercise 3 :",
    "section": "",
    "text": "pacman::p_load(maptools, sf,raster,spatstat,tmap,tidyverse)\nHere we use two different types of reading because for childcare we know the exact file but the other file is a shapefile that requires multiple files, so you use the dsn part.\nchildcare_sf &lt;- st_read(\"../../Hands-On_Ex/Hand-on_Ex03/data/ChildCareServices.geojson\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `ChildCareServices' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nmpsz_sfe &lt;- st_read(dsn=\"data/geospatial\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\In-class_Ex\\In-class-Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#creating-coastal-outline",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#creating-coastal-outline",
    "title": "Hands-On Exercise 3 :",
    "section": "Creating Coastal outline",
    "text": "Creating Coastal outline\nWhen you apply st_union() to a collection of polygons, each representing a state within a country, the function merges all these state polygons into a single polygon that represents the entire country, effectively dissolving the boundaries (state lines) between them.\n\nsg_sf &lt;- mpsz_sfe %&gt;%\n  st_union()\n# st_combine combines geometries wirhout dissolve/resolve boundaries but st_union does\n\n\nplot(sg_sf)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#geospatial-data-wrangling",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#geospatial-data-wrangling",
    "title": "Hands-On Exercise 3 :",
    "section": "geospatial data wrangling",
    "text": "geospatial data wrangling\ncreating ppp objects : sf method\neasier to do this to get from sf -&gt; ppp, instead of sf -&gt; sp* -&gt; sp general -&gt; ppp\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1925 character character \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\nHandling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\nThis is very important for postal code data. Postal code covers a large area and muliple data points have the same postal code, so you must check if there are duplicates + use jittering\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\n\n\nCreating owin object : sf method\nThis .owin helps with the conversion aagain without you doing sf -&gt; sp* -&gt; sp general -&gt; owin\n\n# . functions work with sf layer, so take the originl data\nsg_owin &lt;- as.owin(sg_sf)\n\n\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422\n\n\n\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\n\npg &lt;- mpsz_sfe %&gt;% \n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sfe %&gt;% \n  filter(PLN_AREA_N == \"TAMPINES\")\nckk &lt;- mpsz_sfe %&gt;% \n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sfe %&gt;% \n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning area\n\nplot(pg, main =\"Punggol\")\n\n\n\n\n\nplot(tm, main =\"Tampines\")\n\n\n\n\n\nplot(ckk, main =\"Chua Chu Kang\")\n\n\n\n\n\nplot(jw, main =\"Jurong West\")"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#network-constrained-kernel-density",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#network-constrained-kernel-density",
    "title": "Hands-On Exercise 3 :",
    "section": "Network constrained kernel density",
    "text": "Network constrained kernel density"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#getting-started",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#getting-started",
    "title": "Hands-On Exercise 3 :",
    "section": "Getting started",
    "text": "Getting started\n\npacman::p_load(sp,rgdal,sf, spNetwork, tmap, classInt, viridis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#data-import-and-preparation",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#data-import-and-preparation",
    "title": "Hands-On Exercise 3 :",
    "section": "2. Data Import and Preparation",
    "text": "2. Data Import and Preparation\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\", layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\In-class_Ex\\In-class-Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcareNew &lt;- st_read(dsn=\"data/geospatial\", layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\In-class_Ex\\In-class-Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\nChange projection system\n\nchildcareNew &lt;-childcareNew %&gt;% st_transform(crs =3414)\n\nnetwork &lt;-network  %&gt;% st_transform(crs =3414)\n\n\n\nPlot\n\ntmap_mode('plot')\ntm_shape(childcareNew) + \n  tm_dots() + \n  tm_shape(network) +\n  tm_lines()\n\n\n\n\n\nlixels &lt;- lixelize_lines(network,750,mindist = 375)\n\nlength of a lixel is set to 750m and min length of a lixel is set to 375\n\nsamples &lt;- lines_center(lixels)\n\n\ndensities &lt;- nkde(network, \n                  events = childcareNew,\n                  w = rep(1,nrow(childcareNew)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "",
    "text": "Hello everyone! In tiny dense Singapore, movement of people is large and fast. Hence, in depth analysis of our movement can provide meaningful and actionable insights on our spatial-temporal behaviour.\nIn Singapore, we move by utilising a multitude of avenues such as buses, MRTs, LRTs and private hail services. In this exercise, I will be exploring the movement of our people using grab. We will be utilising spatial point analysis methods to discover the geographical and spatio-temporal distribution of Grab hailing service locations in Singaore."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-download",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-download",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "2.1 Data Download",
    "text": "2.1 Data Download\nLet us first look at the data we are utilising to conduct this analysis.\n\nOverview Off Data Used\n\n\nData Name\nDescription\nType\nFormat\nSource\n\n\nGrab-Posisi\nData on where grab taxis are at a specific time, and at what speed.\nAspatial\n.parquet\nSource\n\n\nRoad data set\nData on the roads present in Singapore, Malaysia, Brunei.\nGeospatial\nESRI shapefile\nSource\n\n\nMaster Plan 2019 Subzone Boundary (No Sea)\nThis data provides the internal and external boundary in Singapore.\nGeospatial\n.kml\nSource"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-import",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-import",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "2.2 Data Import",
    "text": "2.2 Data Import\n\nGrab-PosisiRoad Data SetMaster Plan 2019 Subzone Boundary\n\n\n\ngrab &lt;- read_parquet(\"../../data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n\n\n\n\nroads &lt;- st_read(dsn = \"../../data\",\n                   layer = \"gis_osm_roads_free_1\")\n\nReading layer `gis_osm_roads_free_1' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\data' using driver `ESRI Shapefile'\nSimple feature collection with 1765176 features and 10 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 99.66041 ymin: 0.8021131 xmax: 119.2601 ymax: 7.514393\nGeodetic CRS:  WGS 84\n\n\n\n\n\nmpsz &lt;- st_read(dsn = \"../../data\",\n                   layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source `C:\\shaysnutss\\IS1455-GAA\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-wrangling",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\nWe now have our data imported into our R environment, means we can interact with it and use it!\nHowever, data often can’t be used as it is . We would have to change the data to fit our analysis needs. And that is what we will be doing in this section!\nWe will be doing it dataset by dataset:\n\n2.3.1 Master Plan 2019 Subzone Boundary\n\n2.3.1.1 Coordinate Reference System\nLet’s start with checking the coordinate reference system of the dataset.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nWe know that the coordinate reference system is WGS84. We have to convert it to SVY21. This is because we want to minimise distortions and enable accurate area and distance measurements. The earth is curved, and the WGS84 reference system results in the distance between two points in the equator being different from the distance between the equally spaced points up in north america.\nSo let’s convert this to SVY21:\n\nmpsz &lt;- st_transform(mpsz, crs = 3414)\n\nLet’s check if it has been converted correctly\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n2.3.1.2 Dropping Z coordinate\n\nmpsz &lt;- st_zm(mpsz)\n\n\n\n2.3.1.3 Geometry Validity\nI know we have dropped the Z coordinate, but we still want to check if the geometries we have are valid or if they have any errors. Some of the errors could be zero-area polygons or unclosed rings. Ensuring the data is valid and correcting it before analysis is crucial for an accurate and comprehensive analysis.\nSo this is how we check if the geometries are valid:\n\nlength(which(st_is_valid(mpsz) == FALSE))\n\n[1] 6\n\n\nOh no! We have 6 invalid geometries. Thank god we caught it!\nLet’s make it right using this function:\n\nmpsz &lt;- st_make_valid(mpsz)\nlength(which(st_is_valid(mpsz) == FALSE))\n\n[1] 0\n\n\n\n\n2.3.1.4 Missing values\nWe want to check if there are any empty rows. Datasets can be huge and consequently, we could have many empty rows that is just a waste of memory and processing power. Removing them would be useful.\nHere’s how we do it:\n\n# Use the filter function to check for empty rows\nempty_rows &lt;- mpsz %&gt;%\n  filter_all(all_vars(is.na(.)))\n\n# Check if there are any empty rows\nif (nrow(empty_rows) &gt; 0) {\n  cat(\"There are empty rows in the sf data tibble.\\n\")\n} else {\n  cat(\"There are no empty rows in the sf data tibble.\\n\")\n}\n\nThere are no empty rows in the sf data tibble.\n\n\nWe know that there are no empty rows from running this so we do not need to remove anything.\n\n\n2.3.1.5 mpsz check-in\nLet’s now check the properties of mpsz before moving on:\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR POLYGON ((33222.98 29588.13...\n2        CR POLYGON ((28481.45 30886.22...\n3        CR POLYGON ((28087.34 30541, 2...\n4        WR MULTIPOLYGON (((13919 22120...\n5        CR POLYGON ((29542.53 31041.2,...\n6        CR POLYGON ((35279.55 30886.05...\n7        WR MULTIPOLYGON (((17759.05 15...\n8        WR MULTIPOLYGON (((19713.94 19...\n9        CR MULTIPOLYGON (((28298.9 217...\n10       CR MULTIPOLYGON (((27524.76 24...\n\n\n\nclass(mpsz)\n\n[1] \"sf\"         \"data.frame\"\n\n\nWe know that mpsz now is a sf tibble data frame with 332 features and 2 fields with SVY21 as its coordinate reference system.\nLet’s plot it to see it visually also!\n\nplot(mpsz)\n\n\n\n\n\n\n2.3.1.6 Removal of internal boundaries\nIn this analysis, we also want just the singapore boundary so that we can see what grab taxis are within Singapore. We might not need all the internal breakup and boundaries and constantly using that might clog up processing power.\nHowever, there might be use cases where we need the mpsz object in sf type. So let’s save it first by assigning it to another variable:\n\nmpsz_sf &lt;- mpsz\n\nNow let’s remove the interal boudaries:\n\nmpsz &lt;- mpsz %&gt;%\n  st_union()\n\nLet’s plot mpsz now to see the external boundary:\n\nplot(mpsz)\n\n\n\n\nYay! We have got it.\n\n\n\n2.3.2 Road Data Set\n\n2.3.2.1 Coordinate Reference System\nLet us check the coordinate reference system.\n\nst_geometry(roads)\n\nGeometry set for 1765176 features \nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 99.66041 ymin: 0.8021131 xmax: 119.2601 ymax: 7.514393\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nWe can see it is not in EPSG:3414, therefore, we do a transformation to assign it the right code. We have explained why we do this under the mpsz section.\n\nroads &lt;- st_transform(roads, \n                              crs = 3414)\n\n\n\n2.3.2.2 Constriction of roads to Singapore\nThe data of the roads is related to roads in multiple countries on top of Singapore. Let us constrict it to just to have roads in Singapore as Singapore is our area of study.\nBesides, this will reduce the amount of data tremedously and allow the processing to be faster.\n\nroads_inSG &lt;- st_intersection(roads, mpsz)\n\n\n\n2.3.2.3 Validity Of Geometries\n\nlength(which(st_is_valid(roads_inSG) == FALSE))\n\n[1] 0\n\n\nLuckily, all geometries are validity!\n\n\n2.3.2.4 Missing Values\n\n# Use the filter function to check for empty rows\nempty_rows &lt;- roads_inSG %&gt;%\n  filter_all(all_vars(is.na(.)))\n\n# Check if there are any empty rows\nif (nrow(empty_rows) &gt; 0) {\n  cat(\"There are empty rows in the sf data tibble.\\n\")\n} else {\n  cat(\"There are no empty rows in the sf data tibble.\\n\")\n}\n\nThere are no empty rows in the sf data tibble.\n\n\nLuckily, there are no empty values again!\n\n\n\n2.3.3 Grab Posisi\nNow let’s wrangle the data of Grab posisi.\n\n2.3.3.1 Convert Data type\nHere we convert the int data type to date time data type. We are not using mutate, as we are over writing the data field in the file.\n\ngrab$pingtimestamp &lt;-as_datetime(grab$pingtimestamp)\n\n\n\n2.3.3.2 Origin Datapoints of Each Ride\nIn this data, the location and specifics of each car ride is sent to the server every minute. Here, we only want the data for the origin point for each ride. So let’s wrangle the data this way:\n\n#origin\ngrabOrigin &lt;- grab %&gt;% #use df\n  group_by(trj_id) %&gt;% #group according to trj_id\n  arrange(pingtimestamp) %&gt;% #sort according to timestamp asc (default)\n  filter(row_number()==1) %&gt;% #the first coordinate for every trip should be the origin\n  mutate(weekday = wday(pingtimestamp, label=TRUE, abbr=TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n2.3.3.2.1 Code Walkthrough\nLet me explain step by step so you understand this better!\ngrabOrigin &lt;- grab\nHere we take the data from the grab data and wrangle it and assign it to grabOrigin.\ngroup_by(trj_id)\nWhen we use group_by, we can group the different data records in the data by one column, in this case, trj_id. Here, each group will have rows with the same trj_id, meaning all of the rows in one group will relate to one trip.\narrange(pingtimestamp)\nHere in each group, we arrange all the rows according to the time stamp in an ascending order. Hence, the first row will be the origin location the grab taxi departs from.\nfilter(row_number()==1)\nFilter method is used to filter out the rows that match a criteria.\nHere, we take the first row only - only the origin location the taxi departs from matters.\nmutate(weekday = wday(pingtimestamp, label=TRUE, abbr=TRUE)\nMutate function can be used to create a new column. In this case, we create a column called weekday. The wday function extracts the weekday values from pingtimestamp. We fill the weekday column with the value generated by the wday function.\nstart_hr = factor(hour(pingtimestamp))\nHere, we create a column called start_hr. We use a function called hour to extract the hour from the pingtimestamp and then place it into the start_hr column.\nday = factor(mday(pingtimestamp)))\nHere, we create a column called day. We use a function called mday to extract the day of the month from the pingtimestamp and then place it into the day column.\nI hope the code is clearer now, and you understand how we get the origin data points of each ride.\n\n\n\n2.3.3.3 Destination Datapoints of Each Ride\nLet’s do almost the same to get the destination of each trip.\n\n# get end\ndestination_df &lt;- grab %&gt;% #use df\n  group_by(trj_id) %&gt;% #group according to trj_id\n  arrange(desc(pingtimestamp)) %&gt;% #sort according to timestamp asc (default)\n  filter(row_number()==1) %&gt;% #the first coordinate for every trip should be the origin\n  mutate(weekday = wday(pingtimestamp, label=TRUE, abbr=TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\nThe code is mostly the same except the arrange(desc()) where we arranged the rows descendingly\n\n\n2.3.3.4 Coordinate reference frame\n\ngrabOrigin &lt;- st_as_sf(grabOrigin, coords = c(\"rawlng\", \"rawlat\"), crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\ndestination_df &lt;- st_as_sf(destination_df, coords = c(\"rawlng\", \"rawlat\"), crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nAgain, we transform the coordinate reference system into SVY21.\nLet’s check if it’s been transformed correctly.\n\nst_geometry(grabOrigin) \n\nGeometry set for 28000 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3661.475 ymin: 25201.14 xmax: 49845.23 ymax: 49685.08\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\n\nst_geometry(destination_df)\n\nGeometry set for 28000 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3638.685 ymin: 25350.05 xmax: 50024.92 ymax: 49469.41\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nAnd both have been transformed well!\n\n\n2.3.3.5 Validity Of Geometries\n\nlength(which(st_is_valid(grabOrigin) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(destination_df) == FALSE))\n\n[1] 0\n\n\nLuckily all geometries are valid!\n\n\n2.3.3.6 Drop Z coordinate\n\ngrabOrigin &lt;- st_zm(grabOrigin)\n\n\ndestination_df &lt;- st_zm(destination_df)\n\n\n\n2.3.3.7 Create ppp objects\n\ngrabOriginPPP &lt;- as.ppp(grabOrigin)\n\n\ndestination_dfPP &lt;- as.ppp(destination_df)\n\n\nplot(grabOriginPPP)\n\n\n\n\nLet’s look at the summary statistics of the newly created ppp object\n\nsummary(grabOriginPPP)\n\nMarked planar point pattern:  28000 points\nAverage intensity 2.47621e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n    28000 character character \n\nWindow: rectangle = [3661.47, 49845.23] x [25201.14, 49685.08] units\n                    (46180 x 24480 units)\nWindow area = 1130760000 square units\n\n\n\nplot(destination_dfPP)\n\n\n\n\nLet’s look at the summary statistics of the newly created ppp object\n\nsummary(destination_dfPP)\n\nMarked planar point pattern:  28000 points\nAverage intensity 2.502667e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n    28000 character character \n\nWindow: rectangle = [3638.69, 50024.92] x [25350.05, 49469.41] units\n                    (46390 x 24120 units)\nWindow area = 1118810000 square units\n\n\n\n\n2.3.3.8 Handling duplicate points\nWe are looking at a huge area, and having multiple points in one area might make us miss important details.\nSo let us check if there are duplicate points.\n\nany(duplicated(grabOrigin))\n\n[1] FALSE\n\n\n\nany(duplicated(destination_df))\n\n[1] FALSE\n\n\n\n\n2.3.3.9 Conversion To Owin Objects\nWe do this to define the region we can do spatial point analysis in. Let’s take a refresher - the points are the locations of our grab taxis. So, in this case, we want to define Singapore as the region we execute spatial point analysis in.\n\nmpsz_owin &lt;- as.owin(mpsz)\n\n\ngrabOriginPPP_SG &lt;- grabOriginPPP[mpsz_owin]\n\n\ndestination_dfPPP_SG &lt;- destination_dfPP[mpsz_owin]"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#visualization-spatial-pattern-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#visualization-spatial-pattern-analysis",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "Visualization & Spatial Pattern Analysis",
    "text": "Visualization & Spatial Pattern Analysis\nLet’s plot some of our data to understand this better!\n\nLocation Visualizations\nHere we visualise the origin and destination locations of grab to understand them better!\n\nGrab origin in Singapore\nWe can see where the grabs rides generally start off from in Singapore.\n\ntmap_mode(\"plot\") \n    tm_shape(mpsz_sf) +\n    tm_polygons() +\n    tm_shape(grabOrigin) +\n    tm_dots()\n\n\n\n\n\n\nGrab destination in Singapore\nHere, we can see where the grab rides generally end in Singapore.\n\ntmap_mode(\"plot\") \n    tm_shape(mpsz_sf) +\n    tm_polygons() +\n    tm_shape(destination_df) +\n    tm_dots()\n\n\n\n\n\n\n\nSpatial Analysis\n\nNet outflow from northern Singapore\nThough not conclusive, from staring at the before and after pictures, we can see that there are lesser dots in the extreme east in the destination map than the origin map.\nLet’s prove this through code!\nThis was not done much in class and is new, but good for exploration!\nFirstly, get’s create a bounding box for the northern part of Singapore to extract the northern part of Singapore as we want to study it.\nLet’s extract the north region in Singapore\n\nnorth &lt;- mpsz_sf %&gt;% \n  filter(REGION_N == \"NORTH REGION\")\n\nLet’s see what “north” of singapore looks like:\n\nplot(north)\n\n\n\n\nNow let’s see the number of grab cars that are leaving the north:\n\ncarsOriginInNorth &lt;- st_intersection(grabOrigin, north)\n\nLet’s get the number now\n\ncarsOriginInNorth\n\nSimple feature collection with 4547 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 13681.67 ymin: 35382.98 xmax: 31339.97 ymax: 49685.08\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 4,547 × 17\n   trj_id driving_mode osname pingtimestamp       speed bearing accuracy weekday\n * &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;  &lt;dttm&gt;              &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt; &lt;ord&gt;  \n 1 14555  car          ios    2019-04-10 09:15:04 10.6      107     10   Wed    \n 2 79752  car          ios    2019-04-10 10:17:35  7.52      99      6   Wed    \n 3 77697  car          ios    2019-04-11 04:44:09  2.12     143     12   Thu    \n 4 10587  car          ios    2019-04-11 10:23:59  6.42     101      8   Thu    \n 5 45173  car          andro… 2019-04-11 13:08:29 12.0       85      3.9 Thu    \n 6 76870  car          ios    2019-04-12 06:19:28  7.31      96      6   Fri    \n 7 79546  car          andro… 2019-04-12 07:22:33 17.0       83      3.9 Fri    \n 8 66711  car          ios    2019-04-12 08:10:38 18.3       12      8   Fri    \n 9 35891  car          ios    2019-04-13 03:35:23  2.71     354      5   Sat    \n10 76149  car          andro… 2019-04-13 10:05:54 17.6       86      3.9 Sat    \n# ℹ 4,537 more rows\n# ℹ 9 more variables: start_hr &lt;fct&gt;, day &lt;fct&gt;, SUBZONE_N &lt;chr&gt;,\n#   SUBZONE_C &lt;chr&gt;, PLN_AREA_N &lt;chr&gt;, PLN_AREA_C &lt;chr&gt;, REGION_N &lt;chr&gt;,\n#   REGION_C &lt;chr&gt;, geometry &lt;POINT [m]&gt;\n\n\nWe can see 4547 cars are leaving the North\n\ntmap_mode(\"plot\") \n    tm_shape(north) +\n    tm_polygons() +\n    tm_shape(carsOriginInNorth) +\n    tm_dots()\n\n\n\n\nNow, let’s see the number of cars arriving to the north:\n\ncarsDestInNorth &lt;- st_intersection(destination_df, north)\n\nLet’s get the number now:\n\ncarsDestInNorth\n\nSimple feature collection with 4242 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 13369.5 ymin: 35350.07 xmax: 31403.56 ymax: 49469.41\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 4,242 × 17\n   trj_id driving_mode osname pingtimestamp       speed bearing accuracy weekday\n * &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;  &lt;dttm&gt;              &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt; &lt;ord&gt;  \n 1 69056  car          andro… 2019-04-21 05:02:36 13.2      348      3.9 Sun    \n 2 49387  car          ios    2019-04-21 04:21:53  4.07     283      8   Sun    \n 3 47116  car          ios    2019-04-20 10:42:37 14.4      280     10   Sat    \n 4 68012  car          andro… 2019-04-20 08:27:09 14.2      266      5   Sat    \n 5 10894  car          andro… 2019-04-18 11:50:43  0          0      3   Thu    \n 6 74071  car          andro… 2019-04-18 10:58:28 15.7      348      3.9 Thu    \n 7 9325   car          ios    2019-04-15 02:47:36  7.37     349      5   Mon    \n 8 80203  car          andro… 2019-04-11 18:29:44 17.3        3      4   Thu    \n 9 76951  car          ios    2019-04-21 23:47:07 10.3       26      6   Sun    \n10 19847  car          andro… 2019-04-21 23:40:18  8.20      26     11   Sun    \n# ℹ 4,232 more rows\n# ℹ 9 more variables: end_hr &lt;fct&gt;, day &lt;fct&gt;, SUBZONE_N &lt;chr&gt;,\n#   SUBZONE_C &lt;chr&gt;, PLN_AREA_N &lt;chr&gt;, PLN_AREA_C &lt;chr&gt;, REGION_N &lt;chr&gt;,\n#   REGION_C &lt;chr&gt;, geometry &lt;POINT [m]&gt;\n\n\nWe can see that 4242 cars are leaving the North\nLet’s see visually how it looks like:\n\ntmap_mode(\"plot\") \n    tm_shape(north) +\n    tm_polygons() +\n    tm_shape(carsDestInNorth) +\n    tm_dots()\n\n\n\n\nThough it may not be clear visually, we can see that more cars are leaving the North (4547) than they are going to the North (4242). That makes sense as the North is largely a residential area, and people generally live there more than work there. However, we notice that the difference isn’t too great, and that could be attributed to the fact that the north has slowly been developing many industrial estates that people might work at.\nOne issue with the data above is that there is a huge portion of area that is Considered “North” is not actually a region considered to be the north.\nRefer to the picture below:\n&lt;IMAGE&gt;\nThis area is the central catchment area, with parks and large bodies of water. When thinking of “North Of Singapore”, people generally do not consider the central catchment area as such. And nor is it a place people generally work and live at.\nSo let’s do a second round of analysis and remove it.\nFor this part, I have used this data : Master Plan 2019 Subzone Boundary (No Sea) from Data.gov.sg. I have not shown the import of wrangling of this data on this page, due to the lack of memory and processing space. However, you can wrangle this data the same way I have wrangled the current mpsz data!\nFirstly, get’s create a bounding box for the northern part of Singapore to extract the northern part of Singapore as we want to study it.\nThese coordinates are not random. I have found them on google maps by selecting points and some trial and error to correctly extract the northern area.\n\nNow, let’s convert the coordinate reference system of the bounding box to match that of mpsz_sf which is SVY21. After that, we will crop Singapore to just the area specified by the bounding box.\n\n\nAnd we have!\nNow, let’s see the intersection of grab locations when leaving the northern Singapore.\n\n\nHere we can see that our hypothesis is indeed correct. The number of cars starting at north was 3681 while the number of cars arriving at the north was 2838. The gap between the people leaving the North to coming to the north is much greater when i reduced the study area to areas actually relevent to peoplei n the north.\nThis aligns with common knowledge that the northern parts of Singapore are more residential, and in the mornings, people generally tend to leave the northern areas where they live to go to other parts of Singapore where they work."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#location-visualizations",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#location-visualizations",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.1 Location Visualizations",
    "text": "3.1 Location Visualizations\nHere we visualise the origin and destination locations of grab to understand them better!\n\n3.1.1 Grab origin in Singapore\nWe can see where the grabs rides generally start off from in Singapore.\n\ntmap_mode(\"plot\") \n    tm_shape(mpsz_sf) +\n    tm_polygons() +\n    tm_shape(grabOrigin) +\n    tm_dots()\n\n\n\n\n\n\n3.1.2 Grab destination in Singapore\nHere, we can see where the grab rides generally end in Singapore.\n\ntmap_mode(\"plot\") \n    tm_shape(mpsz_sf) +\n    tm_polygons() +\n    tm_shape(destination_df) +\n    tm_dots()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#spatial-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#spatial-analysis",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.2 Spatial Analysis",
    "text": "3.2 Spatial Analysis\n\n3.2.1 Net outflow from northern Singapore\n\n3.2.1.1 Method 1 of analysis\nThough not conclusive, from staring at the before and after pictures, we can see that there are lesser dots in the extreme east in the destination map than the origin map.\nLet’s prove this through code!\nThis was not done much in class and is new, but good for exploration!\nFirstly, get’s create a bounding box for the northern part of Singapore to extract the northern part of Singapore as we want to study it.\nLet’s extract the north region in Singapore\n\nnorth &lt;- mpsz_sf %&gt;% \n  filter(REGION_N == \"NORTH REGION\")\n\nLet’s see what “north” of Singapore looks like:\n\nplot(north)\n\n\n\n\n\nplot(north)\n\n\n\n\nNow let’s see the number of grab cars that are leaving the north:\n\ncarsOriginInNorth &lt;- st_intersection(grabOrigin, north)\n\n\ncarsOriginInNorth &lt;- st_intersection(grabOrigin, north)\n\nLet’s get the number now\n\ncarsOriginInNorth\n\nSimple feature collection with 4547 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 13681.67 ymin: 35382.98 xmax: 31339.97 ymax: 49685.08\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 4,547 × 17\n   trj_id driving_mode osname pingtimestamp       speed bearing accuracy weekday\n * &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;  &lt;dttm&gt;              &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt; &lt;ord&gt;  \n 1 14555  car          ios    2019-04-10 09:15:04 10.6      107     10   Wed    \n 2 79752  car          ios    2019-04-10 10:17:35  7.52      99      6   Wed    \n 3 77697  car          ios    2019-04-11 04:44:09  2.12     143     12   Thu    \n 4 10587  car          ios    2019-04-11 10:23:59  6.42     101      8   Thu    \n 5 45173  car          andro… 2019-04-11 13:08:29 12.0       85      3.9 Thu    \n 6 76870  car          ios    2019-04-12 06:19:28  7.31      96      6   Fri    \n 7 79546  car          andro… 2019-04-12 07:22:33 17.0       83      3.9 Fri    \n 8 66711  car          ios    2019-04-12 08:10:38 18.3       12      8   Fri    \n 9 35891  car          ios    2019-04-13 03:35:23  2.71     354      5   Sat    \n10 76149  car          andro… 2019-04-13 10:05:54 17.6       86      3.9 Sat    \n# ℹ 4,537 more rows\n# ℹ 9 more variables: start_hr &lt;fct&gt;, day &lt;fct&gt;, SUBZONE_N &lt;chr&gt;,\n#   SUBZONE_C &lt;chr&gt;, PLN_AREA_N &lt;chr&gt;, PLN_AREA_C &lt;chr&gt;, REGION_N &lt;chr&gt;,\n#   REGION_C &lt;chr&gt;, geometry &lt;POINT [m]&gt;\n\n\nWe can see 4547 cars are leaving the North\n\ntmap_mode(\"plot\") \n    tm_shape(north) +\n    tm_polygons() +\n    tm_shape(carsOriginInNorth) +\n    tm_dots()\n\n\n\n\nNow, let’s see the number of cars arriving to the north:\n\ncarsDestInNorth &lt;- st_intersection(destination_df, north)\n\nLet’s get the number now:\n\ncarsDestInNorth\n\nSimple feature collection with 4242 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 13369.5 ymin: 35350.07 xmax: 31403.56 ymax: 49469.41\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 4,242 × 17\n   trj_id driving_mode osname pingtimestamp       speed bearing accuracy weekday\n * &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;  &lt;dttm&gt;              &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt; &lt;ord&gt;  \n 1 69056  car          andro… 2019-04-21 05:02:36 13.2      348      3.9 Sun    \n 2 49387  car          ios    2019-04-21 04:21:53  4.07     283      8   Sun    \n 3 47116  car          ios    2019-04-20 10:42:37 14.4      280     10   Sat    \n 4 68012  car          andro… 2019-04-20 08:27:09 14.2      266      5   Sat    \n 5 10894  car          andro… 2019-04-18 11:50:43  0          0      3   Thu    \n 6 74071  car          andro… 2019-04-18 10:58:28 15.7      348      3.9 Thu    \n 7 9325   car          ios    2019-04-15 02:47:36  7.37     349      5   Mon    \n 8 80203  car          andro… 2019-04-11 18:29:44 17.3        3      4   Thu    \n 9 76951  car          ios    2019-04-21 23:47:07 10.3       26      6   Sun    \n10 19847  car          andro… 2019-04-21 23:40:18  8.20      26     11   Sun    \n# ℹ 4,232 more rows\n# ℹ 9 more variables: end_hr &lt;fct&gt;, day &lt;fct&gt;, SUBZONE_N &lt;chr&gt;,\n#   SUBZONE_C &lt;chr&gt;, PLN_AREA_N &lt;chr&gt;, PLN_AREA_C &lt;chr&gt;, REGION_N &lt;chr&gt;,\n#   REGION_C &lt;chr&gt;, geometry &lt;POINT [m]&gt;\n\n\nWe can see that 4242 cars are leaving the North\nLet’s see visually how it looks like:\n\ntmap_mode(\"plot\") \n    tm_shape(north) +\n    tm_polygons() +\n    tm_shape(carsDestInNorth) +\n    tm_dots()\n\n\n\n\nThough it may not be clear visually, we can see that more cars are leaving the North (4547) than they are going to the North (4242). That makes sense as the North is largely a residential area, and people generally live there more than work there. However, we notice that the difference isn’t too great, and that could be attributed to the fact that the north has slowly been developing many industrial estates that people might work at.\nOne issue with the data above is that there is a huge portion of area that is Considered “North” is not actually a region considered to be the north.\nRefer to the picture below:\n\nThis area is the central catchment area, with parks and large bodies of water. When thinking of “North Of Singapore”, people generally do not consider the central catchment area as such. And nor is it a place people generally work and live at.\nSo let’s do a second round of analysis and remove it.\n\n\n3.2.1.2 Method 2 of analysis\nFor this part, I have used this data : Master Plan 2019 Subzone Boundary (No Sea) from Data.gov.sg. I have not shown the import of wrangling of this data on this page, due to the lack of memory and processing space. However, you can wrangle this data the same way I have wrangled the current mpsz data!\nFirstly, get’s create a bounding box for the northern part of Singapore to extract the northern part of Singapore as we want to study it.\nThese coordinates are not random. I have found them on google maps by selecting points and some trial and error to correctly extract the northern area.\n\nNow, let’s convert the coordinate reference system of the bounding box to match that of mpsz_sf which is SVY21. After that, we will crop Singapore to just the area specified by the bounding box.\n\n\nAnd we have!\nNow, let’s see the intersection of grab locations when leaving the northern Singapore.\n\n\nHere we can see that our hypothesis is indeed correct. The number of cars starting at north was 3681 while the number of cars arriving at the north was 2838. The gap between the people leaving the North to coming to the north is much greater when i reduced the study area to areas actually relevent to peoplei n the north.\nThis aligns with common knowledge that the northern parts of Singapore are more residential, and in the mornings, people generally tend to leave the northern areas where they live to go to other parts of Singapore where they work."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#computing-kde-with-automatic-bandwidth",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#computing-kde-with-automatic-bandwidth",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.1 Computing KDE with automatic bandwidth",
    "text": "3.1 Computing KDE with automatic bandwidth\nWe use automatic bandwidths in this section, where the base of each hill is of different size. Automatic bandwidths can be good in areas where points are really clustered to one another. Hence, sublocations with more points can have smaller based hills to detect small nuanced changes in density. This detection might not be possible if all hills had the same sized hill bases, as the tiny differences in density can be missed out.\n\n3.1.1 Computing KDE with automatic bandwidth and gaussian kernel\nThere are different ways to calculate the automatic bandwidth. Let’s try some of them/\n\n3.1.1.1 Using bw.diggle()\nHere we calculate the density of grabs that are just leaving their location.\n\ngrabOriginPPP_SG_km &lt;- rescale(grabOriginPPP_SG, 1000, \"km\")\n\nkde_grabOriginSG_bw_gaus &lt;- density(grabOriginPPP_SG_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\n\nplot(kde_grabOriginSG_bw_gaus)\n\n\n\n\nHere we calculate the density of grabs that are just arriving to their location.\n\ngrabDestinationPPP_SG &lt;- rescale(destination_dfPPP_SG, 1000, \"km\")\nkde_grabDestSG_bw_gaus &lt;- density(grabDestinationPPP_SG,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\")\n\n\npar(mfrow = c(1, 1), mar = c(1, 1, 2, 2))\nplot(kde_grabDestSG_bw_gaus)\n\n\n\n\nThe southern part of Singapore is more dense with grab cars as their destination, than their origin. This means that more cars come to the southern part of Singapore than they leave, and that makes sense as the CBD is located there, and a lot of workplaces are situated there. Many people would come to the CBD to work daily, leading to the high densities.\n\n\n3.1.1.1 Using bw.CvL()\n\nbw.CvL(grabOriginPPP_SG)\n\n   sigma \n6801.213 \n\n\n\n\n3.1.1.2 Using bw.scott()\n\nbw.scott(grabOriginPPP_SG) \n\n  sigma.x   sigma.y \n1587.8068  935.0244 \n\n\n\n\n3.1.1.3 Using bw.ppl()\n\nbw.ppl(grabOriginPPP_SG)\n\n   sigma \n382.9118 \n\n\n\nkde_grabOriginSG_ppl_gaus &lt;-  density(grabOriginPPP_SG_km, sigma=bw.ppl, edge=TRUE, kernel=\"gaussian\")\n\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\nplot(kde_grabOriginSG_bw_gaus, main = \"bw.diggle\")\n\n\n\nplot(kde_grabOriginSG_ppl_gaus, main = \"bw.ppl\")\n\n\n\n\nWe can see that the densities are more clearly marked when using bw.ppl than when using bw.diggle. This is because the bandwidth, or the base of the hill is much smaller. Hence, the nuances and differences in densities can be more easily picked up.\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. \n\n\n\n3.1.2 Computing KDE with automatic bandwidth and various kernels\nAS mentioned before, when we use various kernels, we are using different methods to smoothen out the hill to ensure that the differences between two hills aren’t too sharp.\nThe quartic kernel makes a flat disc-shaped hill, only considering points close to each other.\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\n\nplot(density(grabOriginPPP_SG_km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\n\n\n\nThe quartic kernel is similar to epanechnikov the but makes wider hills.\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\n\nplot(density(grabOriginPPP_SG_km,\n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\n\n\n\nThe Gaussian kernel is smooth and assigns higher weights to nearby points.\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\n\n\n\nplot(density(grabOriginPPP_SG_km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\n\n\n\n\nhe Disc kernel treats all points within a certain distance equally, making a simple, flat circle around each point.\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\nplot(density(grabOriginPPP_SG_km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#comparing-spatial-point-patterns-using-kde",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#comparing-spatial-point-patterns-using-kde",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.2 Comparing Spatial Point Patterns using KDE",
    "text": "3.2 Comparing Spatial Point Patterns using KDE\n\n3.2.1 Extracting study areas\nFrom our analysis before, we could see that the southern part of Singapore was highly populated due to the CBD and numerous other workplaces. However, we could only see a high level picture of it, now, let’s dive a little deeper and see which areas in the southern part of Singapore were more densely populated with grab cars then the others.\nBy analysing this, we can somewhat deduce which areas have more workplaces than others!\n\ndowntown_core &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"DOWNTOWN CORE\")\nriver_valley &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"RIVER VALLEY\")\norchard &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"ORCHARD\")\n\n\nplot(st_geometry(downtown_core), main = \"downtown_core\")\n\n\n\n\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\nplot(st_geometry(river_valley), main = \"river_valley\")\n\n\n\n\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\nplot(st_geometry(orchard), main = \"orchard\")\n\n\n\n\n\n\n3.2.2 Combining grab points and the study areas\n\n3.2.2.1 Create Owin Object\n\ndowntown_core &lt;- as.owin(downtown_core)\n\n\norchard &lt;- as.owin(orchard)\n\n\nriver_valley &lt;- as.owin(river_valley)\n\n\n\n3.2.2.2 Combination\nHere , we are deriving the points that would be located in each of the locations.\n\ngrabDestinationPPP_downtown &lt;- destination_dfPP[downtown_core]\ngrabDestinationPPP_orchard &lt;- destination_dfPP[orchard]\ngrabDestinationPPP_river &lt;- destination_dfPP[river_valley]\n\nLet’s rescale it, as the default was in meters.\n\ngrabDestinationPPP_downtown = rescale(grabDestinationPPP_downtown, 1000, \"km\")\ngrabDestinationPPP_orchard = rescale(grabDestinationPPP_orchard, 1000, \"km\")\ngrabDestinationPPP_river = rescale(grabDestinationPPP_river, 1000, \"km\")\n\n\n\n3.2.2.3 Plot points\nHere, we just plot the points of grab cars arriving. Later, we will plot the KDE.\nHere we plot grab cars arriving in downtown.\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\nplot(grabDestinationPPP_downtown)\n\n\n\n\nHere we plot grab cars arriving in orchard.\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\nplot(grabDestinationPPP_orchard)\n\n\n\n\nHere we plot grab cars arriving in river valley.\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\nplot(grabDestinationPPP_river)\n\n\n\n\nWhen conducting analysis in a more granular way, we get to see two things\n\nThe differences in grab cars , and by extension workplaces, between different areas in southern Singapore\n\nWe can see from these images that downtown is the more popular location in all of the southern parts of singapore that we have analysed.\n\nWe see the distribution of grab cars within each area itself, telling us which locations are more popular, or have drop offs.\n\nFor example, in Orchard, we can see that the borders of Orchard are more popular.\n\n\n\n\n\n3.2.3 KDE in central areas\nNow let’s compute and plot the KDE in different areas in southern Singapore. This can give us a better idea of the distribution of grab car destinations.\nLet’s calculate KDE for downtown.\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\nplot(density(grabDestinationPPP_downtown, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Downtown\")\n\n\n\n\nLet’s calculate KDE for orchard.\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\nplot(density(grabDestinationPPP_orchard, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Orchard\")\n\n\n\n\nLet’s calculate KDE for river valley.\n\npar(mfrow = c(1, 1), mar = c(1, 1, 1, 1))\nplot(density(grabDestinationPPP_river, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"River Valley\")\n\n\n\n\n#from here\n\n\n3.2.4 Converting KDE output into raster format\nWhy do we do this?\nThis is mainly just for mapping purposes. Conversion into raster format allows us to visualise the KDE in a pixelated format, allowing us to better understand spatial point patterns.\n\nkde_grabOriginSG_ppl_gaus_conv &lt;- as.SpatialGridDataFrame.im(kde_grabOriginSG_ppl_gaus) \n\n\nspplot(kde_grabOriginSG_ppl_gaus_conv)\n\n\n\n\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_grabOriginSG_ppl_gaus_conv &lt;- raster(kde_grabOriginSG_ppl_gaus_conv)\n\nLet’s look at the gridded kernel desnity object\n\nkde_grabOriginSG_ppl_gaus_conv\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.419757, 0.2695907  (x, y)\nextent     : 2.667538, 56.39644, 15.74872, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.533748e-14, 845.4849  (min, max)\n\n\nNotice that the CRS is NA so lets’ set it to SVY21. Remember, we convert everything to the same coordinate reference system!\n\nprojection(kde_grabOriginSG_ppl_gaus_conv) &lt;- CRS(\"+init=EPSG:3414\")\n\n\n\n3.2.5 Displaying KDE on open streetmap of Singapore\n\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(kde_grabOriginSG_ppl_gaus_conv) +\n  tm_raster(\"v\", palette = \"PuRd\", alpha=0.65) + \n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            main.title = \"Grab's Origin KDE \",\n            frame = FALSE)\n\n\n\n\nFrom this, we know that the areas we could be more interested in are the East. the sourthern part of Singapore and Northern part of Singapore. We see that the densities are higher there."
  },
  {
    "objectID": "data/MPSZ-2019.html",
    "href": "data/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#extracting-study-areas-1",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#extracting-study-areas-1",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "4.1 Extracting study areas",
    "text": "4.1 Extracting study areas\nAs mentioned before there are only three areas we are concerned with ar the moment. This is also better for processing and memory power and we do not have to load and process the entire roads dataset.\n\n4.1.1 Extracting the North\n\n4.1.1.1 Extracting the North from mpsz\nHere, we are extracting the north from mpsz. Thankfully we already have it from previous processing. Let’s print it.\n\nnorth\n\nSimple feature collection with 41 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 12386.29 ymin: 35330.11 xmax: 32377.19 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C              PLN_AREA_N PLN_AREA_C\n1                 PANG SUA    SKSZ04            SUNGEI KADUT         SK\n2                   KHATIB    YSSZ08                  YISHUN         YS\n3              MANDAI WEST    MDSZ01                  MANDAI         MD\n4             YISHUN SOUTH    YSSZ04                  YISHUN         YS\n5            LOWER SELETAR    YSSZ05                  YISHUN         YS\n6            MANDAI ESTATE    MDSZ03                  MANDAI         MD\n7           YISHUN CENTRAL    YSSZ01                  YISHUN         YS\n8                GALI BATU    SKSZ03            SUNGEI KADUT         SK\n9               SPRINGLEAF    YSSZ06                  YISHUN         YS\n10 CENTRAL WATER CATCHMENT    CCSZ01 CENTRAL WATER CATCHMENT         CC\n       REGION_N REGION_C                       geometry\n1  NORTH REGION       NR POLYGON ((19156.47 44276.42...\n2  NORTH REGION       NR POLYGON ((27819.05 44960.39...\n3  NORTH REGION       NR POLYGON ((24684.68 44271.39...\n4  NORTH REGION       NR POLYGON ((29187.4 44991.3, ...\n5  NORTH REGION       NR POLYGON ((30918.91 45252.69...\n6  NORTH REGION       NR POLYGON ((27119.56 45071.12...\n7  NORTH REGION       NR POLYGON ((28293.43 44966.31...\n8  NORTH REGION       NR POLYGON ((21410.16 41655.28...\n9  NORTH REGION       NR POLYGON ((27253.37 41646.98...\n10 NORTH REGION       NR POLYGON ((25073.29 43675.36...\n\n\n\n\n4.1.1.2 Extracting the roads in the North\nNow, let’s get the roads in the north.\n\nroads_inNorth &lt;- st_intersection(roads, north)\n\n\n\n4.1.1.3 Extracting the grab origin points in the North\n\ngrabO_inNorth &lt;- st_intersection(grabOrigin, north)\n\n\n\n\n4.1.2 Extracting the East\n\n4.1.2.1 Extracting the East from mpsz\nHere, we are extracting the east from mpsz.\n\neast &lt;- mpsz_sf %&gt;% \n  filter(REGION_N == \"EAST REGION\")\n\n\n\n4.1.2.2 Extracting the roads in the East\nNow, let’s get the roads in the east.\n\nroads_inEast &lt;- st_intersection(roads, east)\n\n\n\n4.1.2.3 Extracting the grab origin points in the East\n\ngrabO_inEast &lt;- st_intersection(grabOrigin, east)\n\n\n\n\n4.1.3 Extracting the Downtown core\n\n4.1.3.1 Extracting the downtown core from mpsz\nHere, we are extracting the downtown core from mpsz.\n\ndowntown_core &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"DOWNTOWN CORE\")\n\n\n\n4.1.3.2 Extracting the roads in the Downtown core\nNow, let’s get the roads in the Downtown core\n\nroads_inDowntown &lt;- st_intersection(roads, downtown_core)\n\n\n\n4.1.3.3 Extracting the grab origin points in the Downtown core\n\ngrabO_in_downtown_core &lt;- st_intersection(grabOrigin, downtown_core)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#deriving-the-network-constrained-kde-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#deriving-the-network-constrained-kde-analysis",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "4.2 Deriving the network constrained KDE Analysis",
    "text": "4.2 Deriving the network constrained KDE Analysis\n\n4.2.1 Deriving KDE in the East\n\n4.2.1.1 Preparing the lixels objects\nThis code snippet means that the roads in the east must be cut into segments, with each of them being at 700m in length, and the minimum length a segment can be is 350m.\n\nroads_inEast &lt;- roads_inEast %&gt;%\n  st_sf() %&gt;%\n  st_cast(\"LINESTRING\")\nlixelsEast &lt;- lixelize_lines(roads_inEast, \n                         700, \n                         mindist = 350)\n\n\n\n4.2.1.2 Generating line centre points\nThis code is intended to generate the center points of the lixels using the lines_center function. These central points are used for netKDE.\n\nsamplesEast &lt;- lines_center(lixelsEast)\n\n\n\n4.2.1.3 Performing netKDE\n\ndensities &lt;- nkde(roads_inEast, \n                  events = grabO_inEast,\n                  w = rep(1,nrow(grabO_inEast)),\n                  samples = samplesEast,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n4.2.2 Deriving KDE in the North\n\n4.2.2.1 Preparing the lixels objects\n\nroads_inNorth &lt;- roads_inNorth %&gt;%\n  st_sf() %&gt;%\n  st_cast(\"LINESTRING\")\n\nlixelsNorth &lt;- lixelize_lines(roads_inNorth, \n                         700, \n                         mindist = 350)\n\n\n\n4.2.2.2 Generating line centre points\n\nsamplesNorth &lt;- lines_center(lixelsNorth)\n\n\n\n4.2.2.3 Performing netKDE\n\ndensitiesNorth &lt;- nkde(roads_inNorth, \n                  events = grabO_inNorth,\n                  w = rep(1,nrow(grabO_inNorth)),\n                  samples = samplesNorth,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n4.2.3 Deriving KDE in the Downtown\n\n4.2.2.1 Preparing the lixels objects\n\nroads_inDowntown &lt;- roads_inDowntown %&gt;%\n  st_sf() %&gt;%\n  st_cast(\"LINESTRING\")\nlixelsDowntown&lt;- lixelize_lines(roads_inDowntown, \n                         700, \n                         mindist = 350)\n\n\n\n4.2.2.3 Generating line centre points\n\nsamplesDowntown &lt;- lines_center(lixelsDowntown)\n\n\n\n4.2.2.4 Performing netKDE\n\ndensitiesDown &lt;- nkde(roads_inDowntown, \n                  events = grabO_in_downtown_core,\n                  w = rep(1,nrow(grabO_in_downtown_core)),\n                  samples = samplesDowntown,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#visualising-nkde",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#visualising-nkde",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "4.3 Visualising nKDE",
    "text": "4.3 Visualising nKDE\n\n4.3.1 Visualising nKDE for Southern/Downtown of Singapore\nBefore we can visualise the NetKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamplesDowntown$density &lt;- densitiesDown\nsamplesDowntown$density &lt;- densitiesDown\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. The code chunk below is used to resale the density values from number of events per meter to number of events per kilometer.\n\n# rescaling to help the mapping\nsamplesDowntown$density &lt;- samplesDowntown$density*1000\nsamplesDowntown$density &lt;- samplesDowntown$density*1000\n\n\n#tmap_mode('plot')   \n#tm_shape(lixelsDowntown)+\n  #tm_lines(col=\"density\")+\n # tm_shape(grabO_in_downtown_core)+\n  #tm_dots()\n\n\n\n4.3.2 Visualising nKDE for North of Singapore\nBefore we can visualise the NetKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamplesNorth$density &lt;- densitiesNorth\nsamplesNorth$density &lt;- densitiesNorth\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. The code chunk below is used to resale the density values from number of events per meter to number of events per kilometer.\n\n# rescaling to help the mapping\nsamplesNorth$density &lt;- samplesNorth$density*1000\nsamplesNorth$density &lt;- samplesNorth$density*1000\n\n\n#tmap_mode('plot')\n#tm_shape(lixelsNorth)+\n # tm_lines(col=\"density\")+\n#tm_shape(grabO_inNorth)+\n # tm_dots()\n\n\n\n4.3.3 Visualising nKDE for East of Singapore\nBefore we can visualise the NetKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamplesEast$density &lt;- densities\nlixelsEast$density &lt;- densities\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. The code chunk below is used to resale the density values from number of events per meter to number of events per kilometer.\n\n# rescaling to help the mapping\nsamplesEast$density &lt;- samplesEast$density*1000\nlixelsEast$density &lt;- lixelsEast$density*1000\n\n\ntmap_mode('plot')\ntm_shape(lixelsEast)+\n  tm_lines(col=\"density\")+\ntm_shape(grabO_inEast)+\n  tm_dots()"
  }
]