[
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "",
    "text": "For my project, we will be exploring the distribution of healthcare facilities in Cambodia. My team consists of ViddyaSri and I, and I will be focusing on the exploratory data analysis portion of the project.\nIn this take home exercise, I will be writing down all the codes needed to derive the maps to be plotted in the final Shiny application. I will also be attaching the UI prototype."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#overview-of-data-used",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#overview-of-data-used",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Overview of data used",
    "text": "Overview of data used\n\nBoundary data\nWe have different levels of the boundary data.\n\n\n\n\n\n\n\n\nName\nDescription\nType\n\n\n\n\nKHM_adm1\nThis data shows the entirety of Cambodia, split by provinces.\nshp\n\n\nKHM_adm2\nThis data shows the entirety of Cambodia, split by districts.\nshp\n\n\nKHM_adm3\nThis data shows the entirety of Cambodia, split by communes.\nshp\n\n\nKHM_adm4\nThis data shows the entirety of Cambodia, split by villages.\nshp\n\n\n\n\n\nHealthcare data\nWe have different levels of the boundary data.\n\n\n\n\n\n\n\n\nName\nDescription\nType\n\n\n\n\nHealth center\nThis data shows the distribution of health center facilities across Cambodia.\nshp\n\n\nHealth post\nThis data shows the distribution of health post facilities across Cambodia.\nshp\n\n\nNational hospital\nThis data shows the distribution of national hospital facilities across Cambodia.\nshp\n\n\nReferral Hospital\nThis data shows the distribution of referral hospital facilities across Cambodia.\nshp\n\n\n\n\n\nRoads\n\n\n\nName\nDescription\nType\n\n\n\n\nRoads\nThis shows the various roads around Cambodia.\ngpkg"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#boundary-data-1",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#boundary-data-1",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Boundary Data",
    "text": "Boundary Data\nLet’s import the data now.\n\nImporting boundary data\n\nProvince LayerDistrict LayerCommune LayerVillage Layer\n\n\n\nprovince_sf &lt;- st_read(dsn = \"data/boundary/level1\", \n                layer = \"KHM_adm1\")\n\nReading layer `KHM_adm1' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\boundary\\level1' \n  using driver `ESRI Shapefile'\nSimple feature collection with 25 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 102.3355 ymin: 9.91361 xmax: 107.63 ymax: 14.68817\nGeodetic CRS:  WGS 84\n\n\n\n\n\ndistrict_sf &lt;- st_read(dsn = \"data/boundary/level2\", \n                layer = \"KHM_adm2\")\n\nReading layer `KHM_adm2' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\boundary\\level2' \n  using driver `ESRI Shapefile'\nSimple feature collection with 178 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 102.3355 ymin: 9.91361 xmax: 107.63 ymax: 14.68817\nGeodetic CRS:  WGS 84\n\n\n\n\n\ncommune_sf &lt;- st_read(dsn = \"data/boundary/level3\", \n                layer = \"KHM_adm3\")\n\nReading layer `KHM_adm3' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\boundary\\level3' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1576 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 102.3355 ymin: 9.91361 xmax: 107.63 ymax: 14.68817\nGeodetic CRS:  WGS 84\n\n\n\n\n\nvillage_sf &lt;- st_read(dsn = \"data/boundary/level4\", \n                layer = \"KHM_adm4\")\n\nReading layer `KHM_adm4' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\boundary\\level4' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1580 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 102.3355 ymin: 9.91361 xmax: 107.63 ymax: 14.68817\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\nHandle Invalid Geometry\n\nProvinceDistrictCommuneVillage\n\n\n\nlength(which(st_is_valid(province_sf) == FALSE))\n\n[1] 0\n\n\nThere are no invalid geometries!\n\n\n\nlength(which(st_is_valid(district_sf) == FALSE))\n\n[1] 0\n\n\nThere are no invalid geometries.\n\n\n\nlength(which(st_is_valid(commune_sf) == FALSE))\n\n[1] 0\n\n\n\n\n\nlength(which(st_is_valid(village_sf) == FALSE))\n\n[1] 0\n\n\n\n\n\nLuckily we have no invalid geometries for the boundary layer.\n\n\nProjection of Data\n\nProvince LayerDistrict LayerCommune LayerVillage Layer\n\n\n\nprovince_sf &lt;- st_transform(province_sf, 32648)\nst_crs(province_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32648 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 48N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 48N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",105,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\"],\n        BBOX[0,102,84,108]],\n    ID[\"EPSG\",32648]]\n\n\n\n\n\ndistrict_sf &lt;- st_transform(district_sf, 32648)\nst_crs(district_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32648 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 48N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 48N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",105,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\"],\n        BBOX[0,102,84,108]],\n    ID[\"EPSG\",32648]]\n\n\n\n\n\ncommune_sf &lt;- st_transform(commune_sf, 32648)\nst_crs(commune_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32648 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 48N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 48N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",105,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\"],\n        BBOX[0,102,84,108]],\n    ID[\"EPSG\",32648]]\n\n\n\n\n\nvillage_sf &lt;- st_transform(village_sf, 32648)\nst_crs(village_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32648 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 48N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 48N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",105,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\"],\n        BBOX[0,102,84,108]],\n    ID[\"EPSG\",32648]]\n\n\n\n\n\n\n\nPlotting Of Data\nLet’s plot the data!\n\nProvinceDistrictCommuneVillage\n\n\n\ntmap_mode('plot')\ntm_shape(province_sf) + \n  tm_polygons(col = \"#F0E1D7\", alpha = 0.5)\n\n\n\n\n\n\n\ntmap_mode('plot')\ntm_shape(district_sf) + \n  tm_polygons(col = \"#F0E1D7\", alpha = 0.5)\n\n\n\n\n\n\n\ntmap_mode('plot')\ntm_shape(commune_sf) + \n  tm_polygons(col = \"#F0E1D7\", alpha = 0.5)\n\n\n\n\n\n\n\ntmap_mode('plot')\ntm_shape(village_sf) + \n  tm_polygons(col = \"#F0E1D7\", alpha = 0.5)\n\n\n\n\n\n\n\n\n\nCreating Cambodia boundary\n\ncambodia_sf &lt;- province_sf %&gt;%\n  st_union() \n\n\nplot(cambodia_sf, main = \"Cambodia Boundary Layer\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#healthcare-data-1",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#healthcare-data-1",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Healthcare Data",
    "text": "Healthcare Data\n\nImporting healthcare data\n\nhealthposthealthcenternational hospitalreferral hospital\n\n\n\npoints_healthpost &lt;- st_read(dsn = \"data/healthpost\", \n                layer = \"healthpost\")\n\nReading layer `healthpost' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\healthpost' \n  using driver `ESRI Shapefile'\nSimple feature collection with 89 features and 12 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 247772 ymin: 1190286 xmax: 762122.8 ymax: 1591629\nProjected CRS: WGS 84 / UTM zone 48N\n\n\n\n\n\npoints_healthcenter &lt;- st_read(dsn = \"data/healthcenter\", \n                layer = \"healthcenter\")\n\nReading layer `healthcenter' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\healthcenter' \n  using driver `ESRI Shapefile'\nSimple feature collection with 956 features and 13 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 213103.9 ymin: 1155396 xmax: 764437 ymax: 1594142\nProjected CRS: WGS 84 / UTM zone 48N\n\n\n\n\n\npoints_nationalhospital &lt;- st_read(dsn = \"data/nationalhospital\", \n                layer = \"national_hospital_en\")\n\nReading layer `national_hospital_en' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\nationalhospital' \n  using driver `ESRI Shapefile'\nSimple feature collection with 9 features and 14 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 376678.3 ymin: 1276217 xmax: 491651.7 ymax: 1478968\nProjected CRS: WGS 84 / UTM zone 48N\n\n\n\n\n\npoints_referralhospital &lt;- st_read(dsn = \"data/referralhospital\", \n                layer = \"hltfacp_referral\")\n\nReading layer `hltfacp_referral' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\referralhospital' \n  using driver `ESRI Shapefile'\nSimple feature collection with 76 features and 12 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 216012.9 ymin: 1158852 xmax: 737796 ymax: 1573927\nProjected CRS: WGS 84 / UTM zone 48N\n\n\n\n\n\n\n\nData preperation\nHere we attach a column called category to each data table, and categorise it. We do this so that when we combine the data into one data variable, we will know what the category of each hospital facility is.\n\npoints_healthcenter &lt;- points_healthcenter %&gt;% mutate(CATEGORY = \"Health Center\")\npoints_healthpost &lt;- points_healthpost %&gt;% mutate(CATEGORY = \"Health Post\")\npoints_referralhospital &lt;- points_referralhospital %&gt;% mutate(CATEGORY = \"Referral Hospital\")\npoints_nationalhospital &lt;- points_nationalhospital %&gt;% mutate(CATEGORY = \"National Hospital\")\n\nLet’s remove the COVERNAME column as there are NAs in the column.\n\npoints_healthcenter &lt;- subset(points_healthcenter, select = -COVERNAME)\n\nLet’s make all he column names uppercase\n\nst_geometry(points_nationalhospital) &lt;- \"geometry\"\n\n# Get the names of all columns except the geometry column\ncolumn_names &lt;- names(points_nationalhospital)[!grepl(\"^geometry$\", names(points_nationalhospital))]\n\n# Convert column names to uppercase\ncolumn_names_upper &lt;- toupper(column_names)\n\n# Replace column names in the sf object\nnames(points_nationalhospital)[!grepl(\"^geometry$\", names(points_nationalhospital))] &lt;- column_names_upper\n\n\n# Drop columns \"BUILDING\", \"STREET\", \"WEB\", \"REFERENCE\", \"LAT\", \"LONG\", and \"LANGUAGE\"\npoints_nationalhospital &lt;- subset(points_nationalhospital, select = -c(BUILDING, STREET, WEB, REFERENCE, LAT, LONG, LANGUAGE))\n\npoints_nationalhospital$DCODE &lt;- NA\npoints_nationalhospital$CCODE &lt;- NA\npoints_nationalhospital$VCODE &lt;- NA\npoints_nationalhospital$ODCODE &lt;- NA\npoints_nationalhospital$ODNAME &lt;- NA\n\n# Rearrange the columns\npoints_nationalhospital &lt;- points_nationalhospital[, c(\"PCODE\", \"PNAME\", \"DCODE\", \"DNAME\", \"CCODE\", \"CNAME\", \"VCODE\", \"VNAME\", \"ODCODE\", \"ODNAME\", \"FACILITCOD\", \"FACILITNAM\", \"CATEGORY\", \"geometry\")]\n\n\npoints_facilities &lt;- rbind(points_healthcenter, points_healthpost, points_referralhospital, points_nationalhospital)\n\n\npoints_facilities$PNAME &lt;- gsub(\"Banteay Mean Chey\", \"Banteay Meanchey\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Battambang\", \"Batdambang\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Battam Bang\", \"Batdambang\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Kampong Speu\", \"Kampong Spoe\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Kampong Spueu\", \"Kampong Spoe\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Kampong Thom\", \"Kampong Thum\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Koh Kong\", \"Kaoh Kong\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Kratie\", \"Kracheh\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Pailin\", \"Krong Pailin\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Sihanoukville\", \"Krong Preah Sihanouk\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Sihaknouk Vill\", \"Krong Preah Sihanouk\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Mondul Kiri\", \"Mondol Kiri\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Oddor Meanchey\", \"Otdar Mean Chey\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Oddar Mean chey\", \"Otdar Mean Chey\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Oddar Meanchey\", \"Otdar Mean Chey\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Pursat\", \"Pouthisat\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Ratanak Kiri\", \"Rotanokiri\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Siemreap\", \"Siemreab\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Siem Reap\", \"Siemreab\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Stung  Treng\", \"Stoeng Treng\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Stung Treng\", \"Stoeng Treng\", points_facilities$PNAME)\npoints_facilities$PNAME &lt;- gsub(\"Takeo\", \"Takev\", points_facilities$PNAME)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#road-data",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#road-data",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Road Data",
    "text": "Road Data\n\nImporting Road Data\n\ncam_road_sf &lt;- st_read(\"data/roads/osm_road_2022_1641440547.gpkg\")\n\nReading layer `osm_road_2022_1641440547' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Take-Home_Ex\\Take-Home_Ex03\\data\\roads\\osm_road_2022_1641440547.gpkg' \n  using driver `GPKG'\nSimple feature collection with 169682 features and 15 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 102.3415 ymin: 10.42264 xmax: 107.6128 ymax: 14.69023\nGeodetic CRS:  WGS 84\n\n\n\n\nHandle Invalid Geometry\n\nlength(which(st_is_valid(cam_road_sf) == FALSE))\n\n[1] 0\n\n\n\n\nProjection\n\ncam_road_sf &lt;- st_transform(cam_road_sf, 32648)\nst_crs(cam_road_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32648 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 48N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 48N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",105,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\"],\n        BBOX[0,102,84,108]],\n    ID[\"EPSG\",32648]]\n\n\nPlot Road Network on Boundary Layer:\n\ntmap_mode('plot')\ntm_shape(cambodia_sf) + \n  tm_polygons(col = \"#F0E1D7\", alpha = 0.5) + \n  tm_shape(cam_road_sf) +\n  tm_lines(lwd = 0.05, col = \"#2B2B2B\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#total-number-of-healthcare-facilities-in-cambodia",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#total-number-of-healthcare-facilities-in-cambodia",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Total number of healthcare facilities in Cambodia",
    "text": "Total number of healthcare facilities in Cambodia\n1130"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#facility-type-breakdown",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#facility-type-breakdown",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Facility type breakdown",
    "text": "Facility type breakdown\n\n\n\n\n\n\n\n\n\nHealth centers\nHealth posts\nNational Hospital\nReferral Hospitals\n\n\n965\n89\n9\n76"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#cambodias-region-breakdown",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#cambodias-region-breakdown",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Cambodia’s region breakdown",
    "text": "Cambodia’s region breakdown\n\n\n\nProvinces\nDistricts\nCommunes\nVillages\n\n\n\n\n25\n178\n1576\n1580"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#breakdown-of-regions-with-highest-number-of-facilities",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#breakdown-of-regions-with-highest-number-of-facilities",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Breakdown of regions with highest number of facilities",
    "text": "Breakdown of regions with highest number of facilities\nThis code finds out which village, district, province and commune each health facility is part of.\n\n\n\n\n\n\nNote\n\n\n\nIn this code below, we go through each of hospital facilities in points_facilities and categorise them to the province, district, commune and village they belong to. There are some villages that do not have their own identifiable name, though they are distinct places with their own geometry column. Through our research we have realised that, ID_4 in village_sf is a distinct primary key column identifying each village. Hence, we will be replacing the villages with no names, with their distinct ID_4 values\n\n\n\n# Load necessary library\nlibrary(sf)\n\n\n# Create a subset of the first 5 rows for points_facilities\npoints_facilities_2 &lt;- points_facilities\n\n# Add new columns for administrative area names\npoints_facilities_2$province_name &lt;- NA\npoints_facilities_2$district_name &lt;- NA\npoints_facilities_2$commune_name &lt;- NA\npoints_facilities_2$village_name &lt;- NA\n\n# Iterate over each row in points_facilities_2\nfor (i in 1:nrow(points_facilities_2)) {\n  # Extract the current point\n  current_point &lt;- points_facilities_2[i, ]\n  \n  # Perform spatial join to find the village polygon that contains the current point\n  matched_village &lt;- village_sf[st_within(current_point, village_sf, sparse = FALSE), ]\n  \n  # Check if a match was found\n  if (nrow(matched_village) &gt; 0) {\n    # If a match was found, update the administrative area names for the current point\n    points_facilities_2$province_name[i] &lt;- matched_village$NAME_1[1]\n    points_facilities_2$district_name[i] &lt;- matched_village$NAME_2[1]\n    points_facilities_2$commune_name[i] &lt;- matched_village$NAME_3[1]\n    \n    # Check if the village name (NAME_4) is NA; if so, use ID_4 instead\n    if (is.na(matched_village$NAME_4[1])) {\n      points_facilities_2$village_name[i] &lt;- matched_village$ID_4[1]\n    } else {\n      points_facilities_2$village_name[i] &lt;- matched_village$NAME_4[1]\n    }\n  }\n}\n\n# Display the updated points_facilities_2\nprint(points_facilities_2)\n\nI’ll be writing this RDS so we don’t do the lengthy operation above.\n\n#write_rds(points_facilities_2, \"data/rds/points_facilities_2.rds\")\n\n\npoints_facilities_2 &lt;- read_rds(\"data/rds/points_facilities_2.rds\")\n\n\nTop 10 provinces with the most number of health facilities\n\n\n\n\n\n\nNote\n\n\n\nHere, we will be using the point_facilities_2 that we created earlier. It has the village, district, commune and province of each health facilitiy. Hence, when we group by province, we will get the health facilities of each province. Plotting them will give us an idea of the provinces that are the most medically advanced.\n\n\n\n# Load the dplyr package\nlibrary(dplyr)\n\n# Assuming points_facilities_2 is your dataset\n# Group by province_name, count the number of facilities, and arrange in descending order\nprovince_facility_count &lt;- points_facilities_2 %&gt;%\n  group_by(province_name) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\n# Select the top 10 provinces\ntop_10_provinces &lt;- head(province_facility_count, 10)\n\n# Adjusted bar plot with counts beside bars, with refined zoom and spacing\nggplot(top_10_provinces, aes(x = reorder(province_name, -count), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  geom_text(aes(label = count), hjust = -0.1, size = 3.5) + # Place text beside bars\n  theme_minimal() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\")) + \n  labs(title = \"Top 10 Provinces by Number of Health Facilities\",\n       x = \"Province\",\n       y = \"Number of Facilities\") +\n  coord_flip() # Keep the plot horizontal\n\n\n\n\n\n\nTop 10 districts with the most number of health facilities\nWe do the same here as above, but group by district.\n\n# Assuming points_facilities_2 is your dataset\n# Group by district_name, count the number of facilities, and arrange in descending order\ndistrict_facility_count &lt;- points_facilities_2 %&gt;%\n  group_by(district_name) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\n# Select the top 10 provinces\ntop_10_district &lt;- head(district_facility_count, 10)\n\n# Adjusted bar plot with counts beside bars, with refined zoom and spacing\nggplot(top_10_district, aes(x = reorder(district_name, -count), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  geom_text(aes(label = count), hjust = -0.1, size = 3.5) + # Place text beside bars\n  theme_minimal() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\")) +\n  labs(title = \"Top 10 Districts by Number of Health Facilities\",\n       x = \"District\",\n       y = \"Number of Facilities\") +\n  coord_flip() # Keep the plot horizontal\n\n\n\n\n\n\nTop 10 communes with the most number of health facilities\nWe do the same here as above, but group by commune.\n\n# Assuming points_facilities_2 is your dataset\n# Group by commune_name, count the number of facilities, and arrange in descending order\ncommune_facility_count &lt;- points_facilities_2 %&gt;%\n  group_by(commune_name) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\n# Select the top 10 provinces\ntop_10_commune &lt;- head(commune_facility_count, 10)\n\n# Adjusted bar plot with counts beside bars, with refined zoom and spacing\nggplot(top_10_commune, aes(x = reorder(commune_name, -count), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  geom_text(aes(label = count), hjust = -0.1, size = 3.5) + # Place text beside bars\n  theme_minimal() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\")) + # Slightly adjust plot margins if necessary\n  labs(title = \"Top 10 Communes by Number of Health Facilities\",\n       x = \"Communes\",\n       y = \"Number of Facilities\") +\n  coord_flip() # Keep the plot horizontal\n\n\n\n\n\n\nTop 10 villages with the most number of health facilities\nWe do the same here as above, but group by villages.\n\n# Assuming points_facilities_2 is your dataset\n# Group by village_name, count the number of facilities, and arrange in descending order\nvillage_facility_count &lt;- points_facilities_2 %&gt;%\n  group_by(village_name) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\n# Select the top 10 provinces\ntop_10_village &lt;- head(village_facility_count, 10)\n\n# Adjusted bar plot with counts beside bars, with refined zoom and spacing\nggplot(top_10_village, aes(x = reorder(village_name, -count), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  geom_text(aes(label = count), hjust = -0.1, size = 3.5) + # Place text beside bars\n  theme_minimal() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\")) + # Slightly adjust plot margins if necessary\n  labs(title = \"Top 10 villages by Number of Health Facilities\",\n       x = \"Communes\",\n       y = \"Number of Facilities\") +\n  coord_flip() # Keep the plot horizontal"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#plotting-facilities-on-cambodia-map-divided-by-provinces",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#plotting-facilities-on-cambodia-map-divided-by-provinces",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Plotting facilities on cambodia map (divided by provinces)",
    "text": "Plotting facilities on cambodia map (divided by provinces)\nThis is what the uses will first see when they have not selected any option. They will get to see the distribution of health care facilities discretely and on a choropleth map against Cambodia divided as provinces.\n\nPlotting map with discrete facilitiesPlotting choropleth map\n\n\n\ntm_shape(province_sf, , scale = 5) +\n  tm_polygons(col = \"black\", border.col = \"white\") +\ntm_shape(points_facilities_2) +\n  tm_dots(size = 0.01, col = \"purple\")\n\n\n\n\n\n\nHere, we will be using points_facilities_2 to group by provinces and find the number healthcare facilities by province.\n\nlibrary(dplyr)\nlibrary(sf)\n\n\n# Process facilities_count_per_province\nfacilities_count_per_province &lt;- points_facilities_2 %&gt;%\n  st_set_geometry(NULL) %&gt;%  # Remove geometry if it's an sf object\n  filter(!is.na(province_name)) %&gt;%  # Filter out rows with NA in province_name\n  group_by(province_name) %&gt;%\n  summarise(count = n(), .groups = 'drop')  # Summarise and drop grouping\n\n# Ensure sf package's select method is used for the sf object\nprovince_sf_selected &lt;- dplyr::select(province_sf, NAME_1, geometry)\n\n# Join with province_sf to add geometries\nfacilities_count_per_province &lt;- facilities_count_per_province %&gt;%\n  left_join(province_sf_selected, by = c(\"province_name\" = \"NAME_1\")) \n\n# Convert the result back to an sf object\nfacilities_count_per_province &lt;- st_as_sf(facilities_count_per_province)\n\n\ntm_shape(facilities_count_per_province)+\n  tm_fill(\"count\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Healthcaren facilities in Cambodia\",\n            main.title.position = \"center\",\n            main.title.size = 0.9,\n            legend.height = 0.3, \n            legend.width = 0.30,\n            legend.position = c(\"right\", \"bottom\"), \n            legend.title.size = 0.8,\n            legend.text.size = 0.6,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 1) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\nPlotting bar chart for categories of facilities in Cambodia\n\nfacilities_count_per_category &lt;- points_facilities_2 %&gt;%\n  st_set_geometry(NULL) %&gt;%  # Remove geometry if  with NA in category\n  group_by(CATEGORY) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\n\nggplot(facilities_count_per_category, aes(x = CATEGORY, y = count)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  labs(title = \"Facilities Count per Category In Cambodia\", x = \"Category\", y = \"Count\") +\n  theme_minimal()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#plotting-facilities-on-a-province-divided-by-districts",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#plotting-facilities-on-a-province-divided-by-districts",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Plotting facilities on a province (divided by districts)",
    "text": "Plotting facilities on a province (divided by districts)\nLet’s get the geometry of the province selected by the user from province_sf.\n\nprovinceNameSelected &lt;- \"Batdâmbâng\"\nselected_row &lt;- subset(district_sf, NAME_1 == provinceNameSelected)\n\n# Select all health facilities that match the selected province name\nselectedHealthFacilities &lt;- subset(points_facilities_2, province_name == provinceNameSelected)\n\n\nMapping discrete healthcare facilities on a mapChoropleth\n\n\n\ntm_shape(selected_row, scale = 5) +\n  tm_polygons(col = \"black\", border.col = \"white\") +\ntm_shape(selectedHealthFacilities) +\n  tm_dots(size = 0.1, col = \"purple\")\n\n\n\n\n\n\nHere we find the healthcare facilities in each district of the selected province.\n\n# Adjusting the placeholder 'x' to the actual province name user is interested in\nprovince_of_interest &lt;- provinceNameSelected\n\n# Process facilities_count_per_district by filtering, grouping, and summarising\nfacilities_count_per_district &lt;- points_facilities_2 %&gt;%\n  st_set_geometry(NULL) %&gt;%  # Remove geometry if it's an sf object\n  filter(!is.na(province_name) & !is.na(district_name)) %&gt;%  # Filter out rows where both province_name and district_name are NA\n  filter(province_name == province_of_interest) %&gt;%  # Keep only rows for the specified province\n  group_by(district_name) %&gt;%\n  summarise(count = n(), .groups = 'drop') %&gt;%\n  ungroup() %&gt;%\n  mutate(province_name = province_of_interest)  # Manually add province_name back\n\n# Prepare district_sf for the join by selecting needed columns\ndistrict_sf_selected &lt;- dplyr::select(district_sf, NAME_1, NAME_2, geometry)\n\n# Join with district_sf to add geometries, matching on district and province names\nfacilities_count_per_district &lt;- facilities_count_per_district %&gt;%\n  left_join(district_sf_selected, by = c(\"district_name\" = \"NAME_2\", \"province_name\" = \"NAME_1\"))\n\n# Convert the result back to an sf object\nfacilities_count_per_district &lt;- st_as_sf(facilities_count_per_district)\n\n\ntm_shape(facilities_count_per_district)+\n  tm_fill(\"count\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Healthcaren facilities in districts in 1 province\",\n            main.title.position = \"center\",\n            main.title.size = 0.9,\n            legend.height = 0.3, \n            legend.width = 0.30,\n            legend.position = c(\"left\", \"bottom\"), \n            legend.title.size = 0.8,\n            legend.text.size = 0.6,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 1) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\nPlotting categories of healthcare facilities in a selected province\n\nfacilities_count_per_category &lt;- points_facilities_2 %&gt;%\n  st_set_geometry(NULL) %&gt;%  # Remove geometry if it's an sf object\n  filter(!is.na(CATEGORY)) %&gt;%  # Filter out rows with NA in category\n  filter(province_name == 'Phnom Penh') %&gt;% \n  group_by(CATEGORY) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\n\nggplot(facilities_count_per_category, aes(x = CATEGORY, y = count)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  labs(title = \"Facilities Count per Category In Phnom Penh\nProvince\", x = \"Category\", y = \"Count\") +\n  theme_minimal()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#plotting-facilities-on-a-district-divided-by-communes",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#plotting-facilities-on-a-district-divided-by-communes",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Plotting facilities on a district (divided by communes)",
    "text": "Plotting facilities on a district (divided by communes)\n\nprovinceNameSelected &lt;- \"Batdâmbâng\"\ndistrictNameSelected &lt;- \"Banan\"\n\n# Subset to select rows from district_sf that match both the selected province and district names\nselected_row &lt;- subset(commune_sf, NAME_1 == provinceNameSelected & NAME_2 == districtNameSelected)\n\n# Select all health facilities that match the selected province and district names\nselectedHealthFacilities &lt;- subset(points_facilities_2, province_name == provinceNameSelected & district_name == districtNameSelected)\n\n\nMapping discrete healthcare facilities on a mapChoropleth\n\n\n\ntm_shape(selected_row, scale = 5) +\n  tm_polygons(col = \"black\", border.col = \"white\") +\ntm_shape(selectedHealthFacilities) +\n  tm_dots(size = 0.1, col = \"purple\")\n\n\n\n\n\n\n\nprovince_of_interest &lt;- provinceNameSelected # Replace with actual province name\ndistrict_of_interest &lt;- districtNameSelected # Replace with actual district name\n\n# Process facilities_count_per_commune by filtering, grouping, and summarising\nfacilities_count_per_commune &lt;- points_facilities_2 %&gt;%\n  st_set_geometry(NULL) %&gt;%  # Remove geometry if it's an sf object\n  filter(!is.na(province_name) & !is.na(district_name) & !is.na(commune_name)) %&gt;%  # Filter out rows where province_name, district_name, and commune_name are NA\n  filter(province_name == province_of_interest & district_name == district_of_interest) %&gt;%  # Keep only rows for the specified province and district\n  group_by(commune_name) %&gt;%\n  summarise(count = n(), .groups = 'drop') %&gt;%\n  ungroup() %&gt;%\n  mutate(province_name = province_of_interest, district_name = district_of_interest)  # Manually add province_name and district_name back\n\n# Prepare district_sf for the join by selecting needed columns\ndistrict_sf_selected &lt;- commune_sf %&gt;%\n  dplyr::select(NAME_1, NAME_2, NAME_3, geometry)\n\n# Join with district_sf to add geometries, matching on province, district, and commune names\nfacilities_count_per_commune &lt;- facilities_count_per_commune %&gt;%\n  left_join(district_sf_selected, by = c(\"province_name\" = \"NAME_1\", \"district_name\" = \"NAME_2\", \"commune_name\" = \"NAME_3\"))\n\n# Convert the result back to an sf object\nfacilities_count_per_commune &lt;- st_as_sf(facilities_count_per_commune)\n\n\ntm_shape(facilities_count_per_commune)+\n  tm_fill(\"count\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Healthcaren facilities in communes in 1 district\",\n            main.title.position = \"center\",\n            main.title.size = 0.9,\n            legend.height = 0.3, \n            legend.width = 0.30,\n            legend.position = c(\"left\", \"bottom\"), \n            legend.title.size = 0.8,\n            legend.text.size = 0.6,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 1) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\nPlotting categories of facilities in a selected district\n\nfacilities_count_per_category &lt;- points_facilities_2 %&gt;%\n  st_set_geometry(NULL) %&gt;%  # Remove geometry if it's an sf object\n  filter(!is.na(CATEGORY)) %&gt;%  # Filter out rows with NA in category\n  filter(province_name == 'Phnom Penh', district_name == 'Phnom Penh') %&gt;% \n  group_by(CATEGORY) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\n\nggplot(facilities_count_per_category, aes(x = CATEGORY, y = count)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  labs(title = \"Facilities Count per Category In Phnom Penh\ndistrict\", x = \"Category\", y = \"Count\") +\n  theme_minimal()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#plotting-facilities-on-a-communedivided-by-villages",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#plotting-facilities-on-a-communedivided-by-villages",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "Plotting facilities on a commune(divided by villages)",
    "text": "Plotting facilities on a commune(divided by villages)\n\nprovinceNameSelected &lt;- \"Tbong Khmum\"\ndistrictNameSelected &lt;- \"Ou Reang Ov\"\ncommuneNameSelected &lt;- \"Kong Chey\"\n\n# Subset to select rows from district_sf that match both the selected province and district names\nselected_row &lt;- subset(village_sf, NAME_1 == provinceNameSelected & NAME_2 == districtNameSelected & NAME_3 == communeNameSelected)\n\n# Select all health facilities that match the selected province and district names\nselectedHealthFacilities &lt;- subset(points_facilities_2, province_name == provinceNameSelected & district_name == districtNameSelected & commune_name == communeNameSelected)\n\n\ntm_shape(selected_row, scale = 5) +\n  tm_polygons(col = \"black\", border.col = \"white\") +\ntm_shape(selectedHealthFacilities) +\n  tm_dots(size = 0.1, col = \"purple\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#ui-of-my-screens",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#ui-of-my-screens",
    "title": "Take-home Exercsie 3 - Distribution of healthcare facilities in Cambodia",
    "section": "UI of my screens",
    "text": "UI of my screens\nThis is the screen for exploratory data analysis. When entering the page, they will see data pertaining to the whole of Cambodia. Then, the user will be able to select what province they want explore, and then their options for district will be filtered according to the province they selected (only districts in that province will be shown). Similarly, when they select a district, only communes of that district will be shown for the commune section - and same for village with regards to the commune chosen.\nThey will be able to see two types of maps to understand the distribution of hospital facilities more - spatial points and choropleth maps. They will also be able to see the types of facilities in their chosen area. So, this is the screen users will see when they choose spatial point maps.\n\nThis is what the user will see when they choose to see choropleth maps. They will have more filters when they chose to do this. They can choose the type of grouping in data (jenkins, quartile etc) and the color theme of their liking"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/data/geospatial/TAINAN_VILLAGE.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/data/geospatial/TAINAN_VILLAGE.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“TWD97”,DATUM[“Taiwan Datum 1997”,ELLIPSOID[“GRS 1980”,6378137,298.257222101,LENGTHUNIT[“metre”,1]]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“Taiwan, Republic of China - onshore and offshore - Taiwan Island, Penghu (Pescadores) Islands.”],BBOX[17.36,114.32,26.96,123.61]],ID[“EPSG”,3824]] +proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs 27230 3824 EPSG:3824 TWD97 longlat EPSG:7019 true"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html",
    "href": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html",
    "title": "In class ex 06",
    "section": "",
    "text": "pacman::p_load(sp, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#data-import-and-preperation",
    "href": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#data-import-and-preperation",
    "title": "In class ex 06",
    "section": "Data Import And Preperation",
    "text": "Data Import And Preperation\n\n12.4.1 Importing geospatial data into R environment\nFilter to select records that meet those requirements\n\nshan_sf &lt;- st_read(dsn = \"data\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\In-class_Ex\\In-class-Ex06\\data' using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\n\n12.4.2 Importing aspatial data into R environment\nThe csv file will be import using read_csv function of readr package.\nThe code chunks used are shown below:\n\nict &lt;- read_csv (\"data/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\n\n\n12.4.3 Derive new variables using dplyr package\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#exploratory-data-analysis-eda",
    "href": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#exploratory-data-analysis-eda",
    "title": "In class ex 06",
    "section": "12.5 Exploratory Data Analysis (EDA)",
    "text": "12.5 Exploratory Data Analysis (EDA)\n\n12.5.1 EDA using statistical graphics\nWe can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n12.5.2 EDA using choropleth map\n\n12.5.2.1 Joining geospatial data with aspatial data\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \n#write_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n12.5.2.2 Preparing a choropleth map\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate by using the code chunk below."
  },
  {
    "objectID": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#correlation-analysis",
    "href": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#correlation-analysis",
    "title": "In class ex 06",
    "section": "12.6 Correlation Analysis",
    "text": "12.6 Correlation Analysis\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\nIn this section, you will learn how to use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both."
  },
  {
    "objectID": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#hierarchy-cluster-analysis",
    "href": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#hierarchy-cluster-analysis",
    "title": "In class ex 06",
    "section": "12.7 Hierarchy Cluster Analysis",
    "text": "12.7 Hierarchy Cluster Analysis\nIn this section, you will learn how to perform hierarchical cluster analysis. The analysis consists of four major steps:\n\n12.7.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nwe want to retain row name\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n12.7.2 Data Standardisation\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n12.7.3 Min-Max standardisation\nIn the code chunk below, normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\n\n12.7.4 Z-score standardisation\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\n\n\n12.7.6 Computing proximity matrix\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n12.7.7 Computing hierarchical clustering\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n12.7.8 Selecting the optimal clustering algorithm\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\n\n\n12.7.9 Determining Optimal Clusters\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n12.7.9.1 Gap Statistic Method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n12.7.10 Interpreting the dendrograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n12.7.11 Visually-driven hierarchical clustering analysis\nIn this section, we will learn how to perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n12.7.11.1 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n12.7.11.2 Plotting interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n12.7.12 Mapping the clusters formed\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nhe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#spatially-constrained-clustering-skater-approach",
    "href": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#spatially-constrained-clustering-skater-approach",
    "title": "In class ex 06",
    "section": "12.8 Spatially Constrained Clustering: SKATER approach",
    "text": "12.8 Spatially Constrained Clustering: SKATER approach\nIn this section, you will learn how to derive spatially constrained cluster by using skater() method of spdep package.\n\n12.8.1 Converting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\n\n12.8.2 Computing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sf)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe can plot the neighbours list on shan_sp by using the code chunk below. Since we now can plot the community area boundaries as well, we plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\nplot(shan_sp, \n     border=grey(.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\nNote that if you plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.\n\n\n12.8.3 Computing minimum spanning tree\n\n12.8.3.1 Calculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n\n12.8.4 Computing minimum spanning tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(shan_sp, border=gray(.5))\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n12.8.5 Computing spatially constrained clusters using SKATER method\nThe code chunk below compute the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the conde chunk below.\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(shan_sp, border=gray(.5))\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\n\n\n\n\n\n\n\n12.8.6 Visualising the clusters in choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#spatially-constrained-clustering-clustgeo-method",
    "href": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#spatially-constrained-clustering-clustgeo-method",
    "title": "In class ex 06",
    "section": "12.9 Spatially Constrained Clustering: ClustGeo Method",
    "text": "12.9 Spatially Constrained Clustering: ClustGeo Method\nIn this section, you will gain hands-on experience on using functions provided by ClustGeo package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis.\n\n12.9.1 A short note about ClustGeo package\nClustGeo package is an R package specially designed to support the need of performing spatially constrained cluster analysis. More specifically, it provides a Ward-like hierarchical clustering algorithm called hclustgeo() including spatial/geographical constraints.\nIn the nutshell, the algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between [0, 1]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the attribute/clustering variable space. D1, on the other hand, gives the dissimilarities in the constraint space. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.\nThe idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called choicealpha().\n\n\n12.9.2 Ward-like hierarchical clustering: ClustGeo\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist(). For sample code chunk, please refer to 5.7.6 Computing proximity matrix\n\n12.9.2.1 Mapping the clusters formed\nSimilarly, we can plot the clusters on a categorical area shaded map by using the steps we learned in 5.7.12 Mapping the clusters formed.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n12.9.3 Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nNotice that as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\nWith reference to the graphs above, alpha = 0.3 will be used as shown in the code chunk below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNext, cutree() is used to derive the cluster objecct.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nWe will then join back the group list with shan_sf polygon feature data frame by using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#visual-interpretation-of-clusters",
    "href": "In-class_Ex/In-class-Ex06/In-Class_Ex06.html#visual-interpretation-of-clusters",
    "title": "In class ex 06",
    "section": "12.10 Visual Interpretation of Clusters",
    "text": "12.10 Visual Interpretation of Clusters\n\n12.10.1 Visualising individual clustering variable\nCode chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5.\n\n\n12.10.2 Multivariate Visualisation\nPast studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, ggparcoord() of GGally package\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html",
    "title": "Hands-On Exercise 3 :",
    "section": "",
    "text": "pacman::p_load(maptools, sf,raster,spatstat,tmap,tidyverse)\nHere we use two different types of reading because for childcare we know the exact file but the other file is a shapefile that requires multiple files, so you use the dsn part.\nchildcare_sf &lt;- st_read(\"../../Hands-On_Ex/Hand-on_Ex03/data/ChildCareServices.geojson\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `ChildCareServices' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nmpsz_sfe &lt;- st_read(dsn=\"data/geospatial\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\In-class_Ex\\In-class-Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nclass(mpsz_sfe)\n\n[1] \"sf\"         \"data.frame\""
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#creating-coastal-outline",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#creating-coastal-outline",
    "title": "Hands-On Exercise 3 :",
    "section": "Creating Coastal outline",
    "text": "Creating Coastal outline\nWhen you apply st_union() to a collection of polygons, each representing a state within a country, the function merges all these state polygons into a single polygon that represents the entire country, effectively dissolving the boundaries (state lines) between them.\n\nsg_sf &lt;- mpsz_sfe %&gt;%\n  st_union()\n# st_combine combines geometries wirhout dissolve/resolve boundaries but st_union does\n\n\nplot(sg_sf)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#geospatial-data-wrangling",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#geospatial-data-wrangling",
    "title": "Hands-On Exercise 3 :",
    "section": "geospatial data wrangling",
    "text": "geospatial data wrangling\ncreating ppp objects : sf method\neasier to do this to get from sf -&gt; ppp, instead of sf -&gt; sp* -&gt; sp general -&gt; ppp\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1925 character character \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\nHandling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\nThis is very important for postal code data. Postal code covers a large area and muliple data points have the same postal code, so you must check if there are duplicates + use jittering\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\n\n\nCreating owin object : sf method\nThis .owin helps with the conversion aagain without you doing sf -&gt; sp* -&gt; sp general -&gt; owin\n\n# . functions work with sf layer, so take the originl data\nsg_owin &lt;- as.owin(sg_sf)\n\n\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422\n\n\n\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\n\npg &lt;- mpsz_sfe %&gt;% \n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sfe %&gt;% \n  filter(PLN_AREA_N == \"TAMPINES\")\nckk &lt;- mpsz_sfe %&gt;% \n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sfe %&gt;% \n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning area\n\nplot(pg, main =\"Punggol\")\n\n\n\n\n\nplot(tm, main =\"Tampines\")\n\n\n\n\n\nplot(ckk, main =\"Chua Chu Kang\")\n\n\n\n\n\nplot(jw, main =\"Jurong West\")"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#network-constrained-kernel-density",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#network-constrained-kernel-density",
    "title": "Hands-On Exercise 3 :",
    "section": "Network constrained kernel density",
    "text": "Network constrained kernel density"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#getting-started",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#getting-started",
    "title": "Hands-On Exercise 3 :",
    "section": "Getting started",
    "text": "Getting started\n\npacman::p_load(sp,rgdal,sf, spNetwork, tmap, classInt, viridis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#data-import-and-preparation",
    "href": "In-class_Ex/In-class-Ex03/In-class-Ex03.html#data-import-and-preparation",
    "title": "Hands-On Exercise 3 :",
    "section": "2. Data Import and Preparation",
    "text": "2. Data Import and Preparation\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\", layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\In-class_Ex\\In-class-Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcareNew &lt;- st_read(dsn=\"data/geospatial\", layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\In-class_Ex\\In-class-Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\nChange projection system\n\nchildcareNew &lt;-childcareNew %&gt;% st_transform(crs =3414)\n\nnetwork &lt;-network  %&gt;% st_transform(crs =3414)\n\n\n\nPlot\n\ntmap_mode('plot')\ntm_shape(childcareNew) + \n  tm_dots() + \n  tm_shape(network) +\n  tm_lines()\n\n\n\n\n\nlixels &lt;- lixelize_lines(network,750,mindist = 375)\n\nlength of a lixel is set to 750m and min length of a lixel is set to 375\n\nsamples &lt;- lines_center(lixels)\n\n\ndensities &lt;- nkde(network, \n                  events = childcareNew,\n                  w = rep(1,nrow(childcareNew)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically Weighted Regression (GWR) is a spatial statistical technique used for exploring spatially varying relationships between a dependent variable and independent variables. It’s an extension of traditional regression analysis that takes into account the spatial variability in data.\nLet’s break down the concept step by step:\n\nRegression Analysis: Regression analysis is a statistical method used to examine the relationship between one dependent variable (usually denoted as �Y) and one or more independent variables (usually denoted as �X). The relationship is typically represented by an equation in the form �=�0+�1�1+�2�2+…+�Y=β0​+β1​X1​+β2​X2​+…+ϵ, where �0,�1,�2,…β0​,β1​,β2​,… are coefficients, �1,�2,…X1​,X2​,… are independent variables, and �ϵ is the error term.\nSpatial Data: In spatial data analysis, we deal with data that have a geographic or spatial component. This could include data such as population density, temperature, rainfall, etc., which vary across geographic space.\nSpatial Variability: Spatial variability refers to the fact that the relationship between variables may change across different locations on a map. For example, the relationship between income and education level might be different in urban areas compared to rural areas.\nGeographically Weighted Regression: Geographically Weighted Regression (GWR) addresses the issue of spatial variability by allowing the regression coefficients to vary across space. Instead of estimating a single set of coefficients for the entire study area, GWR estimates a separate set of coefficients for each location or point in the study area.\nWeighting: In GWR, the influence of neighboring data points on the estimation of coefficients is weighted based on their proximity to the point of interest. Data points that are closer to the point of interest have a higher weight in estimating the coefficients, while those farther away have a lower weight. This means that GWR gives more emphasis to nearby data points when estimating the local relationship between variables.\nLocal Coefficients: The result of GWR is a set of local regression coefficients for each location in the study area. These coefficients reflect the spatially varying relationship between the dependent and independent variables at each location.\n\nIn summary, Geographically Weighted Regression (GWR) is a powerful tool for analyzing spatial data by allowing the regression coefficients to vary locally, taking into account the spatial variability in relationships between variables across geographic space. It’s widely used in various fields such as geography, environmental science, urban planning, and public health for understanding spatial patterns and making informed decisions.\nGeographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "title": "Hands-on Exercise 8 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically Weighted Regression (GWR) is a spatial statistical technique used for exploring spatially varying relationships between a dependent variable and independent variables. It’s an extension of traditional regression analysis that takes into account the spatial variability in data.\nLet’s break down the concept step by step:\n\nRegression Analysis: Regression analysis is a statistical method used to examine the relationship between one dependent variable (usually denoted as �Y) and one or more independent variables (usually denoted as �X). The relationship is typically represented by an equation in the form �=�0+�1�1+�2�2+…+�Y=β0​+β1​X1​+β2​X2​+…+ϵ, where �0,�1,�2,…β0​,β1​,β2​,… are coefficients, �1,�2,…X1​,X2​,… are independent variables, and �ϵ is the error term.\nSpatial Data: In spatial data analysis, we deal with data that have a geographic or spatial component. This could include data such as population density, temperature, rainfall, etc., which vary across geographic space.\nSpatial Variability: Spatial variability refers to the fact that the relationship between variables may change across different locations on a map. For example, the relationship between income and education level might be different in urban areas compared to rural areas.\nGeographically Weighted Regression: Geographically Weighted Regression (GWR) addresses the issue of spatial variability by allowing the regression coefficients to vary across space. Instead of estimating a single set of coefficients for the entire study area, GWR estimates a separate set of coefficients for each location or point in the study area.\nWeighting: In GWR, the influence of neighboring data points on the estimation of coefficients is weighted based on their proximity to the point of interest. Data points that are closer to the point of interest have a higher weight in estimating the coefficients, while those farther away have a lower weight. This means that GWR gives more emphasis to nearby data points when estimating the local relationship between variables.\nLocal Coefficients: The result of GWR is a set of local regression coefficients for each location in the study area. These coefficients reflect the spatially varying relationship between the dependent and independent variables at each location.\n\nIn summary, Geographically Weighted Regression (GWR) is a powerful tool for analyzing spatial data by allowing the regression coefficients to vary locally, taking into account the spatial variability in relationships between variables across geographic space. It’s widely used in various fields such as geography, environmental science, urban planning, and public health for understanding spatial patterns and making informed decisions.\nGeographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "title": "Hands-on Exercise 8 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.2 The Data",
    "text": "8.2 The Data\nTwo data sets will be used in this model building exercise, they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "title": "Hands-on Exercise 8 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.3 Getting Started",
    "text": "8.3 Getting Started\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nR package for building OLS and performing diagnostics tests\n\nolsrr\n\nR package for calibrating geographical weighted family of models\n\nGWmodel\n\nR package for multivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)\n\n\nunlink(\"C:/R-4.3.2/library/00LOCK\", recursive = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 8 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.5 Geospatial Data Wrangling",
    "text": "8.5 Geospatial Data Wrangling\n\n8.5.1 Importing geospatial data\nThe geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information.\n\n\n8.5.2 Updating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\nNext, you will reveal the extent of mpsz_svy21 by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#aspatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#aspatial-data-wrangling",
    "title": "Hands-on Exercise 8 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.6 Aspatial Data Wrangling",
    "text": "8.6 Aspatial Data Wrangling\n\n8.6.1 Importing the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() to display the data structure of will do the job.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n8.6.2 Converting aspatial data frame into a sf object\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 8 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.7 Exploratory Data Analysis (EDA)",
    "text": "8.7 Exploratory Data Analysis (EDA)\nIn the section, you will learn how to use statistical graphics functions of ggplot2 package to perform EDA.\n\n8.7.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation.\n\n\n8.7.2 Multiple Histogram Plots distribution of variables\nIn this section, you will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n8.7.3 Drawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#hedonic-pricing-modelling-in-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#hedonic-pricing-modelling-in-r",
    "title": "Hands-on Exercise 8 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.8 Hedonic Pricing Modelling in R",
    "text": "8.8 Hedonic Pricing Modelling in R\nIn this section, you will learn how to building hedonic pricing models for condominium resale units using lm() of R base.\n\n8.8.1 Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n      *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices.\n\n\n8.8.2 Multiple Linear Regression Method\n\n8.8.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\n8.8.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n8.8.4 Preparing Publication Quality Table: olsrr method\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n8.8.5 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n8.8.5.1 Checking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n8.8.5.2 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n8.8.5.3 Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n8.8.5.4 Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "Hands-on Exercise 8 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.9 Building Hedonic Pricing Models using GWmodel",
    "text": "8.9 Building Hedonic Pricing Models using GWmodel\nIn this section, you are going to learn how to modelling hedonic pricing using both the fixed and adaptive bandwidth schemes\n\n8.9.1 Building Fixed Bandwidth GWR Model\n\n8.9.1.1 Computing fixed bandwith\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\n\n\n8.9.1.2 GWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-24 00:42:23.30599 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-03-24 00:42:24.771318 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n\n\n8.9.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n8.9.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\n8.9.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-24 00:42:35.410272 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-03-24 00:42:37.124141 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\n\n\n8.9.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\n8.9.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n\n8.9.5 Visualising local R2\nThe code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html",
    "title": "Hands on 06",
    "section": "",
    "text": "pacman::p_load(sp, rgdal, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#data-import-and-preperation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#data-import-and-preperation",
    "title": "Hands on 06",
    "section": "Data Import And Preperation",
    "text": "Data Import And Preperation\n\n12.4.1 Importing geospatial data into R environment\nFilter to select records that meet those requirements\n\nshan_sf &lt;- st_read(dsn = \"data\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data' using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\n\n12.4.2 Importing aspatial data into R environment\nThe csv file will be import using read_csv function of readr package.\nThe code chunks used are shown below:\n\nict &lt;- read_csv (\"data/Shan-ICT.csv\")\n\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\n\n\n12.4.3 Derive new variables using dplyr package\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#exploratory-data-analysis-eda",
    "title": "Hands on 06",
    "section": "12.5 Exploratory Data Analysis (EDA)",
    "text": "12.5 Exploratory Data Analysis (EDA)\n\n12.5.1 EDA using statistical graphics\nWe can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\nThe code chunks below are used to create the data visualisation. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\n12.5.2 EDA using choropleth map\n\n12.5.2.1 Joining geospatial data with aspatial data\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\n\n#shan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n12.5.2.2 Preparing a choropleth map\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#correlation-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#correlation-analysis",
    "title": "Hands on 06",
    "section": "12.6 Correlation Analysis",
    "text": "12.6 Correlation Analysis\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\nIn this section, you will learn how to use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#hierarchy-cluster-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#hierarchy-cluster-analysis",
    "title": "Hands on 06",
    "section": "12.7 Hierarchy Cluster Analysis",
    "text": "12.7 Hierarchy Cluster Analysis\nIn this section, you will learn how to perform hierarchical cluster analysis. The analysis consists of four major steps:\n\n12.7.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nwe want to retain row name\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n12.7.2 Data Standardisation\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n12.7.3 Min-Max standardisation\nIn the code chunk below, normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\n\n12.7.4 Z-score standardisation\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\n\n\n12.7.5 Visualising the standardised clustering variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plot the scaled Radio_PR field.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n12.7.6 Computing proximity matrix\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n12.7.7 Computing hierarchical clustering\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n12.7.8 Selecting the optimal clustering algorithm\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\n\n\n12.7.9 Determining Optimal Clusters\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n12.7.9.1 Gap Statistic Method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n12.7.10 Interpreting the dendrograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n12.7.11 Visually-driven hierarchical clustering analysis\nIn this section, we will learn how to perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n12.7.11.1 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n12.7.11.2 Plotting interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n12.7.12 Mapping the clusters formed\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nhe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#spatially-constrained-clustering-skater-approach",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#spatially-constrained-clustering-skater-approach",
    "title": "Hands on 06",
    "section": "12.8 Spatially Constrained Clustering: SKATER approach",
    "text": "12.8 Spatially Constrained Clustering: SKATER approach\nIn this section, you will learn how to derive spatially constrained cluster by using skater() method of spdep package.\n\n12.8.1 Converting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\n\n12.8.2 Computing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe can plot the neighbours list on shan_sp by using the code chunk below. Since we now can plot the community area boundaries as well, we plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\nclass(shan_sp)\n\n[1] \"SpatialPolygonsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\n\n\nclass(shan.nb)\n\n[1] \"nb\"\n\n\n\nplot(shan_sp, \n     border=grey(0.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\nNote that if you plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.\n\n\n12.8.3 Computing minimum spanning tree\n\n12.8.3.1 Calculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n\n12.8.4 Computing minimum spanning tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(shan_sp, border=gray(.5))\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n12.8.5 Computing spatially constrained clusters using SKATER method\nThe code chunk below compute the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the conde chunk below.\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(shan_sp, border=gray(.5))\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\n\n\n\n\n\n12.8.6 Visualising the clusters in choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#spatially-constrained-clustering-clustgeo-method",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#spatially-constrained-clustering-clustgeo-method",
    "title": "Hands on 06",
    "section": "12.9 Spatially Constrained Clustering: ClustGeo Method",
    "text": "12.9 Spatially Constrained Clustering: ClustGeo Method\nIn this section, you will gain hands-on experience on using functions provided by ClustGeo package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis.\n\n12.9.1 A short note about ClustGeo package\nClustGeo package is an R package specially designed to support the need of performing spatially constrained cluster analysis. More specifically, it provides a Ward-like hierarchical clustering algorithm called hclustgeo() including spatial/geographical constraints.\nIn the nutshell, the algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between [0, 1]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the attribute/clustering variable space. D1, on the other hand, gives the dissimilarities in the constraint space. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.\nThe idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called choicealpha().\n\n\n12.9.2 Ward-like hierarchical clustering: ClustGeo\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist(). For sample code chunk, please refer to 5.7.6 Computing proximity matrix\n\n12.9.2.1 Mapping the clusters formed\nSimilarly, we can plot the clusters on a categorical area shaded map by using the steps we learned in 5.7.12 Mapping the clusters formed.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n12.9.3 Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nNotice that as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\nWith reference to the graphs above, alpha = 0.3 will be used as shown in the code chunk below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNext, cutree() is used to derive the cluster objecct.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nWe will then join back the group list with shan_sf polygon feature data frame by using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#visual-interpretation-of-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex6.html#visual-interpretation-of-clusters",
    "title": "Hands on 06",
    "section": "12.10 Visual Interpretation of Clusters",
    "text": "12.10 Visual Interpretation of Clusters\n\n12.10.1 Visualising individual clustering variable\nCode chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5.\n\n\n12.10.2 Multivariate Visualisation\nPast studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, ggparcoord() of GGally package\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#overview",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#getting-started",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "9.2 Getting Started",
    "text": "9.2 Getting Started\n\n9.2.1 The analytical question\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover\n\nif development are even distributed geographically.\nIf the answer is No. Then, our next question will be “is there sign of spatial clustering?”.\nAnd, if the answer for this question is yes, then our next question will be “where are these clusters?”\n\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\n\n\n9.2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n9.2.3 Setting the Analytical Toolls\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#getting-the-data-into-r-environment",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "9.3 Getting the Data Into R Environment",
    "text": "9.3 Getting the Data Into R Environment\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n9.3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"../Hands-On_Ex04/data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n9.3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"../Hands-On_Ex04/data/aspatial/Hunan_2012.csv\")\n\n\n\n9.3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n9.3.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#global-measures-of-spatial-autocorrelation",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "9.4 Global Measures of Spatial Autocorrelation",
    "text": "9.4 Global Measures of Spatial Autocorrelation\nIn this section, you will learn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n9.4.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n9.4.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "9.5 Global Measures of Spatial Autocorrelation: Moran’s I",
    "text": "9.5 Global Measures of Spatial Autocorrelation: Moran’s I\nIn this section, you will learn how to perform Moran’s I statistics testing by using moran.test() of spdep.\n\n9.5.1 Maron’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nhunan$GDPPC: This is specifying the variable on which the Moran’s I test will be performed. It looks like it’s taking a column named GDPPC (which might stand for “Gross Domestic Product Per Capita”) from a data frame or a list named hunan. This is the dataset that contains the values we want to test for spatial autocorrelation.\nlistw=rswm_q: The listw parameter stands for “list weights” and is used to pass a spatial weights object to the function. The object rswm_q contains information about the spatial relationships between the observations in the hunan dataset. These weights define how the influence of each data point is spread out to its neighboring points. The type of weights (e.g., rook, queen, distance-based) and their specifics are defined in the rswm_q object.\nzero.policy = TRUE: This parameter is used to handle cases where there are regions with no neighbors (islands) in the spatial weights list. By setting zero.policy = TRUE, the function is instructed to proceed with the Moran’s I test even if some areas have no neighbors according to the weights matrix. Essentially, it’s a way to tell the function to ignore these “islands” rather than throwing an error.\n\n\n\n\n\n\n\nNote\n\n\n\nThis means that the values in nearby locations are dissimilar and that is statistically significant. The null hypothesis that the data follows random distribution should be rejected\n\n\n\n\n9.5.2 Computing Monte Carlo Moran’s I\nWhat is Monte Carlo?\n\nStart with Real Spatial Data: You have a map with data points, each representing a value of interest, like crime rates in different neighborhoods.\nThe Question: You want to know if high crime rates in one area are related to high crime rates in neighboring areas (positive spatial autocorrelation), or if it’s just random.\nCreating a Simulated World:\n\nImagine you take the map and erase all the crime rate data.\nThen, you redistribute those crime rates randomly across the map. This means you’re shuffling the data points so they no longer have their original spatial pattern. Each area gets a crime rate, but now it’s randomly assigned, not based on the real-world data.\n\nCalculating Moran’s I for the Simulated World:\n\nsimulations (which represent a world of randomness without any spatial pattern\nWith this shuffled map, you calculate Moran’s I, a statistic that measures how much the crime rate in one area is similar to the rates in nearby areas.\nThis calculation gives you a sense of whether the shuffled (randomized) data still shows any pattern of similar values being close together.\n\nRepeat the Simulation Multiple Times:\n\nYou don’t do this process just once. You repeat it many times, each time reshuffling the data and calculating a new Moran’s I.\nThis creates a bunch of Moran’s I values from worlds that are similar to ours but with randomized crime rates.\n\nCompare the Real World to the Simulated Worlds:\n\nNow, you compare the Moran’s I you calculated from your real data to the range of Moran’s I values you got from your simulations.\nIf the real Moran’s I is much higher than what you mostly see in the simulations, it suggests that the pattern in your real data is not random; it’s statistically significant.\nso if moran i of real data is much greater tahn the ranges of moran i we got from the simulations, means there are culstered data and observations closer to each other are similar\n\n\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 100 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=99, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value = 0.01\nalternative hypothesis: greater\n\n\n\nbperm$res[1:99]\n\n [1]  0.0579802047  0.0995374215  0.0694251386 -0.1042239884  0.0038110193\n [6] -0.0601316902 -0.0898497549  0.0886477537 -0.0495291344  0.0044879277\n[11] -0.0403080940 -0.1030595506 -0.0274239009  0.1083713535 -0.0188529094\n[16] -0.0484197610 -0.0253754744 -0.0212514958  0.0469779612  0.0408910440\n[21] -0.0324240897  0.0244599283 -0.0285621520 -0.0315422476 -0.0648166118\n[26]  0.0507360621 -0.0196479277 -0.1012356629 -0.0033345890 -0.0451875786\n[31] -0.0169780147  0.0972702432  0.1049185834 -0.0001699816 -0.0783668376\n[36] -0.0360203633 -0.0554003109 -0.0262207742  0.0066261362 -0.0584681167\n[41] -0.0168718257  0.0082456956 -0.0546958795 -0.0373107908 -0.0653454082\n[46]  0.0462297591 -0.0150531959  0.0282874005  0.0157705925 -0.0836056491\n[51] -0.1190189000  0.0172090478  0.0255428252 -0.0029558492 -0.0355542593\n[56] -0.1258924633  0.0435571651  0.1046473070 -0.0859109762  0.0829705234\n[61] -0.0943879694 -0.0587038328 -0.0135097048 -0.0506202830 -0.0528293680\n[66] -0.1124883683 -0.0770476050 -0.1152233509 -0.0955935516 -0.0970605978\n[71]  0.0637698821 -0.1005808607 -0.0349010557 -0.0481678951 -0.0460736682\n[76] -0.0446534235  0.0496933101  0.0463172140 -0.0224125804 -0.0671087934\n[81] -0.0187950839 -0.0221283710 -0.0038543168  0.0485712996 -0.0670291358\n[86] -0.0340662445 -0.0547678023 -0.1115993786 -0.0286081812 -0.0189904775\n[91] -0.0010492210 -0.0588839587 -0.0013944345  0.0691749580  0.1021861142\n[96]  0.0186604784  0.0091017099 -0.0265195474  0.0001244783\n\n\nThe code mean(bperm$res[1:999]) in R is used to calculate the average (mean) of a subset of simulation results from a Monte Carlo test for spatial autocorrelation (Moran’s I).\n\nmean(bperm$res[1:99])\n\n[1] -0.01842288\n\n\nThe R code var(bperm$res[1:999]) is used to calculate the variance of a subset of simulation results.\n\nvar(bperm$res[1:99])\n\n[1] 0.00338786\n\n\nyou can assess the variability in the Moran’s I values that would be expected under the null hypothesis of no spatial autocorrelation. If the actual Moran’s I calculated from your data is outside this range of variability, it may suggest that the pattern observed in your data is not due to random chance, and there is indeed spatial autocorrelation.\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "9.6 Global Measures of Spatial Autocorrelation: Geary’s C",
    "text": "9.6 Global Measures of Spatial Autocorrelation: Geary’s C\nIn this section, you will learn how to perform Geary’s C statistics testing by using appropriate functions of spdep package.\n\n9.6.1 Geary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nvalues are dissimilar\n\n\n9.6.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=99)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 100 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.01\nalternative hypothesis: greater\n\n\n\n\n9.6.3 Visualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:99])\n\n[1] 1.00126\n\n\n\nvar(bperm$res[1:99])\n\n[1] 0.006247721\n\n\n\nsummary(bperm$res[1:99])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.8289  0.9563  0.9971  1.0013  1.0413  1.2385"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05-Global.html#spatial-correlogram",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "9.7 Spatial Correlogram",
    "text": "9.7 Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n9.7.1 Compute Moran’s I correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\norder=6: This tells the command to look at six levels of connection. So not just next-door neighbors (first-level connections), but also the neighbors’ neighbors, and so on, up to six steps away.\n\nPoints: Each point on the correlogram represents the Moran’s I statistic calculated for that particular lag. The value of Moran’s I at lag 1 being the highest and positive suggests that neighboring areas (the first level of neighbors) have the most significant positive spatial autocorrelation, indicating that areas with similar GDP per capita values are geographically close.\nVertical Lines (Error Bars): The vertical lines extending from each point represent the uncertainty or variability in the Moran’s I estimates, often corresponding to confidence intervals. The length of the line indicates the range of Moran’s I values that are statistically plausible for that lag. If the line crosses the horizontal line at Moran’s I = 0, the spatial autocorrelation for that lag is not statistically significant at the chosen confidence level.8u/000\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n9.7.2 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Hello! In this page, i will be describing how i performed Thematic Mapping and GeoVisualisation with R. I will mainly be trying to create a choropleth map using the tmap package!\nWe also use pivot_wider() of the tidyr package, and mutate() ,group_by() , select() and filter() of the dplyr package, which i will be explaining in detail.\nI hope you can follow along, and be able to create choropleth maps!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#loading-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#loading-packages",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "Loading packages",
    "text": "Loading packages\nThis is a very important step as we have to load the packages before we can use them.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\nWhat is the tmap package?\nThe tmap package provides you with many handy functions to create your own thematic maps like choropleth maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "Importing the data",
    "text": "Importing the data\n\nDownloading the data\nThe links of the data i used are here (download shp format) and here\n\n\nImporting Geospatial Data into R\nAs learnt in the previous page, we use st_read() function of the sf package to read in the data.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWhen we realtiple features (geographical entities), with 15 fields, or attributes (such as temperature, precipitation for example).\nLet us examine it further by just printing mpsz (the variable we have stored the data in, that is of sf data object).\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nWe can also use glimpse() or head().\n\n\nImporting Attribute Data into R\nNow let us import the aspatial or attribute data into R.\n\nWhat is aspatial/attribute data?\nIt is data that’s not related to shape/location or coordinates but provides more context to the data. For example, if the data is about Airbnb, it tells you the number of rooms, the pricing, the number of people living in each Airbnb house.\nLet’s import it:\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nNow, let’s view it:\n\nlist(popdata) \n\n[[1]]\n# A tibble: 984,656 × 7\n   PA         SZ                     AG     Sex     TOD                Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 1- and 2-Ro…     0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 3-Room Flats    10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 4-Room Flats    30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 5-Room and …    50  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HUDC Flats (exc…     0  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Landed Properti…     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Condominiums an…    40  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Others               0  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 1- and 2-Ro…     0  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 3-Room Flats    10  2011\n# ℹ 984,646 more rows\n\n\n\n\n\nData Preparation\nWe need to prepare data to be in the form of a data table (like a normal sql table) before we can prepare a choropleth map.\nTo prepare the data, we use a few methods. i will go through them here before we actually execute them.\nThese are the methods we will go through:\n\npivot_wider() - tidyr package\nmutate() - dplyr package\ngroup_by() - dplyr package\nselect() - dplyr package\nfilter() - dplyr package\n\n\npivot_wider()\nIt helps transform data from long format to wide format.\nLong format: There are more rows and less columns. Here data is normalised and there are many rows for one subject. This can make it hard to compare the different subjects, and is not very good for visualization.\nHere is how a long format table could look like:\n\nHere there are multiple rows if you want to see the amount of sales in a particular month , or for a particular product. It is not very conducive for comparisons.\nWide format: There are less rows and more columns.\n\nHere there are lesser rows (usually there are more rows but in this case it worked out to still being 3 columns). And it is clearer as to how much sales there is per product per month.\nHow it’s used:\nwide_data &lt;- long_data %&gt;% pivot_wider(names_from = Product, values_from = Sales)\nnames_from: is the argument where you specify the column that will be used to create columns in the wide format\nvalues_from: specifies the column containing the values that will be used to file the new wide format columns\n\n\nmutate()\nmutate() is used to execute operations on existing columns and transform them, create new columns, or transform/create data using conditional statements.\n\nHere we see that we create a new column called Grade and if the score is greater than 90, we populate it with A , if not B. We then process existing data by increasing age by 1.\n\n\nfilter()\nThis method is used to filter rows based on a condition. Here is how it is used:\n\nHere we filter the rows and include rows in the data frame ONLY if the score was equal to or greater than 90.\n\n\nselect()\nThis is like the select query in sql, and you use this to select columns you are interested in.\n\n\n\ngroup_by()\nHere you group the data into groups due to a column, like gender for instance. You can then do group wide operations.\n\n\n\nData Wrangling\nNow this is the code we are supposed to run to prepare the data. Before we prepare the data let’s take a step back.\nOur purpose here is to build a choropleth map that shows you the distribution of the dependency variable across the country/ per region. The dependency variable is calculated like so: DEPENDENCY = (YOUNG + AGED) /`ECONOMY ACTIVE. Thus, we need to know the number of people who are young, aged and economy active in each region. Hence, we have to make sure we make rows that tell us these values per region - that requires group by the two values PA and SZ. We can also group_by AG first so we can see the number of people per age group in each location.\nI have added the explanation for each line of code above that code.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  # we then just want to display columns that are these\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\nCode walkthrough\n\nfilter(Time == 2020) %&gt;%\n\nHere, we are only selecting the rows that have the value 2020 under the time category.\nHere’s a sample data set to help you understand.\n\n\ngroup_by(PA, SZ, AG) %&gt;%\n\nIn group by, we make different groups, each with a unique combination of PA, SZ, and AG. Any row in the dataset that matches that group’s combination of PA, SZ, and AG will be in that group. Hence, each group will have different number of rows. All of the columns of the row will still be there when just executing a group_by(). When grouping, we can do group wide operations, instead of data wide.\n\nsummarise(POP = sum(Pop)) %&gt;%\n\nWe now have the data in groups, with each group having different number of rows.\nWe then add up all the population figures of all the rows in each group and store them in a new column called pop. Now, since the population values in all rows in each group are added together, we have one row per group. Each group has its own combination of pa, sz and ag and its aggragated total summary for population. All the other columns like sex and tod are discarded. You chose to add the population values of all rows together, and did not mention what to do with the other rows, hence they are discarded!\nIn the picture below, you can see that the number of rows have decreased as there were some groups with more than 1 row, and when the population values were added, they were summarised into a row.\nWe now know the number of people per age group per region. This is vital because we have different categories such as young, aged and economy active that we need to compute. Each young, aged and economy active category would consitute of different age categories. Having various different age categories allows us to pick and choose the varying age categories we want to compute to find out the population for each of the young, aged and economy active categories for each region.\n\n\npivot_wider(names_from=AG, values_from=POP) %&gt;%\n\nTo make it easier to compute the population values for each young, aged and economy active category per region, we should make the age categories column names. Then, we can make the population the values under each age category. As illustrated below, we can easily see the number of people per age category per region.\n\n\nmutate(YOUNG = rowSums(.[3:6]) +rowSums(.[12])) %&gt;%\n\nAs we said before, there are different age categories , like 0-4 being one column 5-9 being another column. Hence, we add up populations under columns 3 to 6 in each row as that is the age range that we think is young. After calculating that for each row, we create a column called young and populate it.\n\n\nmutate(ECONOMY ACTIVE = rowSums(.[7:11])+ rowSums(.[13:15]))%&gt;%\n\nnext we want to find out what is the total number of pople in each subzone that are economically active. so we want to add up the values under age range categories that we think are eco active in each row and then make a eco active column and populate it underneath that\n\nmutate(AGED=rowSums(.[16:21])) %&gt;%\n\nDo the same thing for total number of people for each subzone\n\nmutate(TOTAL=rowSums(.[3:21])) %&gt;%\n\nDo the same thing for total number of people for each subzone\n\nmutate(DEPENDENCY = (YOUNG + AGED) /ECONOMY ACTIVE) %&gt;%\n\nwe then calculate the dependency\n\nselect(PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY)\n\nwe then just select the columns we want\n\n\n\n\n\nJoining attribute and geographical data\nThe values in PA and SZ are made up of lower and upper case so lets make them all uppercase\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNow let’s join them based on one common column that is SZ - it is present in both the geospatial and attribute data.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nLet’s write it into a file. Remember to create the directory and file data/rds/mpszpop2020.rds before executing this.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "Choropleth Mapping Geospatial Data using tmap",
    "text": "Choropleth Mapping Geospatial Data using tmap\nYou can do this two ways\n\nPlotting a thematic map quickly by using qtm()\nPlotting highly customisable thematic map by using tmap elements\n\n\nUsing qtm()\nWhen we say fill = “DEPENDENCY”, we mean that the colors of the choropleth map would vary based on the values of dependency.\nThis method is quick but reduces the scope for customization.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\nUsing tmap()\nWe can start of with learning about using tm_shape() and tm_fill().\nWe are showing a geographical distribution of dependency.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nIf we wanted to customise more, and use tm_borders,\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nIf we wanted ultimate customisation, these are the functions and arguments available.\nstyle= quantile shows that we use quantile to classify the data and come up with categories/classes. This means there are four categories with the number of data points each category being equal.\nThe palette=blues is the theme of the map.\nThe layout method often focuses on the aesthetics of the map and is quite self explanatory.\ntm_compass() adds a compass to the map.\ntm_scale_bar() adds the scale to show the relationship between the real measurements to the measurements on the screen.\ntm_grid() adds grid lines to show longitutde and latitude.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nHere we have used tmap and used tm_shape() + tm_fill(). tm_fill() automatically draws out polygons in your map and fills them with the color necessiated by its relevant value.\nLet’s say you wanted to draw other shapes in your map other than polygons. You could do that with tm_lines() or tm_raster()\nBut let’s say we wanted to say outright that we wanted to draw out polygons. We can use tm_polygons()\n\n\nUsing tm_polygons()\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\nRemember: we have to do tm_shape first to load our data in.\nIf we wanted to also say what variable we wanted to show a geographical distribution of :\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\nDrawing a choropleth map using tm_fill() and *tm_border()*\nWritten right underneath the tmap section for better flow.\n\n\nData classification methods of tmap\nThere are different ways to classify data into categories.\n\nPlotting choropleth maps with built-in classification methods\nHere we are using jenks, which means it looks for natural clusters in the data and then groups them together. And we are looking to divide the data into 5 natural clusters.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can also use equal, where the interval in data values is equal. But this will not be good when the data is skewed in one direction as there might not be any data points in many of the intervals.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nDIY (1)\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\nLet’s try sd:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s try quantile:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nI can see that quantile shows more of a geographic distribution. sd shows a lesser range- perhaps the sd was too huge. Hence, there were large number of data points per category and consequently, the number of categories was also less - showing less of a range.\n\n\nDIY (2)\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\nLet’s try quantile.\nLet’s start with 6 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s start with 6 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 7,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can see the map when the classes are 5,6 and 7. As it increases from 5 to 6, we get a greater nuance in the geographic distribution of the dependency column. However, when we go from 6 to 7, there is not much of an increase in nuance. The difference in category boundaries are very minimal. Hence, the ideal number of classes would be 6.\n\n\nPlotting choropleth maps with custom breaks\nIn the methods we used before, the breakpoints were set automatically by them. If we wanted to define the boundaries of each category ourselves, we can do that too. However, to do that, we need more information about the data to understand it. Getting the data’s mean/quantile values, minimum, median, can help with setting those boundaries.\nSo let’s get those values through the use of this method.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nNow let’s choose our breakpoints and plot the choropleth map.\nOur breakpoints are at 0, 0.6. 0.7, 0., 0.9, 1.00.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nColor Scheme\nNow on to the fun part! We get to delve into the color scheme of things\n\nUsing ColourBrewer palette\nLet’s try the blue palette.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s try the green palette.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nMap Layouts\nWhen we talk about map layouts, we want to control how a map looks. We want to ensure that all aspects of a map are present. This includes the title, the scale bar, the compass, legend, margins and aspect ratios. We also can control the style of the map.\n\nMap Style\nThis refers to tmap_style(), not the style argument in your tm_fill where you declare the type of data classification you choose to employ.\nIt controls how your map would look like. These are the arguments you could use:\nThe available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \nIf we were to use classic:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\nIf we used dark,\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"cobalt\")\n\n\n\n\n\n\nMap Legend\nLet’s try adding the legend first.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s go through what the legend part of the code means.\nlegend.hist= TRUE means that we are going to include a histogram like legend. This will allow the viewer to see the distribution of values in the form of a histogram as well.\nlegend.is.portrait = TRUE means that the legend/histogram will be in portrait orientation.\nlegend.hist.z=0.1 means the legend will be slightly behind the map.\n\n\nCartographic furniture\nThis refers to adding of the compass, scale bar and grid lines that we talked about earlier.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\nDrawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arranged side-by-side or vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\nBy assigning multiple values to at least one of the aesthetic arguments\nHere you want both to have the data classification of equal.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nNow, you want each of them to have different data classifications, and different looks.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nIn these two sets of graphs (4), the two maps in each set are showcasing different variables across Singapore . In the first set, we show the distribution of young and then the distribution of old.\nNow what if we wanted the maps to be linked to each other, as in, show the distribution of the same variable?\n\n\nBy defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nHere, we show the distribution of the same dependency variable across multiple regions.\n\n\nBy creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\nMappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "here we are doing spatial point analysis where we are basically studying and analysing the spread of points in a space.\nIt helps us answer tje following questions:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "IS415-GAA",
    "section": "",
    "text": "here we are doing spatial point analysis where we are basically studying and analysing the spread of points in a space.\nIt helps us answer tje following questions:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#data",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#data",
    "title": "IS415-GAA",
    "section": "Data",
    "text": "Data\n\nchildcare\nMP14_SUBZONE_WEB_PL\nCostalOutline"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#installing-and-loading-the-r-packages",
    "title": "IS415-GAA",
    "section": "Installing and loading the R packages",
    "text": "Installing and loading the R packages\nWe need to install and load the R packages into the R environment to use them\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)\n\nIf you aren’t able to install maptools, do this:\n\ninstall.packages(\"maptools\", repos=\"http://R-Forge.R-project.org\")\n\nWarning: package 'maptools' is in use and will not be installed"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#spatial-data-wrangling",
    "title": "IS415-GAA",
    "section": "Spatial Data Wrangling",
    "text": "Spatial Data Wrangling\n\nImporting the spatial data\nWe will use the st_read() function of sf package to import geospatial datasets into R.\nLet’s import the first one of ChildCareServices:\n\nchildcare_sf &lt;- st_read(\"data/ChildCareServices.geojson\")\n\nReading layer `ChildCareServices' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe can see that the CRS is not what we want let’s transform it to SVY21\n\nchildcare_sf &lt;- st_transform(childcare_sf, crs = 3414)\n\nLet’s print out childcare_sf to see what is the CRS.\n\nst_geometry(childcare_sf)\n\nGeometry set for 1925 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (40985.94 33848.38 0)\n\n\nPOINT Z (28308.65 45530.47 0)\n\n\nPOINT Z (17828.84 36607.36 0)\n\n\nPOINT Z (25579.73 29221.89 0)\n\n\nPOINT Z (38981.02 32483.41 0)\n\n\nLet’s import coastal outline.\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nWhen we look at the coordinate reference system of coastal outline, we see that the user input is SVY21 but the correct EPSG code is 9001 instead of 3414.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSo here we change it to 3414.\nReminder we don’t use st_transform() because the CRS is already SVY21, it’s just the ESPG code that is wrong!\n\nsg_sf &lt;- st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow let’s recheck if the coordiante system and ESPG code match.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNow let’s import MP_14_SUBZONE_WEB_PL.\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nLet’s check the coordinate system, it has to be SVY21 so that it is projected coordinate system, and the ESPG code has to match the SVY21.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince it’s 9001 and not 3414, let’s change the code.\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nLet’s check.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nMapping the Geospatial data sets\n\ncol_names &lt;- names(childcare_sf)\nprint(col_names)\n\n[1] \"Name\"        \"Description\" \"geometry\"   \n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +\n  tm_shape(childcare_sf) +  \n  tm_dots()"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "title": "IS415-GAA",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\nAlthough simple feature data frame is gaining popularity again sp’s Spatial* classes, there are, however, many geospatial analysis packages require the input geospatial data in sp’s Spatial* classes. In this section, you will learn how to convert simple feature data frame to sp’s Spatial* class.\n\nConverting sf data frames to sp’s Spatial* class\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\n#print(as.data.frame(childcare))\n\n\n#childcare\n\n\n#mpsz\n\n\n#sg\n\n\n\nConverting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. \nSpatial* classes -&gt; Spatial -&gt; ppp\nLet’s do spatial* classes -&gt; spatial first\nRemeber to use the correct type of shape\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nWhat are the differences between Spatial* classes and generic sp object?\nIn summary, you would use Spatial* classes when you have simple spatial data without additional attributes, and you want a straightforward representation of points, lines, or polygons. On the other hand, if your spatial data includes associated attributes and you need to perform in-depth analysis, you would use generic sp objects like SpatialPointsDataFrame or SpatialPolygonsDataFrame.\nFor example, if you only need to plot the locations of childcare centers on a map, you can use the SpatialPoints class. However, if you want to perform statistical analysis on the childcare data, including attributes such as capacity or age group, you would convert it into a SpatialPointsDataFrame, which allows you to work with both spatial and attribute data seamlessly.\n\n\nConverting the generic sp format into spatstat’s ppp format\nsp -&gt; ppp. And now you can put it into spatstat.\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1925 points\nwindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\nwhat’s the difference between plotting a geojson with spatial points and plotting the same data thats converted to ppp format\nPlotting a GeoJSON file with spatial points typically results in a standard spatial point map. Each point is displayed as a symbol or marker on the map, and you can customize the appearance of the points, such as color, size, and shape.\nConverting data to ppp format is typically done when you intend to perform spatial point process analysis. In this context, a point pattern represents the locations of events or objects of interest (e.g., tree locations, disease cases). ppp objects are used in the spatstat package for advanced spatial point pattern analysis. This includes tasks like assessing spatial clustering, estimating intensity, performing K-functions analysis, and simulating point patterns under different models.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\nHandling duplicated points\nDuplicates, in this context, are multiple points that occupy exactly the same location in space.\nCoincident points are points that are so close to each other that they are considered to occupy the same location within a certain tolerance threshold.\nThese duplicates or coincident points can occur for various reasons, such as measurement errors, data collection methods, or the nature of the phenomenon being studied.\nLet’s check if there are any duplicates in the data:\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nThe multiplicity() function is a function or method typically provided by spatial point pattern analysis software or packages like spatstat. Its purpose is to calculate the multiplicity of points in a point pattern. Multiplicity refers to the number of points that occupy the same location (coincident points) at each location where such coincidences occur.\n\n# Count the number of coincident\n#points in the childcare_ppp point pattern\nmultiplicity(childcare_ppp)\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\nThere are three different approaches to address the issue of duplicate points in spatial point pattern analysis:\n\nDeleting Duplicates: This is the simplest approach, where you remove the duplicate points from your dataset. However, this method comes with a drawback, as it may result in the loss of valuable point events. If each point represents a meaningful observation, deleting duplicates can lead to the omission of important data.\nJittering: The second solution involves adding a small random perturbation to the duplicate points. This perturbation is often referred to as “jitter,” and it introduces a slight variation in the spatial locations of duplicate points, ensuring that they do not occupy the exact same space. Jittering is a way to retain all points while avoiding the issue of perfect overlap.\nAttaching Duplicates as Marks: The third solution is to treat each point as “unique” and then attach the duplicates of the points as marks or attributes of the points. In this approach, duplicate points are not removed or perturbed; instead, they are associated with additional information or attributes. This allows you to preserve all observations while acknowledging their duplications. Analytical techniques that consider these marks can be applied to study the spatial pattern or relationships among points.\n\n\nJittering\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nLet’s check if there are any duplicate points\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nCreating owin object\nThe owin object is essentially a spatial window that limits the analysis to a specific polygonal region. It provides a framework for handling point patterns within this spatial window. This is particularly important when you want to account for the geographic boundaries of the study area in your analysis.\n\n# this is from generic spatia lclass to owin\nsg_owin &lt;- as(sg_sp, \"owin\")\n\n\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\n\nCombining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "IS415-GAA",
    "section": "First-order Spatial Point Patterns Analysis",
    "text": "First-order Spatial Point Patterns Analysis\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics\n\n\nKernel Density Estimation\n\nComputing kernel density estimation using automatic bandwidth selection method\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\n\nCode walkthrough:\n\ndensity: estimate density of a dataset\nsigma=bw.diggle\n\nsigma refers to the bandwidth / radius of the circle/base of the hill. remember, each hill would be given a weight at its peak and it slowly gradually decreases as it goes to the sides.\nbw.diggle is how we calculate the bandwidth\nkernel=gaussian refers to the smoothening method. we know the density is the top of the hill, and how it smoothens out to the edges of the hill is controlled by the kernel method\n\n\n\nplot(kde_childcareSG_bw)\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nHow do you recover bandwidth:\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n306.6986 \n\n\n\n\nRescalling KDE values\nkde_childcareSG_bw stores the density information / the density at different parts of the geographic space.\nNormally, density in the context of kernel density estimation is expressed in terms of “number of points per unit area.” Since the unit here is meters, the density is being expressed as “number of points per square meter.” This means that the value you see (like 0.000035) represents how many points you would expect to find in a square meter of space.\nWhy the Values are Small: Given that a square meter is a relatively small area for most geographical data (like locations of childcare centers, if that’s what your data represents), it’s common for the density values to be very small, especially if the points (childcare centers in this example) are not extremely densely packed.\nIn practical terms, when dealing with such small values in a large area (like a city or country), we might consider transforming the scale of your data or adjusting the units of measurement to make the data more interpretable. For instance, we could convert the densities into “number of points per square kilometer” by multiplying the densities by 1,000,000 (since there are 1,000,000 square meters in a square kilometer). This could make the values more comprehensible in a broader geographical context.\nIn the code chunk below, rescale() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp.km &lt;- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nplot(kde_childcareSG.bw)\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend).\n\n\n\nWorking with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.159749 1.396455 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.3066986 \n\n\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\nWorking with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\npar(mfrow=c(2,2)) plot(density(childcareSG_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=“gaussian”), main=“Gaussian”) plot(density(childcareSG_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=“epanechnikov”), main=“Epanechnikov”) plot(density(childcareSG_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=“quartic”), main=“Quartic”) plot(density(childcareSG_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=“disc”), main=“Disc”)"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "title": "IS415-GAA",
    "section": "Fixed and Adaptive KDE",
    "text": "Fixed and Adaptive KDE\n\nComputing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nplot(kde_childcareSG_600)\n\n\n\n\n\n\nComputing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, you will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\nConverting KDE output into grid object\nA grid object in spatial analysis represents a regular tessellation of a surface into cells or squares, each with its own value. In the context of KDE output, each cell in the grid would represent the estimated density of points within that cell.\nWhy do we do this?\nCell-wise Comparisons: Once the KDE output is in a grid format, you can perform cell-wise comparisons or calculations. For example, you might want to find areas where the density exceeds a certain threshold or calculate the total area that has a density within a specific range.\nIntegration with GIS Tools: Many Geographic Information System (GIS) tools are optimized to work with grid data. Converting KDE output to a grid format makes it easier to use these tools for further analysis, modeling, or mapping.\nLet’s convert\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\n\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\nConverting gridded output into raster\nWhy do we do this?\nBoth raster data and gridded outputs represent spatial information using a grid format, but they serve slightly different purposes and have varying degrees of compatibility with Geographic Information Systems (GIS) and third-party tools.\n\nInteroperability with GIS and Tools: While both gridded outputs and raster data are grid-formatted, raster data is specifically formatted for and thus more directly interoperable with GIS software and third-party tools. Raster formats are designed to be easily imported, manipulated, analyzed, and visualized in GIS platforms.\nMetadata and Georeferencing: Raster datasets typically include metadata and georeferencing information, making them immediately useful for spatial analyses without requiring additional steps to define the spatial extent, projection, or coordinate system.\nEfficiency and Compatibility: Raster formats often support compression, pyramids for efficient zooming, and spatial indexing, which enhances their performance in GIS applications. They are widely supported across different platforms, ensuring compatibility and ease of use in various analyses and application contexts.\n\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -1.014191e-14, 32.45281  (min, max)\n\n\ndimensions: 128, 128, 16384:\n\nnrow: The raster has 128 rows.\nncol: The raster has 128 columns.\nncell: The total number of cells (or pixels) in the raster is 16,384, which is the product of the number of rows and columns (128 x 128).\n\nresolution: 0.4170614, 0.2647348 (x, y): This specifies the size of each cell in the units of the raster’s coordinate reference system (CRS). The first number is the width of each cell (x-direction), and the second number is the height of each cell (y-direction). This tells you how much geographic area each pixel represents.\n\n\nAssigning projection systems\nWe saw that there was no projection system on the raster variable. So let’s assign it!\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.014191e-14, 32.45281  (min, max)\n\n\n\n\n\nVisualising the output in tmap\nFinally, we will display the raster in cartographic quality map using tmap package\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nVariable(s) \"v\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nif i did not put tm_raster i would have put tm_fill or tm_polgon.tm_raster, tm_fill, and tm_polygon are functions used within the tmap package in R to add different types of layers to a map,\ntm_raster is specifically designed for adding and visualizing raster data layers on a map.\n\n\ntm_fill and tm_polygon\n\ntm_fill: This function is used to add and visualize areas on a map by filling them with colors based on their attributes. It’s often used with spatial polygons data where each polygon represents a distinct area, such as countries, states, districts, or other regions.\ntm_polygon: Very similar to tm_fill, tm_polygon is used to add polygon layers to a map. It can fill the polygons with color based on their attributes and also allows for the customization of border colors and styles. Essentially, tm_fill is a shortcut for tm_polygon with a focus on filling the polygons rather than styling their borders.\n\n\n\nComparing Spatial Point Patterns using KDE\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas\n\n4.7.5.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\nplot(pg, main = \"Ponggol\")\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\nConverting the spatial point data frame into generic sp format\nso mspz, and any data from it was converted from sf to sp’s spatial* class\nIn summary, you would use Spatial* classes when you have simple spatial data without additional attributes, and you want a straightforward representation of points, lines, or polygons. On the other hand, if your spatial data includes associated attributes and you need to perform in-depth analysis, you would use generic sp objects like SpatialPointsDataFrame or SpatialPolygonsDataFrame.\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\nCreating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\nspatstat cant take generic sp obejcts and tehy need to be converted into owin objects\nThis is so that we confine our geospatial analysis to that area.\n\nConverting sp Objects to spatstat Objects\nTo use sp objects with spatstat, you generally need to convert them into a format that spatstat understands:\n\nFrom sp to owin: If you have a spatial polygons object from the sp package that defines the study area or observation window, you would convert it to an owin object to define the observation window in spatstat.\nFrom sp Point to ppp: Similarly, if you have point data in an sp format, you would convert it to a ppp object (point pattern object) for analysis in spatstat.\n\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\nchildcare_ppp_jit was made when we tried to remove duplicated points. And that was made from childcare_ppp that was made from an sp object, as ppp objects were needed to put into the spatstat object for spatial analysis.\n\n\n\nCombining childcare points and the study area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\n\n\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\n\n\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\n\n\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\nComputing KDE\nLet’s compute KDE in each location!\n\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\n\n\n\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\n\n\n\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\n\n\n\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\nComputing fixed bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth\n\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\n\n\n\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\n\n\n\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "title": "IS415-GAA",
    "section": "Nearest Neighbour Analysis",
    "text": "Nearest Neighbour Analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\nTesting spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.5062, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\nClark and Evans Test: Choa Chu Kang planning area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.86401, p-value = 0.02523\nalternative hypothesis: two-sided\n\n\n\n\nClark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.67993, p-value = 3.516e-11\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "data/MPSZ-2019.html",
    "href": "data/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "",
    "text": "Hello! In this page, i will be describing how i performed data wrangling - which is basically cleaning and transforming raw data into a more structured and usable format or later analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Installing and loading R packages",
    "text": "Installing and loading R packages\nIn this section, I will install and load ‘tidyverse’ and ‘sf’ packages.\n\nWhat are the sf and tidyverse packages?\nLet me give you a break down.\n\nTidyverse Package\nImagine you have a pile of dirty data that you need to handle. The Tidyverse package helps you handle your data. It actually has a bunch of packages within it to help handle data. It can do the following:\n\nreadr - reading and writing data into or out of a spreadsheet\ntidyr - organizing and tidying up your data\nggplot2 - visualizing your data\ndpylr - mainpulating your data, like doing some basic math to it.\n\n\n\nSF Package\nSF package provides us with tools to work with data related to maps and geospatial data. It can\n\nRead and write geospatial data from and into files.\nManipulate data - like cut out a specific area on a map\nVisualize data\n\nNow let’s load the packages into our environment.\n\n# Loads the p_load function on pacman which checks if packages are available, and then loads them into the R environment.\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\n\nImporting the geospatial data in shapefile format\nHere we import the geospatial data which is in shapefile format as a a polygon feature data frame.\n\nWhat is a shapefile and what is a polygon feature data frame?\n\nShapefile\nShapefile format stores geographic location and attribute information of geographic features.\n\n\nPolygon feature data frame\nThink of polygons as shapes that represent areas on a map.\nData frames store details about the polygons (think area) on tables.\nSo polygon feature data frames store data about areas on the map.\n\n#st_read is a function from the SF package which helps with the handling of data. We read the data into the variable mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n layer  = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\nImporting polyline feature data in shapefile form\n\nWhat is a polyline feature data frame?\nA polyline is made up of connected points and can represent things such as roads, rivers, or hiking trails.\nFeature Data Frames store information about these lines, like what is the name of the road, how long is it, what’s its surface?\nA polyline feature data frame stores information on lines that represent routes or rivers on a map.\nNow let’s import the polyline feature data\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\nImporting GIS data in kml format\n\nWhat is a GIS data and kml format ?\n\nkml format\nIt is keyhole markup language used to describe places and features on a digital map. You can define shapes like drawing a line to show a hiking trail or a polygon to show a lake. You can also attach information to places.\n\n\nGIS data\nA map has information like shapes, paths, data and locations. GIS data is when all this information is organized in a computer friendly way. People use these data to analyse the environment, plan cities and much more.\nNow let’s import GIS data in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Checking out the contents of a simple feature data frame",
    "text": "Checking out the contents of a simple feature data frame\n\nst_geometry\nShapes represent areas on a map. The data.frame in the package sf contains a column, and that column contains a list of those shapes in the specific class called ‘sfc’.\nLet’s execute this command\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThis commands tells you a few things:\n\nThe types of shapes you’re dealing with. Multipolygon means its an area with multiple connected lines.\nThe bounding box/ range of coordinates that coer the same\nAlso the first 5 shapes in the column of the data frame\n\n\n\nglimpse\nLet’s execute this command\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThis command gives you a glimpse into the dataset.\nit tells you the following things:\n\nthe number of rows\nthe number of columns\nwhat columns are there\ndata type of each column\nfirst few values of each column\n\n\n\nhead()\nLet’s execute this command\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThis provides you with complete information (columns and the number of values u want)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Plotting Data",
    "text": "Plotting Data\nNow, let’s plot the data in our mpsz as a visualization. We use the plot() function for it.\nThis provides the entire visualization.\n\nplot(mpsz)\n\n\n\n\nIf you want to just plot the different shapes in the map, we can do this:\n\nplot(st_geometry(mpsz))\n\n\n\n\nIf you want to plot just based off of one column/attribute, you can do this. Each color reprsents the a row.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Working with projection",
    "text": "Working with projection\nThere are multiple ways you can study geography. You can study it if it were on a flat piece of paper or curved 3d way on your laptop screen.\nWhen there are two different ways of expressing geography, the way the data is, is differnet. If you want to use two sets of geospatial data, you want to ensure the data has the same projection, i.e. represents locations on the earth’s surface the same way. Hence, you will have to translate one of the maps to the same projection of another.\n\nWorking with projection\nOne of the common issues that can happen is that the coordinate system of a geospatial data is mising or incorrect. To check and input the correct coordinate system, we execute the following command to check the coordinate reference system.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nthen check at the end of the print if the ESPG code corresponds correctly to the coordinate system. Here, svy21 should correspond to 3414 not 9001. So we change it!\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow let’s double check if the ESPG code is correct\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nWorking with projection\nSometimes we change projection of a geospatial data to one that is congrunet with the type of analysis we are making.\nFor example, geographic coordinate system may not be appropriate if the analysis needs to use distance or/and area measurements.\nlet’s do some transformation here.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\n##Importing and Converting An Aspatial Data\n\n\nWhat is aspatial data?\nLet’s back track. Spatial data refers to physical location, shapes and positions of the objects on the earth’s surface.\nAspatial data refers to characteristics or properties of those objects. Airbnb is asptial data, so it focuses on what kind of house is it, how many bed rooms how many bathrooms, maybe its rental per night.\n\n\nImport spatial data\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nLet’s explore the data.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n###Creating a simple feature data frame from an aspatial data frame\nLet’s do some conversion : transform one coordinate system to another.\nFirst code line, we convert the aspatial data from to a simple feature data frame. Then we change the coordinate system.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\nHere, we will be learning about buffering and point in polygon.\n###Buffering\n####What is bufferring\nLet’s say there is a point of interest like a cycling path You want to analyse a certain amount of area around it, and the amount would be the buffer. Let’s say buffer is 5, you would want to study the area in a 5 mile radius around it.\nLet’s have another working scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nLet’s create a data frame with a buffer zone around the cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nYou created the buffer in the previous command , now you can calculate the total area of the buffer by doing so.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nNow the summation of the buffer land and the exisiting cycling path- total land involved.\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n###Point-in-polygon count\n####What is Point-in-polygon count\nIt refers to counting the number of points in an area (polygon)\nLet’s say, a pre-school service group wants to find out the numbers of pre-schools in each Planning Subzone.\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nZone with most preschools\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nCalculate density of presch\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n##Exploratory Data Analysis (EDA)\nLet’s visualize our data to get a better idea of it.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\n\n\n\nHello! In this page, i will be describing how i performed data wrangling - which is basically cleaning and transforming raw data into a more structured and usable format or later analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Installing and loading R packages",
    "text": "Installing and loading R packages\nIn this section, I will install and load ‘tidyverse’ and ‘sf’ packages.\n\nWhat are the sf and tidyverse packages?\nLet me give you a break down.\n\nTidyverse Package\nImagine you have a pile of dirty data that you need to handle. The Tidyverse package helps you handle your data. It actually has a bunch of packages within it to help handle data. It can do the following:\n\nreadr - reading and writing data into or out of a spreadsheet\ntidyr - organizing and tidying up your data\nggplot2 - visualizing your data\ndpylr - mainpulating your data, like doing some basic math to it.\n\n\n\nSF Package\nSF package provides us with tools to work with data related to maps and geospatial data. It can\n\nRead and write geospatial data from and into files.\nManipulate data - like cut out a specific area on a map\nVisualize data\n\nNow let’s load the packages into our environment.\n\n# Loads the p_load function on pacman which checks if packages are available, and then loads them into the R environment.\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\n\nImporting the geospatial data in shapefile format\nHere we import the geospatial data which is in shapefile format as a a polygon feature data frame.\n\nWhat is a shapefile and what is a polygon feature data frame?\n\nShapefile\nShapefile format stores geographic location and attribute information of geographic features.\n\n\nPolygon feature data frame\nThink of polygons as shapes that represent areas on a map.\nData frames store details about the polygons (think area) on tables.\nSo polygon feature data frames store data about areas on the map.\n\n#st_read is a function from the SF package which helps with the handling of data. We read the data into the variable mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n layer  = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\nImporting polyline feature data in shapefile form\n\nWhat is a polyline feature data frame?\nA polyline is made up of connected points and can represent things such as roads, rivers, or hiking trails.\nFeature Data Frames store information about these lines, like what is the name of the road, how long is it, what’s its surface?\nA polyline feature data frame stores information on lines that represent routes or rivers on a map.\nNow let’s import the polyline feature data\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\nImporting GIS data in kml format\n\nWhat is a GIS data and kml format ?\n\nkml format\nIt is keyhole markup language used to describe places and features on a digital map. You can define shapes like drawing a line to show a hiking trail or a polygon to show a lake. You can also attach information to places.\n\n\nGIS data\nA map has information like shapes, paths, data and locations. GIS data is when all this information is organized in a computer friendly way. People use these data to analyse the environment, plan cities and much more.\nNow let’s import GIS data in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Checking out the contents of a simple feature data frame",
    "text": "Checking out the contents of a simple feature data frame\n\nst_geometry\nShapes represent areas on a map. The data.frame in the package sf contains a column, and that column contains a list of those shapes in the specific class called ‘sfc’.\nLet’s execute this command\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThis commands tells you a few things:\n\nThe types of shapes you’re dealing with. Multipolygon means its an area with multiple connected lines.\nThe bounding box/ range of coordinates that coer the same\nAlso the first 5 shapes in the column of the data frame\n\n\n\nglimpse\nLet’s execute this command\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThis command gives you a glimpse into the dataset.\nit tells you the following things:\n\nthe number of rows\nthe number of columns\nwhat columns are there\ndata type of each column\nfirst few values of each column\n\n\n\nhead()\nLet’s execute this command\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThis provides you with complete information (columns and the number of values u want)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Plotting Data",
    "text": "Plotting Data\nNow, let’s plot the data in our mpsz as a visualization. We use the plot() function for it.\nThis provides the entire visualization.\n\nplot(mpsz)\n\n\n\n\nIf you want to just plot the different shapes in the map, we can do this:\n\nplot(st_geometry(mpsz))\n\n\n\n\nIf you want to plot just based off of one column/attribute, you can do this. Each color reprsents the a row.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection-3",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection-3",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Working with projection",
    "text": "Working with projection\nThere are multiple ways you can study geography. You can study it if it were on a flat piece of paper or curved 3d way on your laptop screen.\nWhen there are two different ways of expressing geography, the way the data is, is differnet. If you want to use two sets of geospatial data, you want to ensure the data has the same projection, i.e. represents locations on the earth’s surface the same way. Hence, you will have to translate one of the maps to the same projection of another.\n\nWorking with projection\nOne of the common issues that can happen is that the coordinate system of a geospatial data is mising or incorrect. To check and input the correct coordinate system, we execute the following command to check the coordinate reference system.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nthen check at the end of the print if the ESPG code corresponds correctly to the coordinate system. Here, svy21 should correspond to 3414 not 9001. So we change it!\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow let’s double check if the ESPG code is correct\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nWorking with projection\nSometimes we change projection of a geospatial data to one that is congrunet with the type of analysis we are making.\nFor example, geographic coordinate system may not be appropriate if the analysis needs to use distance or/and area measurements.\nlet’s do some transformation here.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\n##Importing and Converting An Aspatial Data\n\n\nWhat is aspatial data?\nLet’s back track. Spatial data refers to physical location, shapes and positions of the objects on the earth’s surface.\nAspatial data refers to characteristics or properties of those objects. Airbnb is asptial data, so it focuses on what kind of house is it, how many bed rooms how many bathrooms, maybe its rental per night.\n\n\nImport spatial data\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nLet’s explore the data.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n###Creating a simple feature data frame from an aspatial data frame\nLet’s do some conversion : transform one coordinate system to another.\nFirst code line, we convert the aspatial data from to a simple feature data frame. Then we change the coordinate system.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\nHere, we will be learning about buffering and point in polygon.\n###Buffering\n####What is bufferring\nLet’s say there is a point of interest like a cycling path You want to analyse a certain amount of area around it, and the amount would be the buffer. Let’s say buffer is 5, you would want to study the area in a 5 mile radius around it.\nLet’s have another working scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nLet’s create a data frame with a buffer zone around the cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nYou created the buffer in the previous command , now you can calculate the total area of the buffer by doing so.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nNow the summation of the buffer land and the exisiting cycling path- total land involved.\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n###Point-in-polygon count\n####What is Point-in-polygon count\nIt refers to counting the number of points in an area (polygon)\nLet’s say, a pre-school service group wants to find out the numbers of pre-schools in each Planning Subzone.\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nZone with most preschools\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nCalculate density of presch\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n##Exploratory Data Analysis (EDA)\nLet’s visualize our data to get a better idea of it.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4 : Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute spatial weights using R. By the end to this hands-on exercise, you will be able t\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "title": "Hands-on Exercise 4 : Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute spatial weights using R. By the end to this hands-on exercise, you will be able t\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#the-study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#the-study-area-and-data",
    "title": "Hands-on Exercise 4 : Spatial Weights and Applications",
    "section": "8.2 The Study Area and Data",
    "text": "8.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n8.2.1 Getting Started\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-the-data-into-r-environmen",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-the-data-into-r-environmen",
    "title": "Hands-on Exercise 4 : Spatial Weights and Applications",
    "section": "8.3 Getting the Data Into R Environmen",
    "text": "8.3 Getting the Data Into R Environmen\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n8.3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n8.3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n8.3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunanNew &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nThe left_join operation combines rows from hunan and hunan2012 based on a common column, which is likely the ID in this case. The result includes all rows from hunan and the matching rows from hunan2012. If there’s no match, the right side will have NA.\nThis indicates the selection of the first to fourth columns, the seventh column, and the fifteenth column."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 4 : Spatial Weights and Applications",
    "section": "8.4 Visualising Regional Development Indicator",
    "text": "8.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunanNew) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunanNew, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 4 : Spatial Weights and Applications",
    "section": "8.5 Computing Contiguity Spatial Weights",
    "text": "8.5 Computing Contiguity Spatial Weights\nWhat are spatial weights?\nThey are used to understand the relationship or connection between two locations.\nWhat are contiguity spatial weights?\nTwo geographical areas are considered neighbours if they share a boundary\nWhat is the sdep package used for?\nOne of the primary functions of the “spdep” package is to analyze spatial autocorrelation. Spatial autocorrelation refers to the degree to which the values of a variable tend to be similar (or dissimilar) in neighboring locations.\nIn this section, you will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n8.5.1 Computing (QUEEN) contiguity based neighbours\n\nwm_q &lt;- poly2nb(hunanNew, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nWhat does this function do?\nIt takes information about shapes or regions (polygons) and figures out which ones are next to each other. It does this by identifying regions that share a common boundary or vertex, essentially defining which regions are neighbors. The function then organizes this information into a list, making it easier to analyze the spatial relationships between regions in the dataset.\nNumber of regions: 88 \nIndicates the total number of regions (or polygons) in the dataset.\nNumber of nonzero links: 448 \nNonzero links refer to a geographical region’s neighbour , and in this context neighbour refers to a region that shares a boundary and tip with another region.\nIn the provided output, it states that there are 448 nonzero links, meaning there are 448 pairs of regions that are directly connected to each other in the spatial dataset.\nPercentage nonzero weights: 5.785124 \nThis represents the proportion of nonzero spatial weights relative to the total possible spatial relationships in the dataset.\nThe percentage nonzero weights indicate how many of these potential connections are actual nonzero links (i.e., regions that are actually neighbors).\nThe “total possible spatial relationships” refers to all potential pairwise connections between regions.\nAverage number of links: 5.090909 \nhe average number of links represents, on average, how many neighbors each location (or region) has in the spatial dataset\nLink number distribution:  \n1  2  3  4  5  6  7  8  9 11   \n2  2 12 16 24 14 11  4  2  1 \nThe numbers on the top(1, 2, 3, 4, 5, 6, 7, 8, 9, 11) represent the count of links. For example, “1” means there are regions with only 1 link, “2” means there are regions with 2 links, and so on.\n2 least connected regions: 30 65 with 1 linkk\n\nThis part identifies the regions with the fewest connections (or links) to neighboring regions.\nIn the example provided, regions 30 and 65 are the least connected, each having only 1 link to neighboring regions.\n\n1 most connected region: 85 with 11 links\n\nThis part identifies the region with the highest number of connections (or links) to neighboring regions.\nIn the example provided, region 85 is the most connected, having 11 links to neighboring regions.\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunanNew$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunanNew$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunanNew$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\n\n\n8.5.2 Creating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunanNew, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n8.5.3 Visualising contiguity weights\nA connectivity graph is a visual representation that shows how points or polygons in a dataset are connected to each other. Each point is connected to its neighboring points through lines or edges.\nSince polygons are being used in the spatial dataset, we use polygon centroids as points to represent each polygon in the connectivity graph.\nin order to create the connectivity graph, the first step is to obtain points associated with each polygon.\nTo achieve this, we use the “sf” package, which is commonly used for handling spatial data in R.\nSpecifically, we use the st_centroid function to calculate the centroids of polygons. However, since the input data is likely in the form of an “sf” object (us.bound), some additional steps are required.\nHence, we use a mapping function.\nA mapping function is like a tool that applies another function to each item in a list or column.\nThe map_dbl function from the “purrr” package is used to do this. It takes each polygon as input, applies the st_centroid function to it, and returns the result.\nAfter finding the centroid for each polygon, we want to extract the longitude value from each centroid.\nThe st_centroid function returns a point, which is like a pair of coordinates (latitude and longitude).\n\nlongitude &lt;- map_dbl(hunanNew$geometry, ~st_centroid(.x)[[1]])\n\nmap_dbl: This function is part of the “purrr” package in R. It’s used to apply another function (in this case, st_centroid) to each element of a vector or list.\nHere, map_dbl is being used to apply st_centroid to each element in the vector hunanNew$geometry.\nThe st_centroid function takes a geometry object as input and returns a point geometry representing the centroid of that shape.\nThe ~ symbol indicates the start of a lambda function (also known as a “formula” or “anonymous” function). It’s a concise way to define a function inline.\nIn this lambda function, .x represents each element of the vector hunanNew$geometry. It’s a placeholder for the current element being processed\nst_centroid(.x) calculates the centroid of the current geometry element.\n[[1]] extracts the first value of the centroid point, which corresponds to the longitude coordinate.\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n8.5.3.1 Plotting Queen contiguity based neighbours map\n\nplot(hunanNew$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n8.5.3.2 Plotting Rook contiguity based neighbours map\n\nplot(hunanNew$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n8.5.3.3 Plotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-distance-based-neighbours",
    "title": "Hands-on Exercise 4 : Spatial Weights and Applications",
    "section": "8.6 Computing distance based neighbours",
    "text": "8.6 Computing distance based neighbours\nIn distance based neigbours, regions are considered neighbours when they are a certain distance apart.\nEuclidean distance is a measure of straight-line distance between two points in a Euclidean space (such as a two-dimensional plane).\nThe dnearneigh() function is part of the “spdep” package in R. It is used to identify neighboring regions (or points) based on Euclidean distance. The function calculates the distances between points and identifies neighboring points within a specified distance band.\nThe distance band is defined by lower (d1) and upper (d2) bounds. The bounds argument allows control over these bounds, specifying the range within which points are considered neighbors based on their distances.\nIf unprojected coordinates are used (i.e., coordinates specified as latitude and longitude) and longlat=TRUE is specified, the function calculates great circle distances in kilometers.\n\n8.6.1 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nfinding k nearest neighbours\n\nThe first step involves finding the k nearest neighbors for each point in the dataset.\nThis is done using the knearneigh() function from the “spdep” package in R.\nThe function returns a matrix with the indices of points that are the k nearest neighbors of each other.\n\neach row corresponds to a data point, and each column contains the indices (or positions) of the k nearest neighbors of that data point in the dataset.\n\n\nconverting output to neighbours list\n\nWhile the matrix returned by knearneigh() provides information about the nearest neighbors, it may not be in the most convenient format for further analysis.\nnew structure allows for easier manipulaton and interpretation of spatial relationships\n\ncalculating length of neighbour relationships\n\nAfter identifying the nearest neighbors for each data point, we want to know how far apart these neighbors are from each other.\nThis distance between neighboring points is referred to as the “length of neighbor relationship edges.”\nTo calculate these distances, we use the nbdists() function from the “spdep” package in R\n\nremoval of list structure\n\nunlist() function converts the output into a simple vector without any nested lists\n\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n8.6.2 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\nThe dnearneigh() function calculates the neighbors of each region (or point) in the dataset based on the specified distance range. If the distance between two regions falls within this distance band, they are considered neighbors according to the spatial weight matrix created by the function.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\ncoords: This is the input data containing the coordinates of the points for which the spatial weight matrix will be calculated.\n0: This value specifies the lower bound of the distance band. In this case, it’s set to 0, meaning that all points within a certain distance (up to the upper bound) will be considered neighbors.\n62: This value specifies the upper bound of the distance band. It determines the maximum distance within which points will be considered neighbors.\nlonglat = TRUE: This argument indicates that the coordinates are given in latitude and longitude, and great circle distances should be used for calculations (measured in kilometers).\n\n\n8.6.2.1 Plotting fixed distance weight matrix\n\nplot(hunanNew$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n8.6.3 Computing adaptive distance weight matrix\nAn adaptive distance weight matrix helps address the issue where densely populated areas (such as urban areas) tend to have more neighbors, while sparsely populated areas (such as rural areas) tend to have fewer neighbors.\nBy adjusting the number of neighbors for each point based on its local density, an adaptive distance weight matrix ensures a more balanced representation of spatial relationships across different regions. This means that each point will have a consistent number of neighbors, regardless of the overall density of the dataset.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\n\n8.6.3.1 Plotting distance based neighbours\n\nplot(hunanNew$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#weights-based-on-idw",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#weights-based-on-idw",
    "title": "Hands-on Exercise 4 : Spatial Weights and Applications",
    "section": "8.7 Weights based on IDW",
    "text": "8.7 Weights based on IDW\nInverse distance calculation is a technique where the relationship between two locations is determined by the inverse of the distance between them.The basic idea is that closer locations have a stronger relationship, while farther locations have a weaker relationship.\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\nThe nbdists() function calculates the distances between points in a neighbors list, which in this case is represented by wm_q.\nThe longlat = TRUE argument indicates that the coordinates are in latitude and longitude format, and great circle distances should be used for the calculations (measured in kilometers)\nOnce the distances are computed, they are transformed using the inverse distance method."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 4 : Spatial Weights and Applications",
    "section": "Row-standardised Weights Matrix",
    "text": "Row-standardised Weights Matrix\nThe goal is to assign weights to neighboring polygons based on their spatial relationships.\nIn this case, each neighboring polygon is assigned equal weight, indicated by the “W” style option.\nEach neighboring polygon is assigned a weight equal to the fraction 1number of neighborsnumber of neighbors1​.\nThis means that the weight assigned to each neighboring polygon is determined by dividing 1 by the total number of neighboring polygons.\nAssigning equal weights ensures that each neighboring polygon contributes equally to the analysis.\nassigning equal weights may lead to potential biases, especially for polygons along the edges of the study area\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#application-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 4 : Spatial Weights and Applications",
    "section": "8.9 Application of Spatial Weight Matrix",
    "text": "8.9 Application of Spatial Weight Matrix\nIn this section, you will learn how to create four different spatial lagged variables, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\nWhat’s a spatial lagged variable?\nImagine you’re studying crime rates in different neighborhoods of a city. You have data on the number of reported crimes in each neighborhood. You’re interested in understanding if the crime rate in one neighborhood is influenced by the crime rates in neighboring neighborhoods.\nThe spatial value is a single value that represents the influence of the neighbours crime rate on the crime rate of the focal area. Spatial lag is a way to measure how the value of something in one area is influenced by the values of the same thing in neighboring areas.\nThe spatial variable, refers to the original variable of interest (in this case, crime rate) for each individual area or observation in the dataset.\nWhat is Spatial lag with row-standardized weights?\nLet’s say we have a small town divided into three neighborhoods: A, B, and C.\n\nNeighborhood A has a crime rate of 10.\nNeighborhood B has a crime rate of 5.\nNeighborhood C has a crime rate of 8.\n\nWe want to calculate the spatial lag for each neighborhood’s crime rate using row-standardized weights.\nStep 1: Determine Neighbors:\n\nLet’s assume that neighborhoods A and B are neighbors, and neighborhoods B and C are neighbors.\n\nStep 2: Calculate Spatial Lag:\n\nFor each neighborhood, we’ll calculate the spatial lag by taking a weighted average of its neighbors’ crime rates.\nFor neighborhood A:\n\nIts neighbors are B and C.\nWeights: Since there are two neighbors, we divide 1 by 2 to get 0.5 for each weight (assuming equal weighting for simplicity).\nSpatial lag for A = (0.5 * 5) + (0.5 * 8) = 6.5.\n\nFor neighborhood B:\n\nIts neighbor is A.\nWeights: There is only one neighbor, so the weight is 1.\nSpatial lag for B = 1 * 10 = 10.\n\nFor neighborhood C:\n\nIts neighbor is B.\nWeights: There is only one neighbor, so the weight is 1.\nSpatial lag for C = 1 * 5 = 5.\n\n\nIn this example, neighborhood A are less influenced by neighbors’ crime rates compared to neighborhood B.\nWhat is spatial lag as a sum of neighboring values?\nLet’s use the same example of a small town divided into three neighborhoods: A, B, and C.\n\nNeighborhood A has a population of 100.\nNeighborhood B has a population of 150.\nNeighborhood C has a population of 200.\n\nWe want to calculate the spatial lag for each neighborhood’s population as a sum of neighboring values.\nStep 1: Determine Neighbors:\n\nLet’s assume that neighborhoods A and B are neighbors, and neighborhoods B and C are neighbors.\n\nStep 2: Calculate Spatial Lag as a Sum:\n\nFor each neighborhood, we’ll calculate the spatial lag by summing the population values of its neighboring neighborhoods.\nFor neighborhood A:\n\nIts neighbors are B and C.\nSpatial lag for A = Population of B (150) + Population of C (200) = 350.\n\nFor neighborhood B:\n\nIts neighbor is A.\nSpatial lag for B = Population of A (100) = 100.\n\nFor neighborhood C:\n\nIts neighbor is B.\nSpatial lag for C = Population of B (150) = 150.\n\n\nStep 3: Interpretation:\n\nThe spatial lag values represent the total population of neighboring neighborhoods for each focal neighborhood.\nIn our example, neighborhood A’s spatial lag of 350 means that its population is influenced by the total population of its neighbors, neighborhoods B and C.\n\nWhat is a spatial window ?\nA spatial window is a defined area or region around a focal observation or point of interest.\nIn spatial analysis, a spatial window is used to group neighboring observations or areas together for analysis.\nA focal observation could indeed be something like the crime rate in a specific area. So, when we talk about a spatial window in the context of crime rates, we’re defining an area around a specific location where we’re interested in understanding the surrounding crime rates.\nWhat is a spatial window average?\nSpatial window average calculates the average value of a variable within a defined spatial window around each observation.\nIt provides insight into the average characteristics of itself and its neighboring areas, considering the variable of interest within a specified spatial context.\nso the difference between the row standardized spatial lag and spatial window average is that in spatial window average we take the focal region into account too but in row standardised we just look at the neighbours\nWhat is spatial window sum?\nso difference between spatial window sum and spatial lag as a sum of neighbouring values is that spatial window sum takes focal region into account\n\n8.9.1 Spatial lag with row-standardized weights\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunanNew$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\n\nlag.list &lt;- list(hunanNew$NAME_3, lag.listw(rswm_q, hunanNew$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunanNew &lt;- left_join(hunanNew,lag.res)\n\n\nhead(hunanNew)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunanNew, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunanNew, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n8.9.2 Spatial lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nBinary weights assign a value of 1 to each neighbor, indicating a binary relationship (either adjacent or not). This step involves creating a binary weight matrix based on the neighbors list.\nThe lapply() function is used to apply a function across each element of the neighbors list (wm_q). Inside the lapply() function, a simple function is defined: function(x) 0*x + 1. This function assigns a value of 1 to each neighbor in the list.\nThe second step involves converting the binary weights list (b_weights) into a binary spatial weights matrix (b_weights2) using the nb2listw() function.\nWhile binary weights have already been assigned in the first step, converting them to a spatial weights matrix format is necessary for certain spatial analysis techniques that require a formal spatial weights object.\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunanNew$NAME_3, lag.listw(b_weights2, hunanNew$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunanNew &lt;- left_join(hunanNew, lag.res)\n\n\nhunanNew\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC lag GDPPC lag_sum GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667  24847.20        124236\n2   Changde 21100   Hanshou      County   Hanshou 20981  22724.80        113624\n3   Changde 21101    Jinshi County City    Jinshi 34592  24143.25         96573\n4   Changde 21102        Li      County        Li 24473  27737.50        110950\n5   Changde 21103     Linli      County     Linli 25554  27270.25        109081\n6   Changde 21104    Shimen      County    Shimen 27137  21248.80        106244\n7  Changsha 21109   Liuyang County City   Liuyang 63118  43747.00        174988\n8  Changsha 21110 Ningxiang      County Ningxiang 62202  33582.71        235079\n9  Changsha 21111 Wangcheng      County Wangcheng 70666  45651.17        273907\n10 Chenzhou 21112     Anren      County     Anren 12761  32027.62        256221\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\ngdppc &lt;- qtm(hunanNew, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunanNew, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n8.9.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\n\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunanNew$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunanNew$NAME_3, lag.listw(wm_qs, hunanNew$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunanNew, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunanNew, \"lag_window_avg GDPPC\")\n\n\n\n8.9.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunanNew$NAME_3, lag.listw(b_weights2, hunanNew$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunanNew &lt;- left_join(hunanNew, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunanNew %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05-Local.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05-Local.html",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05-Local.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05-Local.html#overview",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05-Local.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05-Local.html#getting-started",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "10.2 Getting Started",
    "text": "10.2 Getting Started\n\n10.2.1 The analytical question\nIn spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)\n\n\n10.2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n10.2.3 Setting the Analytical Toolls\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05-Local.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05-Local.html#getting-the-data-into-r-environment",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "10.3 Getting the Data Into R Environment",
    "text": "10.3 Getting the Data Into R Environment\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n10.3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"../Hands-On_Ex04/data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n10.3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"../Hands-On_Ex04/data/aspatial/Hunan_2012.csv\")\n\n\n\n10.3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n10.3.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n10.4.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n10.4.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n10.4.3 Global Spatial Autocorrelation: Moran’s I\nIn this section, you will learn how to perform Moran’s I statistics testing by using moran.test() of spdep.\n\n\n10.4.4 Maron’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n10.4.4.1 Computing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n10.4.4.2 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n10.4.5 Global Spatial Autocorrelation: Geary’s\nIn this section, you will learn how to perform Geary’s c statistics testing by using appropriate functions of spdep package.\n\n10.4.5.1 Geary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n10.4.5.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nWhen you perform a Monte Carlo simulation, you’re essentially creating many random samples (in your case, 1000) based on the null hypothesis, which assumes there is no spatial autocorrelation. Each of these samples will have its own Geary’s C statistic. These simulated statistics create a distribution against which you can compare the Geary’s C statistic from your actual data.\nThe “observed rank” is where the actual Geary’s C statistic falls within this distribution. If the “observed rank” is 1, as in your output, it means that the actual statistic is the smallest out of all the simulated statistics — it’s ranked first, or in other words, no simulated statistic is smaller than the actual one.\n\n\nInterpreting the Observed Rank\nThe observed rank helps to understand the p-value in a Monte Carlo simulation:\n\nA low rank (like 1) means that the actual statistic is at the very low end of the simulated distribution, indicating that the actual observed spatial pattern is more pronounced than almost all patterns generated under the null hypothesis.\nConversely, a high rank would indicate that the actual statistic is at the high end of the simulated distribution, closer to patterns one might expect by chance.\n\nThe rank, when considered with the p-value, tells us about the statistical significance of the actual Geary’s C statistic:\n\nWith a rank of 1 and a p-value of 0.001, it’s very unlikely that the observed pattern happened by chance. This low p-value suggests that the spatial pattern detected by the actual Geary’s C statistic is statistically significant.\n\nIn sum, the rank in a Monte Carlo simulation for Geary’s C provides context for the p-value and helps confirm the statistical significance of the spatial pattern observed in your data.\n\n\n10.4.5.3 Visualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05-Local.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05-Local.html#spatial-correlogram",
    "title": "Hands-on Exercise 9 : Global Measures of Spatial Autocorrelation",
    "section": "10.5 Spatial Correlogram",
    "text": "10.5 Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n10.5.1 Compute Moran’s I correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\nA correlogram is a chart that shows how well the value of a variable, measured at one location, predicts the value at another location across various distances. In spatial analysis, this means looking at how the similarity between places changes as the distance between them increases.\n\nX-axis (Lags): The x-axis shows the “lags”, which represent different levels of spatial relationship or distance classes. A lag of 1 indicates immediate neighbors, lag 2 indicates the neighbors of those neighbors, and so on, up to lag 6.\nY-axis (Moran’s I): The y-axis represents the Moran’s I statistic for each lag. Moran’s I values range from -1 to 1. Positive values indicate positive spatial autocorrelation (similar values cluster together), values around zero indicate a random spatial pattern, and negative values indicate negative spatial autocorrelation (dissimilar values cluster together).\npoints: Each point on the correlogram represents the Moran’s I statistic calculated for that particular lag. The value of Moran’s I at lag 1 being the highest and positive suggests that neighboring areas (the first level of neighbors) have the most significant positive spatial autocorrelation, indicating that areas with similar GDP per capita values are geographically close.\nVertical Lines (Error Bars): The vertical lines extending from each point represent the uncertainty or variability in the Moran’s I estimates, often corresponding to confidence intervals. The length of the line indicates the range of Moran’s I values that are statistically plausible for that lag. If the line crosses the horizontal line at Moran’s I = 0, the spatial autocorrelation for that lag is not statistically significant at the chosen confidence level.\n\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n10.5.2 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7 : Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, you are going to gain hands-on experience on using appropriate functions of spNetwork package:\n\nto derive network constrained kernel density estimation (NetKDE), and\nto perform network G-function and k-function analysis\n\nHow common is it for a point to have its nearest neighbor within 10 units\ncalculates the probability that a point is of ≤x distance away from its nearest neighbour\nprobability that the distance from a randomly chosen point to its nearest neighbor is less than or equal to a certain value.\n\nIf you find that the G function indicates a higher probability of short distances between flowers than you’d expect by chance, it suggests that flowers are clustered rather than randomly or evenly distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview",
    "title": "Hands-on Exercise 7 : Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, you are going to gain hands-on experience on using appropriate functions of spNetwork package:\n\nto derive network constrained kernel density estimation (NetKDE), and\nto perform network G-function and k-function analysis\n\nHow common is it for a point to have its nearest neighbor within 10 units\ncalculates the probability that a point is of ≤x distance away from its nearest neighbour\nprobability that the distance from a randomly chosen point to its nearest neighbor is less than or equal to a certain value.\n\nIf you find that the G function indicates a higher probability of short distances between flowers than you’d expect by chance, it suggests that flowers are clustered rather than randomly or evenly distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data",
    "title": "Hands-on Exercise 7 : Network Constrained Spatial Point Patterns Analysis",
    "section": "7.2 The Data",
    "text": "7.2 The Data\nIn this study, we will analyse the spatial distribution of childcare centre in Punggol planning area. For the purpose of this study, two geospatial data sets will be used. They are:\n\nPunggol_St, a line features geospatial data which store the road network within Punggol Planning Area.\nPunggol_CC, a point feature geospatial data which store the location of childcare centres within Punggol Planning Area.\n\nBoth data sets are in ESRI shapefile format."
  },
  {
    "objectID": "In-class_Ex/In-class-Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class-Ex02/In-class_Ex02.html",
    "title": "In-class exercise 2 : R for geospatial data science",
    "section": "",
    "text": "Hey friends! Let’s learn about a few package:"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#loading-packages",
    "href": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#loading-packages",
    "title": "In-class exercise 2 : R for geospatial data science",
    "section": "Loading packages",
    "text": "Loading packages\nThis is a very important step as we have to load the packages before we can use them.\n\npacman::p_load(sf, tmap, tidyverse,lubridate,arrow)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#importing-the-data",
    "href": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#importing-the-data",
    "title": "In-class exercise 2 : R for geospatial data science",
    "section": "Importing the data",
    "text": "Importing the data\n\nImporting Geospatial Data into R\nAs learnt in the previous page, we use st_read() function of the sf package to read in the data.\n\ndf &lt;- read_parquet(\"../../data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n\n\n\nConversion of data type\nHere we convert the int data type to date time data type. We are not using mutate, as we are over writing the data field in the file.\n\ndf$pingtimestamp &lt;-as_datetime(df$pingtimestamp)\n\n\n# get origin\norigin_df &lt;- df %&gt;% #use df\n  group_by(trj_id) %&gt;% #group according to trj_id\n  arrange(pingtimestamp) %&gt;% #sort according to timestamp asc (default)\n  filter(row_number()==1) %&gt;% #the first coordinate for every trip should be the origin\n  mutate(weekday = wday(pingtimestamp, label=TRUE, abbr=TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\ndf_summary &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  summarize(count = n(), .groups = 'drop')\n\n# Display the first few rows of the summary to check\nhead(df_summary)\n\n# A tibble: 6 × 2\n  trj_id count\n  &lt;chr&gt;  &lt;int&gt;\n1 10       104\n2 100       72\n3 1000      89\n4 10001    121\n5 10004     84\n6 10005     89\n\n\n\ndf_summary &lt;- origin_df %&gt;%\n  group_by(trj_id) %&gt;%\n  summarize(count = n(), .groups = 'drop')\n\n# Display the first few rows of the summary to check\nhead(df_summary)\n\n# A tibble: 6 × 2\n  trj_id count\n  &lt;chr&gt;  &lt;int&gt;\n1 10         1\n2 100        1\n3 1000       1\n4 10001      1\n5 10004      1\n6 10005      1\n\n\neach trip will have multiple rows because every minute the new location one be sent to the server . so when we arrange it, the first row is the origin location.\n\n# get end\ndestination_df &lt;- df %&gt;% #use df\n  group_by(trj_id) %&gt;% #group according to trj_id\n  arrange(desc(pingtimestamp)) %&gt;% #sort according to timestamp asc (default)\n  filter(row_number()==1) %&gt;% #the first coordinate for every trip should be the origin\n  mutate(weekday = wday(pingtimestamp, label=TRUE, abbr=TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n# he writes in rds if he still wants to write in r\nwrite_rds(origin_df, \"../../data/rds/origin_df.rds\")\nwrite_rds(destination_df,\n          \"../../data/rds/destination_df.rds\")\n\n#import data\n\norigin_df &lt;- read_rds(\"../../data/rds/origin_df.rds\")\ndestination_df &lt;- read_rds(\"../../data/rds/destination_df.rds\")\n\n\nrm(grabOriginSg)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex05/In-class-Ex05.html",
    "href": "In-class_Ex/In-class-Ex05/In-class-Ex05.html",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "",
    "text": "We would need this take home exercise 2!"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex05/In-class-Ex05.html#installing-and-loading-r-packages",
    "href": "In-class_Ex/In-class-Ex05/In-class-Ex05.html#installing-and-loading-r-packages",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "Installing and loading R packages",
    "text": "Installing and loading R packages\nLet’s import !\n\npacman::p_load(sfdep, sf, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex05/In-class-Ex05.html#data-import",
    "href": "In-class_Ex/In-class-Ex05/In-class-Ex05.html#data-import",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "Data Import",
    "text": "Data Import\n\nGeospatial\n\nhunan &lt;- st_read(dsn = \"data/data/geospatial\",\n layer  = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\In-class_Ex\\In-class-Ex05\\data\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nAspatial\n\nhunan2012 &lt;- read_csv(\"data/data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex05/In-class-Ex05.html#data-wrangling",
    "href": "In-class_Ex/In-class-Ex05/In-class-Ex05.html#data-wrangling",
    "title": "Take-home Exercise 1 : Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nMake sure that the names of the columns you are joining ais the same. Not just that, make sure the column has the same values. To do so, you sort it first, and compare the values of both of them. Since they are the same , you can do a relational join.\n\n\n\n\n\n\nNote\n\n\n\nWhat’s the difference between left join and right join? Find out\n\n\n\nhuman_GDPPC &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n# only need gdp per capita and geometry, thats why we take those columns\n\neval:false is a directive that tells the Quarto rendering engine not to evaluate or execute the code in this chunk. This can be useful when you want to show the code for instructional or illustrative purposes without actually running it\n\nwrite_rds(hunan_GDPPC,\n          \"data/rds/hunan_GDPPC.rds\")\n\n\ntmap_mode(\"plot\")\ntm_shape(human_GDPPC) +\n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") + \n  tm_layout(main.title = \"distribution of gdp per capita\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\nwm_q &lt;- human_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt= st_weights(nb, style = \"W\"),\n         .before = 1)\n\n\nComputing Global Moran’ I\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\nPerforming global moran’I permutation test\nThis is the only one required for take home exercise, the one directly before is not needed.\n\nset.seed(1234)\n\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nthe report show that p value is smaller than alpha value of o,o,5. ALWAYS SAY U INFER NOT PROVING. we have enouh stat evidence to reject nullhypo that spatial distriution ."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS1455-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications.\nThis is the course website of the IS415 mod that I am embarking on this semester. You will find my course materials here. Have fun:)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "In this take home exercise, our central subject of study would be Dengue.\n\n\nDengue is a disease spread by mosquitoes, particularly, the female Aedes aegypti and Aedes albopictus mosquitoes, in tropical and subtropical regions like Taiwan. It is transmitted to humans th\ne-infected person, the mosquito is then infected. After approximately one week, the mosquito can then transmit the virus to other people they bite. It can result in sudden high fever, severe headache, joint pains and skin rashes.\n\n\n\nIt can easily spread in areas in Taiwan due to the tropical climate, the high population density and numerous pools of stagnant water - which is a loved breeding ground for mosquitoes. It is imperative to track the speed at which it spreads and the areas in which it can spread in order to curtail its spread. And thats what we will be doing in this take home exercise.\n\n\n\n\nWe firstly want to know if the outbreaks in Taiwan are independent of space and time. That means that the dengue instances would be randomly distributed and not show any pattern\nIf they are not independent of space and time, we would want to find certain areas that have high incidents of dengue (hotspots) and low incidents of it (coldspots). We also want to find if there are certain times of the year when outbreaks are more common."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#what-is-dengue",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#what-is-dengue",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "Dengue is a disease spread by mosquitoes, particularly, the female Aedes aegypti and Aedes albopictus mosquitoes, in tropical and subtropical regions like Taiwan. It is transmitted to humans th\ne-infected person, the mosquito is then infected. After approximately one week, the mosquito can then transmit the virus to other people they bite. It can result in sudden high fever, severe headache, joint pains and skin rashes."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#why-study-it",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#why-study-it",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "It can easily spread in areas in Taiwan due to the tropical climate, the high population density and numerous pools of stagnant water - which is a loved breeding ground for mosquitoes. It is imperative to track the speed at which it spreads and the areas in which it can spread in order to curtail its spread. And thats what we will be doing in this take home exercise."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#what-in-particular-are-we-investigating",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#what-in-particular-are-we-investigating",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "We firstly want to know if the outbreaks in Taiwan are independent of space and time. That means that the dengue instances would be randomly distributed and not show any pattern\nIf they are not independent of space and time, we would want to find certain areas that have high incidents of dengue (hotspots) and low incidents of it (coldspots). We also want to find if there are certain times of the year when outbreaks are more common."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-download-import",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-download-import",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "3.1 Data Download & Import",
    "text": "3.1 Data Download & Import\nLet us first look at the data we are utilising to conduct this analysis.\n\nOverview Off Data Used\n\n\n\n\n\n\n\n\nData Name\nDescription\nType\nFormat\n\n\nDengue Daily\nThis data denotes the locations and time of each dengue incident in Taiwan.\nGeospatial\nCSV\n\n\nHistorical map data of the village boundary (TWD97 longitude and latitude)\nThis data provides the internal and external boundary of Taiwan at the village level.\nGeospatial\nESRI shapefile"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#geospatial-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#geospatial-data",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "3.2 Geospatial Data",
    "text": "3.2 Geospatial Data\nIn this section, we will be importing and wrangling our data. We do this because data might not always be in the format that is suitable for our analysis, and hence, conversion to a suitable format is imperative.\n\n3.2.1 Import the data\n\ntaiwan &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"TAINAN_VILLAGE\")\n\nReading layer `TAINAN_VILLAGE' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Take-Home_Ex\\Take-Home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 649 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0269 ymin: 22.88751 xmax: 120.6563 ymax: 23.41374\nGeodetic CRS:  TWD97\n\n\nLet’s look at the data to understand it better.\n\nhead(taiwan)\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.053 ymin: 22.93251 xmax: 120.2905 ymax: 23.16919\nGeodetic CRS:  TWD97\n     VILLCODE COUNTYNAME TOWNNAME VILLNAME        VILLENG COUNTYID COUNTYCODE\n1 67000280002     臺南市   歸仁區   六甲里    Liujia Vil.        D      67000\n2 67000350032     臺南市   安南區   青草里   Qingcao Vil.        D      67000\n3 67000150009     臺南市   七股區   溪南里     Xinan Vil.        D      67000\n4 67000150010     臺南市   七股區   七股里      Qigu Vil.        D      67000\n5 67000150008     臺南市   七股區   龍山里  Longshan Vil.        D      67000\n6 67000150017     臺南市   七股區   中寮里 Zhongliao Vil.        D      67000\n  TOWNID TOWNCODE NOTE                       geometry\n1    D33 67000280 &lt;NA&gt; POLYGON ((120.2725 22.95868...\n2    D06 67000350 &lt;NA&gt; POLYGON ((120.1176 23.08387...\n3    D22 67000150 &lt;NA&gt; POLYGON ((120.121 23.1355, ...\n4    D22 67000150 &lt;NA&gt; POLYGON ((120.1312 23.1371,...\n5    D22 67000150 &lt;NA&gt; POLYGON ((120.0845 23.13503...\n6    D22 67000150 &lt;NA&gt; POLYGON ((120.126 23.16917,...\n\n\n\nclass(taiwan)\n\n[1] \"sf\"         \"data.frame\"\n\n\nWe can see that the data is in a data frame of type sf. This data frame talks about each village in Tainan city (in Taiwan), and accompanying information like which county and town the village is in.\nLet’s see how Tainan city in Taiwan looks like when it is divided by its villages. In this plot below, we see Taiwan divided by villages, and each color represents a different town that it is part of.\n\ntmap_mode(\"plot\")\nqtm(taiwan, fill=\"TOWNID\")\n\n\n\n\nHowever, we only need towns D01, D02, D04, D06, D07, D08, D32 and D39.\n\n\n3.2.2 Data Filtering\nLet’s now filter the rows in our Taiwan data frame to contain rows/villages from just these particular towns: D01, D02, D04, D06, D07, D08, D32 and D39.\n\ntaiwan_filtered &lt;- taiwan %&gt;%\n  filter(TOWNID %in% c('D01', 'D02', 'D04', 'D06', 'D07', 'D08', 'D32', 'D39'))\n\nLet’s visualise the data again.\n\ntmap_mode(\"plot\")\nqtm(taiwan_filtered, fill=\"TOWNID\")\n\n\n\n\nHere we see that we were successful in our filtering, we have got the villages just in the towns that we are interested in. This is a much smaller subset of the data we were working with, hopefully processing speeds would be higher too!\n\n\n3.2.3 Assessing Geometric Validity\n\nlength(which(st_is_valid(taiwan_filtered) == FALSE))\n\n[1] 0\n\n\n0 means that none of our rows have invalid geometries and that we could move on peacefully.\n\n\n3.2.4 Missing values\nWe want to check if there are any empty rows. Datasets can be huge and consequently, we could have many empty rows that is just a waste of memory and processing power. Removing them would be useful.\nHere’s how we do it:\n\n# Use the filter function to check for empty rows\nempty_rows &lt;- taiwan_filtered %&gt;%\n  filter_all(all_vars(is.na(.)))\n\n# Check if there are any empty rows\nif (nrow(empty_rows) &gt; 0) {\n  cat(\"There are empty rows in the sf data tibble.\\n\")\n} else {\n  cat(\"There are no empty rows in the sf data tibble.\\n\")\n}\n\nThere are no empty rows in the sf data tibble.\n\n\nLuckily, we have no empty rows either!\n\n\n3.2.5 Coordinate reference system\n\nst_crs(taiwan_filtered)\n\nCoordinate Reference System:\n  User input: TWD97 \n  wkt:\nGEOGCRS[\"TWD97\",\n    DATUM[\"Taiwan Datum 1997\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"Taiwan, Republic of China - onshore and offshore - Taiwan Island, Penghu (Pescadores) Islands.\"],\n        BBOX[17.36,114.32,26.96,123.61]],\n    ID[\"EPSG\",3824]]"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#aspatial-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#aspatial-data",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "3.3 Aspatial Data",
    "text": "3.3 Aspatial Data\n\n3.3.1 Import the data\nLet’s import the data.\n\ndengue &lt;- read.csv(\"data/aspatial/Dengue_Daily.csv\")\n\nLet’s explore how the data is like!\n\nhead(dengue)\n\n      發病日 個案研判日     通報日 性別 年齡層 居住縣市 居住鄉鎮 居住村里\n1 1998/01/02       None 1998/01/07   男  40-44   屏東縣   屏東市     None\n2 1998/01/03       None 1998/01/14   男  30-34   屏東縣   東港鎮     None\n3 1998/01/13       None 1998/02/18   男  55-59   宜蘭縣   宜蘭市     None\n4 1998/01/15       None 1998/01/23   男  35-39   高雄市   苓雅區     None\n5 1998/01/20       None 1998/02/04   男  55-59   宜蘭縣   五結鄉     None\n6 1998/01/22       None 1998/02/19   男  20-24   桃園市   蘆竹區     None\n     最小統計區 最小統計區中心點X 最小統計區中心點Y   一級統計區 二級統計區\n1 A1320-0136-00     120.505898941      22.464206650 A1320-04-008   A1320-04\n2 A1303-0150-00     120.453657460      22.466338948 A1303-09-007   A1303-09\n3 A0201-0449-00     121.751433765      24.749214667 A0201-23-006   A0201-23\n4 A6408-0153-00     120.338158907      22.630316700 A6408-10-010   A6408-10\n5 A0209-0232-00     121.798235373      24.684507639 A0209-10-005   A0209-10\n6          None              None              None         None       None\n  感染縣市 感染鄉鎮 感染村里 是否境外移入 感染國家 確定病例數 居住村里代碼\n1     None     None     None           否     None          1         None\n2     None     None     None           是     None          1         None\n3     None     None     None           是     None          1         None\n4     None     None     None           否     None          1         None\n5     None     None     None           否     None          1         None\n6     None     None     None           是     None          1         None\n  感染村里代碼 血清型 內政部居住縣市代碼 內政部居住鄉鎮代碼 內政部感染縣市代碼\n1         None   None              10013            1001301               None\n2         None 第二型              10013            1001303               None\n3         None   None              10002            1000201               None\n4         None   None                 64            6400800               None\n5         None   None              10002            1000209               None\n6         None   None                 68            6800500               None\n  內政部感染鄉鎮代碼\n1               None\n2               None\n3               None\n4               None\n5               None\n6               None\n\n\nWe realise that the columns are in Chinese, so let’s translate them to english so that we can understand them better. I have used Google translate to individually translate each column to english\n\nnew_names &lt;- c(\"Onset_date\", \"judgement_date\", \"notification_date\", \"gender\", \"age_group\", \"country_city_residence\", \"residential_township\", \"residential_village\", \"min_stat_area\", \"min_stat_area_center_point_x\", \"min_stat_area_center_point_y\", \"first_level_stat_area\", \"second_level_stat_area\", \"infected_counties_cities\", \"infected_towns\", \"infected_villages\",\n               \"immigrant\", \"country_of_infection\", \"confirmed_cases_number\", \"village_residence_code\", \"infected_village_code\", \"serotype\", \"interior_county_city_ministry_code\", \"interior_residence_township_ministry_code\", \"interior_infection_county_ministry_code\", \n               \"interior_infection_township_ministry_code\"\n               )\n\n\nnames(dengue) &lt;- new_names\n\nLet’s check if the translation has worked!\n\nnames(dengue)\n\n [1] \"Onset_date\"                               \n [2] \"judgement_date\"                           \n [3] \"notification_date\"                        \n [4] \"gender\"                                   \n [5] \"age_group\"                                \n [6] \"country_city_residence\"                   \n [7] \"residential_township\"                     \n [8] \"residential_village\"                      \n [9] \"min_stat_area\"                            \n[10] \"min_stat_area_center_point_x\"             \n[11] \"min_stat_area_center_point_y\"             \n[12] \"first_level_stat_area\"                    \n[13] \"second_level_stat_area\"                   \n[14] \"infected_counties_cities\"                 \n[15] \"infected_towns\"                           \n[16] \"infected_villages\"                        \n[17] \"immigrant\"                                \n[18] \"country_of_infection\"                     \n[19] \"confirmed_cases_number\"                   \n[20] \"village_residence_code\"                   \n[21] \"infected_village_code\"                    \n[22] \"serotype\"                                 \n[23] \"interior_county_city_ministry_code\"       \n[24] \"interior_residence_township_ministry_code\"\n[25] \"interior_infection_county_ministry_code\"  \n[26] \"interior_infection_township_ministry_code\"\n\n\n\n\n3.3.2 Conversion of data types\nThe data type of all the fields in the data table is char, which doesn’t make sense for numeric values such as the x&y coordinates and the onset date.\nLet’s change the data type of onset date.\nIn this code snippet, we convert onset date to a date datatype (it was char before). Then we create a new week column to detect the week of the onset date (we need it later to extract relevant weeks)\n\ndengue_new &lt;- dengue\ndengue_new$Onset_date &lt;- as.Date(dengue_new$Onset_date)\n\ndengue_new$week &lt;- as.numeric(format(dengue_new$Onset_date, \"%V\"))\n\nLet’s convert data type of X and Y coordinates.\nHowever, I have noticed that some x and y coordinates are non numerical like “none” , and these will not be able to be converted. lets remove them first.\n\ndengue_new &lt;- dengue_new %&gt;%\n  filter(grepl(\"^[+-]?[0-9]*[.]?[0-9]+$\", min_stat_area_center_point_x))\n\n\ndengue_new &lt;- dengue_new %&gt;%\n  filter(grepl(\"^[+-]?[0-9]*[.]?[0-9]+$\", min_stat_area_center_point_y))\n\nNow let’s do the conversion.\n\ndengue_new$min_stat_area_center_point_x &lt;- as.numeric(dengue_new$min_stat_area_center_point_x)\ndengue_new$min_stat_area_center_point_y &lt;- as.numeric(dengue_new$min_stat_area_center_point_y)\n\n\n\n3.3.3 Check Missing Data\n\ndengue[rowSums(is.na(dengue))!=0,]\n\n [1] Onset_date                               \n [2] judgement_date                           \n [3] notification_date                        \n [4] gender                                   \n [5] age_group                                \n [6] country_city_residence                   \n [7] residential_township                     \n [8] residential_village                      \n [9] min_stat_area                            \n[10] min_stat_area_center_point_x             \n[11] min_stat_area_center_point_y             \n[12] first_level_stat_area                    \n[13] second_level_stat_area                   \n[14] infected_counties_cities                 \n[15] infected_towns                           \n[16] infected_villages                        \n[17] immigrant                                \n[18] country_of_infection                     \n[19] confirmed_cases_number                   \n[20] village_residence_code                   \n[21] infected_village_code                    \n[22] serotype                                 \n[23] interior_county_city_ministry_code       \n[24] interior_residence_township_ministry_code\n[25] interior_infection_county_ministry_code  \n[26] interior_infection_township_ministry_code\n&lt;0 rows&gt; (or 0-length row.names)\n\n\nThankfully we have no missing data! Let’s proceed.\n\ndengue_before_geo &lt;- dengue_new\n\n\n\n3.3.4 Conversion of Lat/Long into Geometry\nWe want to convert the lat long to a point so that we could conduct spatial point analysis!\nNow, let’s do the conversion!\n\ndengue_new &lt;- st_as_sf(dengue_new, coords = c(\"min_stat_area_center_point_x\", \"min_stat_area_center_point_y\"), crs = 3824)\n\nLet’s look at our dengue_new now. it’s indeed projected in TWD97 and that’s what we wanted!\n\nst_geometry(dengue_new)\n\nGeometry set for 106081 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 118.3081 ymin: 21.92574 xmax: 121.9826 ymax: 26.15617\nGeodetic CRS:  TWD97\nFirst 5 geometries:\n\n\n\n\n3.3.5 Extracting dengue cases from relevant weeks\nWe are asked to extract dengue cases from only week 31 to week 50 of 2023. We do not need data from other time periods. So, let’s do that!\n\ndengue_new &lt;- dengue_new %&gt;% filter(year(Onset_date) == 2023\n  & (week &gt;=31 & week &lt;= 50))\ndengue_before_geo &lt;- dengue_before_geo %&gt;% filter(year(Onset_date) == 2023\n  & (week &gt;=31 & week &lt;= 50))\n\n\n\n3.3.6 Extracting dengue data in specific areas\nOur geospatial data, taiwan_filtered, provides the boundaries of villages in Tainan City in particular - not the whole of taiwan. And we had taiwan_``filtered created after selecting only a few towns in Tainan City. We need to make sure that the dengue_new data only corresponds to the areas defined in the taiwan_``filtered area.\n\n#dengue_tainan &lt;- st_intersection(taiwan_filtered, dengue_new)\n\nLet’s write this to rds as it was a time consuming task and we do not want to execute this agaain.\n\n#write_rds(dengue_tainan, \"../../data/rds/dengue_tainan.rds\")\n\n\ndengue_tainan &lt;- read_rds(\"../../data/rds/dengue_tainan.rds\")\n\n\ntm_shape(taiwan_filtered) +\n  tm_polygons(\"TOWNID\") +\n  tm_shape(dengue_tainan) +\n  tm_dots()\n\n\n\n\n\n\n3.3.7 Examining dengue incidents /town\nBy looking at our graphical analysis, we can tell that villages in Towns. D01, D08, D04 have a high density of dengue cases.\nLet’s see if that is right by plotting the number of dengue incidents per TOWNID!\n\ndengue_summary &lt;- dengue_tainan %&gt;%\n  group_by(TOWNID) %&gt;%\n  summarise(incidents = n(), .groups = 'drop')\n\nLet’s plot the results!\n\nggplot(dengue_summary, aes(x = reorder(TOWNID, -incidents), y = incidents)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(x = \"Town ID\", y = \"Number of Incidents\", title = \"Dengue Incidents by Town\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 65, hjust = 1))\n\n\n\n\nGuess we weren’t fully correct! The towns with the more incidents were D01, D06 and D39. But it is important to note that the top 5 towns have very similar number of incidents\n\n\n3.3.8 Examining dengue /village\nNow, let’s examine the number of incidents per village. And since we already examined the number of incidents per town, let’s see if the villages with the highest number of incidents come from towns with the highest number of incidents!\n\n\n\n\n\n\nNote\n\n\n\nThis is very important to do so, so that we can make links between different facets of data - villages and towns and gain a better understanding of the geospatial distribution of the incidents.\n\n\nIn this section, not only are we aiming to find the villages with the highest number of incidents, we are trying to link them to the town they are from.\nAs our first task, let’s map the villages to their town on our own.\n\n3.3.8.1 Mapping town to village\nIn our dengue_tainan data frame, each row corresponds to a particular incident of dengue in a particular point. There might be multiple points referring to the same village.\nWe need to remove the geometry column for this so that we can remove the uniqueness for each row and can group all the same village ids together. To do so, we change the data type of dengue_tainan and store it in dengue_tainan_no_geom.\n\ndengue_tainan_no_geom &lt;- st_set_geometry(dengue_tainan, NULL)\n\nNow let’s do the mapping between villagecode and townid.\n\nvillcode_townid_mapping &lt;- dengue_tainan_no_geom %&gt;%\n  select(VILLCODE, TOWNID) %&gt;%\n  distinct()\n\nhead(villcode_townid_mapping)\n\n       VILLCODE TOWNID\n212 67000310004    D39\n27  67000320003    D01\n19  67000310001    D39\n128 67000270012    D32\n246 67000310025    D39\n150 67000310037    D39\n\n\nWe have done it!\n\n\n3.3.8.1 Calculating top 10 villages\nHere we group by villcode so that we can get the number of incidents per village\n\ndengue_summary &lt;- dengue_tainan %&gt;%\n  group_by(VILLCODE) %&gt;%\n  summarise(incidents = n(), .groups = 'drop')\n\nLet’s remove the geometry column here as well so that we can join it with the mapping we made above. We do this because we use left_join for combining the mapping with the number of incidents per village, and it does not allow us to have a geometry column\n\ndengue_summary  &lt;- st_set_geometry(dengue_summary , NULL)\n\nNow let’s do the join.\n\ndengue_summary &lt;- dengue_summary %&gt;%\n  left_join(villcode_townid_mapping, by = \"VILLCODE\")\n\nLet’s now get the top 10 villages with the most number of incidents\n\ntop_10_villages &lt;- dengue_summary %&gt;%\n  arrange(desc(incidents)) %&gt;%\n  slice_max(order_by = incidents, n = 10)\n\nHere, let’s plot the number of incidents for the top 10 villages with the most incidents, in an ascending order. Each village will be uniquely colored based on the town it is from, so that we can make connections between the towns and villages with the most incidents.\n\nggplot(top_10_villages, aes(x = reorder(VILLCODE, -incidents), y = incidents, fill = as.factor(TOWNID))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_viridis_d() + \n  labs(title = \"Top 10 Villages with Most Dengue Incidents\",\n       x = \"Village Code\",\n       y = \"Number of Incidents\",\n       fill = \"Town ID\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), # Improve x-axis label readability\n        legend.position = \"bottom\") # Adjust legend position\n\n\n\n\nTo analyse the graph above, let’s refer to our previous chart depicting the towns with the most incidents.\n\nFrom the first graph, we can see that the village with the most incidents is from D39, however, D39 isactually the town with the 3rd most number of incidents.\nBut if D39 is a town with the 3rd most number of incidents, it is actually corroborated by the fact that in the first graph, 3 of the top 10 villages with the most incidents come from D39\nFrom the second graph, we can see that D06 is the town with the second most number of incidents, 4 of the top 10 villages with most incidents actually come from town D06, thus making the second graph make a lot of sense!\nWhat the interesting or controversial thing is, is that, D01 is said to be the town with the most number of incidents, but only one village from town D01 made it to the top 10 list! HMmm.. That means that multiple villages in D01 had a smaller number of incidents, whilst D36 maybe just had a select few villages with high number of cases.\n\n\n\n3.3.9 Examining dengue /village/week\nLet’s get all the weeks for each village code. We have to use village code as the unique identifier as there are 258 unique village codes but 253 unique village names. That means, there are multiple village codes with the same village =eng, so it’s important to disregard villageeng.\nSo let’s get all the weeks from 30-50 for each village code.\n\nvillagecode_week_set &lt;- expand.grid(VILLCODE = unique(taiwan_filtered$VILLCODE), week= seq(31,50))\n\nLet us now see how many dengue incidents are there per week per village!\nLet’s group by the week and the village code, and then add it up to calculate the total number of incidents\n\ndengue_summary &lt;- dengue_tainan %&gt;%\n  group_by(VILLCODE, week) %&gt;%\n  summarise(incidents = n(), .groups = 'drop')\n\n\ndengue_pervillage_week &lt;- dengue_summary\n\n\nhead(dengue_summary)\n\nSimple feature collection with 6 features and 3 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 120.2534 ymin: 22.98918 xmax: 120.2721 ymax: 22.994\nGeodetic CRS:  TWD97\n# A tibble: 6 × 4\n  VILLCODE     week incidents                                           geometry\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;int&gt;                                     &lt;GEOMETRY [°]&gt;\n1 67000270001    33         1                          POINT (120.2583 22.99218)\n2 67000270001    34         1                          POINT (120.2612 22.99222)\n3 67000270001    35         2 MULTIPOINT ((120.2625 22.994), (120.2668 22.98918…\n4 67000270001    36         3 MULTIPOINT ((120.2555 22.99274), (120.2574 22.989…\n5 67000270001    37         5 MULTIPOINT ((120.2555 22.99274), (120.2591 22.992…\n6 67000270001    38         4 MULTIPOINT ((120.2534 22.99117), (120.2639 22.991…\n\n\nThere are many rows in this data table, so let’s find out the particular weeks in specific villages that had the highest number of incidents.\nIn this code snippet, we get sort the incident values in a descending order, then take the top 10 rows, and change the columns.\n\ntop_10_incidents &lt;- dengue_summary %&gt;%\n  arrange(desc(incidents)) %&gt;%\n  slice_max(order_by = incidents, n = 10) %&gt;%\n  mutate(concatenated_vill_week = paste(\"vill\", VILLCODE, \"at week\", week))\n\nLet’s plot it to see which weeks and villages had the most incidents\n\nggplot(top_10_incidents, aes(x = concatenated_vill_week, y = incidents, fill = VILLCODE)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  labs(x = \"Village Code and Week\", y = \"Number of Incidents\", title = \"Top 10 Dengue Incidents by Village and Week\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) \n\n\n\n\nWe can see that dengue_summary does not have all the weeks for each unique VILLCODE . So we must ensure that the resulting data table has a row represnting each week for each village code.\nSo we left join with the data frame with all the week-villagecode combinations so that all the ocmbinations will be included. The last line of code replaces week-villagecode combinations with no incidents as 0.\n\nfinal_set&lt;- left_join(villagecode_week_set, dengue_summary, by= c(\"VILLCODE\", \"week\")) %&gt;%\n  replace(is.na(.), 0)\n\n\nfinal_set &lt;- left_join(taiwan_filtered, final_set, by = c(\"VILLCODE\"))\n\nLet’s drop geometry.y as it refers to the dengue incident point, and we don’t need that as we are looking at number of incidents per village per week\n\nfinal_set&lt;- final_set %&gt;%\n  select(-geometry.y)\n\n\n\n3.8.9 Additional Data Wrangling\nLet’s get the number of incidents per village\n\ndengue_per_village &lt;- dengue_tainan %&gt;%\n  group_by(VILLCODE) %&gt;%\n  summarise(incidents = n(), .groups = 'drop')\n\nAs I am trying to investigate the number of incidents per week, i do not need the gemoetries of each individual point that have amalgamated into a multipoint. So, let’s remove geome\n\ndengue_per_village  &lt;- st_set_geometry(dengue_per_village , NULL)\n\nLet’s perform left join.\n\ntryNow &lt;- left_join(taiwan_filtered, dengue_per_village, by = c(\"VILLCODE\"))\n\n\ntmap_mode(\"plot\")\ntm_shape(tryNow) +\n  tm_fill(col = \"incidents\",\n          style = \"quantile\",\n          palette = \"Purples\",\n          title = \"Number of Dengue Cases\") +\n  tm_layout(main.title = \"Number of Dengue Cases\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.4,\n            legend.width = 0.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#calculating-contiguity-weights-queens-method",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#calculating-contiguity-weights-queens-method",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.1 Calculating Contiguity Weights: Queen’s method",
    "text": "4.1 Calculating Contiguity Weights: Queen’s method\nHere we are trying to determine the neighbours of each village, and then we are determining how much each neighbour could affect the focus location (through weights)\nWhen doing it, i got an error that there were NA values. When we looked at our tryNow data frame, there was a column called Note with only NA values.\nHence, let’s remove that.\n\ntryNow &lt;- tryNow %&gt;%\n  select(-NOTE)\n\n\ntryNow &lt;- tidyr::drop_na(tryNow)\n\nNow, let’s calculate the weights of neighbouring villages of each focal village.\n\nwm_q &lt;- tryNow %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\n\nwm_q\n\nSimple feature collection with 257 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0627 ymin: 22.89401 xmax: 120.2925 ymax: 23.09144\nGeodetic CRS:  TWD97\nFirst 10 features:\n                                             nb\n1                                   6, 118, 160\n2                       126, 128, 138, 167, 221\n3          68, 69, 171, 180, 183, 184, 187, 199\n4                    94, 97, 100, 104, 181, 206\n5                              12, 13, 248, 254\n6                      1, 12, 13, 118, 160, 248\n7                               54, 98, 99, 200\n8  9, 73, 75, 115, 125, 144, 156, 157, 165, 185\n9                         8, 110, 115, 125, 165\n10                  11, 159, 161, 165, 235, 257\n                                                                 wt    VILLCODE\n1                                   0.3333333, 0.3333333, 0.3333333 67000350032\n2                                           0.2, 0.2, 0.2, 0.2, 0.2 67000270011\n3            0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125 67000370005\n4  0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667 67000330004\n5                                            0.25, 0.25, 0.25, 0.25 67000350028\n6  0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667 67000350030\n7                                            0.25, 0.25, 0.25, 0.25 67000370009\n8                  0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1 67000350017\n9                                           0.2, 0.2, 0.2, 0.2, 0.2 67000350049\n10 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667 67000350018\n   COUNTYNAME TOWNNAME VILLNAME       VILLENG COUNTYID COUNTYCODE TOWNID\n1      臺南市   安南區   青草里  Qingcao Vil.        D      67000    D06\n2      臺南市   仁德區   保安里   Bao'an Vil.        D      67000    D32\n3      臺南市   中西區   赤嵌里  Chihkan Vil.        D      67000    D08\n4      臺南市     南區   大成里  Dacheng Vil.        D      67000    D02\n5      臺南市   安南區   城北里 Chengbei Vil.        D      67000    D06\n6      臺南市   安南區   城南里 Chengnan Vil.        D      67000    D06\n7      臺南市   中西區   法華里    Fahua Vil.        D      67000    D08\n8      臺南市   安南區   海南里   Hainan Vil.        D      67000    D06\n9      臺南市   安南區   國安里   Guo'an Vil.        D      67000    D06\n10     臺南市   安南區   溪心里    Xixin Vil.        D      67000    D06\n   TOWNCODE incidents                       geometry\n1  67000350         2 POLYGON ((120.1176 23.08387...\n2  67000270        19 POLYGON ((120.2304 22.93544...\n3  67000370       111 POLYGON ((120.2012 22.99966...\n4  67000330        29 POLYGON ((120.1985 22.98147...\n5  67000350         1 POLYGON ((120.1292 23.06512...\n6  67000350        10 POLYGON ((120.1246 23.06904...\n7  67000370        38 POLYGON ((120.2094 22.98452...\n8  67000350        44 POLYGON ((120.175 23.02218,...\n9  67000350       112 POLYGON ((120.1866 23.02766...\n10 67000350        65 POLYGON ((120.1834 23.06086...\n\n\nLet’s understand this. We can see that there is a list of neighbours for each village. For example, the first village has neighbours 6, 118, 160. And each of the neighbours had equal weight, with each neighbour having the same influence over the village"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-global-moran-i",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-global-moran-i",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.2 Computing Global Moran’ I",
    "text": "4.2 Computing Global Moran’ I\nWhat is Global Moran’ I?\nGlobal Moran’s I is a statistical measure used to assess spatial autocorrelation in data measured across a geographic area. We are trying to assess whether similar values cluster close together, or are further away.\nValue’s meaning:\n\nA positive value indicates positive spatial correlation and that similar values cluster together.\nA negative value indicates negative spatial correlation and that similar values being spatially apart.\nA value near zero implies a random spatial distribution of the values, showing no significant autocorrelation\n\n\nmoranI &lt;- global_moran(wm_q$incidents,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.464\n $ K: num 5.66\n\n\nThe Global Moran’s I statistic was 0.464. This suggests a positive spatial autocorrelation. This means that similar values of incidents tend to be clustered together geographically in your dataset.\nNot only do we Global Moran’s I statistic, we want to assess the statistical significance of the Moran’s I statistic if the spatial pattern is unlikely to have occurred by chance."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-global-morans-i-test",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-global-morans-i-test",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.3 Performing Global Moran’s I test",
    "text": "4.3 Performing Global Moran’s I test\n\nglobal_moran_test(wm_q$incidents,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 12.705, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.464386792      -0.003906250       0.001358653 \n\n\nBased on analysis result, sicne p value which is 2.2e-16 and is much lower than the confidence interval value of 0.05, we have enough statistical evidence to reject the null hypothesis that states that points are randomly distributed. It allows us to infer that the distribution resembles clustering because the Moran I value was over 0.4.\nAs it is 0. we can infer there is clustering, but the value is not tool large- so there is clustering but at very distinct places. So we need to execute local moran to detect the specific areas with hotspots/coldspots , clusters and outliers."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-global-morans-permutation-test",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-global-morans-permutation-test",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.4 Performing Global Moran’s permutation test",
    "text": "4.4 Performing Global Moran’s permutation test\nWe do this to double confirm that there indeed is clustering and that the incidents of dengue are not randomly distributed. We do this through monte carlo simulations.\nHow are Monte Carlo Simulations conducted?\n\nStart with Real Spatial Data: We have a map with data points, each representing a value of interest, like dengue incidents in different villages.\nThe Question: We want to know if dengue incidents in one village are related to high dengue incidents in neighboring village (positive spatial autocorrelation), or if it’s just random.\nCreating a Simulated World:\n\n-   Imagine we take the map and erase all the dengue incidents data.\n\n-   Then, we redistribute those dengue incidents data randomly across the map. This means we're shuffling the data points so they no longer have their original spatial pattern. Each village gets a dengue incidents data, but now it's randomly assigned, not based on the real-world data.\n\nCalculating Moran’s I for the Simulated World:\n\n1.  WE do simulations (which represent a world of randomness without any spatial pattern),\n\n2.  With this shuffled map, we calculate Moran's I, a statistic that measures how much the dengue incidents data in one village is similar to the rates in nearby villages.\n\n3.  This calculation gives us a sense of whether the shuffled (randomized) data still shows any pattern of similar values being close together.\n\nRepeat the Simulation Multiple Times:\n\nWe don’t do this process just once. We repeat it many times, each time reshuffling the data and calculating a new Moran’s I.\nThis creates a bunch of Moran’s I values from worlds that are similar to ours but with randomized crime rates.\n\nCompare the Real World to the Simulated Worlds:\n\n-   Now, we compare the Moran's I you calculated from your real data to the range of Moran's I values you got from your simulations.\n\n-   If the real Moran's I is much higher than what we mostly see in the simulations, it suggests that the pattern in your real data is not random; it's statistically significant.\n\nIt is alway a good practice to use set.seed() before performing simulation. This is to ensure that the computation is reproducible.\n\n\nset.seed(1234)\n\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\nglobal_moran_perm(wm_q$incidents,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.46439, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nIn the context of Monte Carlo simulations, the rank of the observed Moran’s I value (0.46439) among the Moran’s I values generated from the simulated random datasets indicates its position. A rank of 100 out of 100 means that the observed Moran’s I was the highest among all simulated values, suggesting that the observed spatial autocorrelation is exceptionally strong compared to what would be expected by chance.\nThe very low p value also allows us to reject the null hypothesis and deduce that the spatial autocorrelation is unlikely to have occurred by chance.\nWe can infer that the spatial distribution shows sign of clustering.\nNow, let’s use local moran to identify areas where clustering occurred."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-local-morans-i",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-local-morans-i",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.5 Computing local Moran’s I",
    "text": "4.5 Computing local Moran’s I\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    incidents, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n4.5.1 Visualisng local Moran’s I\nLet’s visualise!\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of incidents\",\n            main.title.size = 0.8)\n\n\n\n\nLet’s analyse this visualisation.\nThe dark green areas that also surrounded by dark green or lighter green areas have high local moran’s i values, indicating strong spatial correlation, and that these areas and immediate neighbours have similarly high values.\nThe same middle part also has many orange areas, that have low local moran’s I values. This means that there is a stark difference between the number of dengue incidents there compared to villages near it - and this makes sense.\nFrom our first map, we know that the middle area is concentrated with dengue incidents.\nThe middle area is so dense with packed with many small small villages. It makes sense that some villages would be concentrated with incidents, and another village right next to it might not, and this can result in a stark difference in a stark difference in value and negative local moran.\n\n\n4.5.1 Visualisng p value of local Moran’s I\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\n\n\n\nLight Brown Areas : These areas have low p-values, indicating that the Local Moran’s I values for these areas are statistically significant. The closer the p-value is to 0, the stronger the evidence against the null hypothesis (which states that there is no spatial autocorrelation). Thus, areas in this range are likely to represent significant spatial clusters or outliers.\nDarker Brown Areas : As the colors get darker (moving towards the 1.0 end of the scale), the p-values increase, suggesting weaker evidence against the null hypothesis. Areas with p-values closer to 1.0 suggest that the local spatial patterns might be due to random chance rather than a significant spatial process.\n\n\n4.5.2 Visuaising local Moran’s I and p-value\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-lisa-map",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-lisa-map",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.6 Visualising LISA map",
    "text": "4.6 Visualising LISA map\nLet’s plot the LISA map to check for of outliers and clusters.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\nThis again corroborates with our first map that shows the distribution of dengue cases , and the area around the middle part having high number of cases can be likened to the high-high villages around the middle of the city."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.7 Hot Spot and Cold Spot Area Analysis (HCSA)",
    "text": "4.7 Hot Spot and Cold Spot Area Analysis (HCSA)\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure.\n\n4.7.1 Computing Local Gi* Statistics\n\ntryNow1 &lt;- tryNow %&gt;%\n  filter(!is.na(incidents))\n\nWe will need to derive a spatial weight matrix before we can compute local Gi* statistics.\nIt specifies which areas are neighbors and how strongly they should be weighted based on distance.\nHigh positive Gi∗​ values indicate a clustering of high values (hotspots), while low negative Gi∗​ values indicate a clustering of low values (coldspots).\n\nwm_idw &lt;- tryNow1 %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\nNow we are calculating the Local GI* Statistic\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    incidents, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 257 features and 22 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0627 ymin: 22.89401 xmax: 120.2925 ymax: 23.09144\nGeodetic CRS:  TWD97\n# A tibble: 257 × 23\n   gi_star cluster    e_gi    var_gi std_dev p_value p_sim p_folded_sim skewness\n     &lt;dbl&gt; &lt;fct&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  -2.35  Low     0.00295   1.95e-6 -1.93   0.0535   0.02         0.01   0.417 \n 2  -2.07  Low     0.00334   1.39e-6 -1.73   0.0831   0.04         0.02   1.08  \n 3   0.369 High    0.00424   9.47e-7  0.0302 0.976    0.98         0.49   0.319 \n 4   0.366 Low     0.00362   1.38e-6  0.591  0.555    0.58         0.29   0.487 \n 5  -2.65  Low     0.00292   1.01e-6 -2.68   0.00742  0.02         0.01   0.870 \n 6  -3.17  Low     0.00351   1.18e-6 -3.03   0.00242  0.02         0.01  -0.0143\n 7  -1.25  Low     0.00342   1.60e-6 -0.983  0.325    0.32         0.16   0.650 \n 8  -0.277 Low     0.00386   8.08e-7 -0.244  0.807    0.88         0.44   0.434 \n 9   1.53  High    0.00438   1.42e-6  1.21   0.228    0.32         0.16   0.501 \n10  -1.47  Low     0.00398   1.30e-6 -1.57   0.117    0.1          0.05   0.396 \n# ℹ 247 more rows\n# ℹ 14 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, VILLCODE &lt;chr&gt;,\n#   COUNTYNAME &lt;chr&gt;, TOWNNAME &lt;chr&gt;, VILLNAME &lt;chr&gt;, VILLENG &lt;chr&gt;,\n#   COUNTYID &lt;chr&gt;, COUNTYCODE &lt;chr&gt;, TOWNID &lt;chr&gt;, TOWNCODE &lt;chr&gt;,\n#   incidents &lt;int&gt;, geometry &lt;POLYGON [°]&gt;\n\n\nLet’s visualise it!\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\nLet’s also add the first map that showed the distribution of the dengue incidents to understand the HCSA map better:\n\nDark Red villages :\nThese are likely the coldspots, areas where the local ∗Gi∗​ values are significantly lower than the mean, indicating a clustering of low values.\nThis makes sense when we see the purple distribution map that shows how the outer areas have the lowest number of dengue cases, and they are all near each other.\nDark green and Green Villages (2-6) :\nThese are the villages around the middle of the city that are hotspots, where the local Gi* values are significantly higher than the mean, meanning that there is a clustering of high values which is corroborated by the purple graph too. In the area around the middle of the city, multiple villages close together have high number of dengue cases.\n\nHere we have done Hot spot cold spot analysis and calculated Gi* values without taking time into consideration. We do not consider how many dengue incidents happened per week per village, but considered just the number of incidents per village in totaily."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-gi",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-gi",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Computing Gi*",
    "text": "Computing Gi*\nNext, we will compute the local Gi* statistics, but this time taking the number of incidents, per village ,per week - its a temporal analysis as well.\n\nDeriving the spatial weights\nThe code chunk below will be used to identify neighbors and to derive an inverse distance weights.\n\ndengue_st_nb &lt;- dengue_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\nNote that this dataset now has neighbors and weights for each time-slice.\n\nhead(dengue_st_nb)\n\n# A tibble: 6 × 5\n  VILLCODE     week incidents nb        wt       \n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;   \n1 67000350032    31         0 &lt;int [4]&gt; &lt;dbl [4]&gt;\n2 67000270011    31         1 &lt;int [6]&gt; &lt;dbl [6]&gt;\n3 67000370005    31         0 &lt;int [9]&gt; &lt;dbl [9]&gt;\n4 67000330004    31         0 &lt;int [7]&gt; &lt;dbl [7]&gt;\n5 67000350028    31         0 &lt;int [5]&gt; &lt;dbl [5]&gt;\n6 67000350030    31         0 &lt;int [8]&gt; &lt;dbl [8]&gt;\n\n\nThis lists the neighbours of each village, and the spatial weight of each village."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-gi-1",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-gi-1",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Computing Gi*",
    "text": "Computing Gi*\nWe can use these new columns to manually calculate the local Gi* for each village. We can do this by grouping by week and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\ngi_stars &lt;- dengue_st_nb %&gt;% \n  group_by(week) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    incidents, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)\n\n\n# Inspect the structure of 'nb' to ensure it's a valid neighbors list\nstr(dengue_st_nb$nb)\n\nList of 5160\n $ : int [1:4] 1 6 118 160\n $ : int [1:6] 2 126 128 138 168 222\n $ : int [1:9] 3 68 69 172 181 184 185 188 200\n $ : int [1:7] 4 94 97 100 104 182 207\n $ : int [1:5] 5 12 13 249 255\n $ : int [1:8] 1 6 12 13 118 160 165 249\n $ : int [1:5] 7 54 98 99 201\n $ : int [1:11] 8 9 73 75 115 125 144 156 157 166 ...\n $ : int [1:6] 8 9 110 115 125 166\n $ : int [1:7] 10 11 159 161 166 236 258\n $ : int [1:6] 10 11 159 161 167 242\n $ : int [1:5] 5 6 12 13 249\n $ : int [1:7] 5 6 12 13 14 118 255\n $ : int [1:4] 13 14 118 255\n $ : int [1:5] 15 16 18 139 226\n $ : int [1:5] 15 16 17 139 226\n $ : int [1:6] 16 17 22 139 226 240\n $ : int [1:5] 15 18 139 209 210\n $ : int [1:7] 19 23 24 149 151 241 246\n $ : int [1:4] 20 21 23 241\n $ : int [1:9] 20 21 23 140 145 197 198 208 241\n $ : int [1:9] 17 22 24 139 141 148 150 151 240\n $ : int [1:8] 19 20 21 23 24 140 145 241\n $ : int [1:10] 19 22 23 24 141 142 145 151 164 248\n $ : int [1:5] 25 26 169 211 248\n $ : int [1:6] 25 26 163 211 213 248\n $ : int [1:6] 27 28 128 131 136 152\n $ : int [1:6] 27 28 29 36 136 152\n $ : int [1:6] 28 29 30 32 36 152\n $ : int [1:9] 29 30 31 32 34 39 92 152 153\n $ : int [1:7] 30 31 33 39 92 95 98\n $ : int [1:7] 29 30 32 34 36 39 41\n $ : int [1:5] 31 33 37 39 98\n $ : int [1:8] 30 32 34 36 39 41 42 47\n $ : int [1:6] 35 36 38 44 131 137\n $ : int [1:11] 28 29 32 34 35 36 41 44 50 136 ...\n $ : int [1:6] 33 37 39 51 54 98\n $ : int [1:5] 35 38 43 44 131\n $ : int [1:11] 30 31 32 33 34 37 39 42 47 51 ...\n $ : int [1:5] 40 43 45 131 135\n $ : int [1:9] 32 34 36 41 42 44 46 47 50\n $ : int [1:6] 34 39 41 42 47 51\n $ : int [1:6] 38 40 43 44 45 131\n $ : int [1:9] 35 36 38 41 43 44 45 50 52\n $ : int [1:9] 40 43 44 45 48 52 135 225 226\n $ : int [1:6] 41 46 47 49 50 56\n $ : int [1:12] 34 39 41 42 46 47 49 50 51 53 ...\n $ : int [1:5] 45 48 52 57 226\n $ : int [1:8] 46 47 49 53 55 56 58 60\n $ : int [1:10] 36 41 44 46 47 50 52 56 63 64\n $ : int [1:7] 37 39 42 47 51 54 59\n $ : int [1:8] 44 45 48 50 52 57 63 64\n $ : int [1:5] 47 49 53 55 60\n $ : int [1:9] 7 37 39 51 54 59 98 201 218\n $ : int [1:5] 49 53 55 58 60\n $ : int [1:7] 46 49 50 56 58 61 63\n $ : int [1:5] 48 52 57 64 226\n $ : int [1:7] 49 55 56 58 60 61 67\n $ : int [1:8] 47 51 54 59 60 62 188 218\n $ : int [1:10] 47 49 53 55 58 59 60 62 67 68\n $ : int [1:5] 56 58 61 63 67\n $ : int [1:6] 59 60 62 67 68 188\n $ : int [1:9] 50 52 56 61 63 64 65 66 67\n $ : int [1:11] 50 52 57 63 64 65 146 226 239 240 ...\n $ : int [1:6] 63 64 65 66 192 239\n $ : int [1:5] 63 65 66 67 192\n $ : int [1:10] 58 60 61 62 63 66 67 68 192 214\n $ : int [1:9] 3 60 62 67 68 69 70 188 214\n $ : int [1:7] 3 68 69 70 172 176 177\n $ : int [1:7] 68 69 70 175 177 214 215\n $ : int [1:5] 71 72 73 154 156\n $ : int [1:9] 71 72 73 75 154 189 196 203 221\n $ : int [1:6] 8 71 72 73 75 156\n $ : int [1:8] 74 76 140 173 174 178 179 190\n $ : int [1:8] 8 72 73 75 113 125 203 217\n $ : int [1:6] 74 76 109 111 140 173\n $ : int [1:3] 77 78 79\n $ : int [1:6] 77 78 79 80 132 223\n $ : int [1:4] 77 78 79 80\n $ : int [1:5] 78 79 80 132 133\n $ : int [1:4] 81 82 83 133\n $ : int [1:8] 81 82 83 84 86 128 133 153\n $ : int [1:5] 81 82 83 84 91\n $ : int [1:7] 82 83 84 85 86 87 91\n $ : int [1:8] 84 85 86 87 89 91 102 171\n $ : int [1:8] 82 84 85 86 87 88 100 153\n $ : int [1:7] 84 85 86 87 88 90 171\n $ : int [1:6] 86 87 88 90 94 100\n $ : int [1:6] 85 89 91 93 102 171\n $ : int [1:5] 87 88 90 94 171\n $ : int [1:8] 83 84 85 89 91 102 120 143\n $ : int [1:5] 30 31 92 95 153\n $ : int [1:5] 89 93 96 102 171\n $ : int [1:7] 4 88 90 94 97 100 171\n $ : int [1:7] 31 92 95 98 99 100 153\n $ : int [1:8] 93 96 97 101 102 103 104 171\n $ : int [1:6] 4 94 96 97 104 171\n $ : int [1:8] 7 31 33 37 54 95 98 99\n $ : int [1:7] 7 95 98 99 100 201 207\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"list\" \"nb\""
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-emerging-hotspot-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#performing-emerging-hotspot-analysis",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Performing Emerging Hotspot Analysis",
    "text": "Performing Emerging Hotspot Analysis\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x , and the quoted name of the variable of interest for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\n#ehsa &lt;- emerging_hotspot_analysis(\n  #x = dengue_st, \n  #.var = \"incidents\", \n  #k = 1, \n  #nsim = 99\n#)\n\n\n#write_rds(ehsa, \"../../data/rds/ehsa.rds\")\n\n\nehsa &lt;- read_rds(\"../../data/rds/ehsa.rds\")\n\n\nVisualising the distribution of EHSA classes\nIn the code chunk below, ggplot2 functions ised used to reveal the distribution of EHSA classes as a bar chart.\n\nlibrary(ggplot2)\nlibrary(stringr) # for str_wrap function\n\nggplot(data = ehsa, aes(x = classification)) +\n  geom_bar() +\n  theme_light() +\n  theme(axis.text.x = element_text(size = 8, angle = 0, hjust = 0.5, vjust = 0.5)) +\n  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) # Adjust 'width' as needed\n\n\n\n\nHere, there are a high number of oscillating hotspots. These locations alternate being hotspots and coldspots during different time periods. For example a village with the villagecode 67000330004 is like so."
  }
]