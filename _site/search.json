[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS1455-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications.\nThis is the course website of the IS415 mod that I am embarking on this semester. You will find my course materials here. Have fun:)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Hello! In this page, i will be describing how i performed Thematic Mapping and GeoVisualisation with R. I will mainly be trying to create a choropleth map using the tmap package!\nWe also use pivot_wider() of the tidyr package, and mutate() ,group_by() , select() and filter() of the dplyr package, which i will be explaining in detail.\nI hope you can follow along, and be able to create choropleth maps!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#loading-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#loading-packages",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "Loading packages",
    "text": "Loading packages\nThis is a very important step as we have to load the packages before we can use them.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\nWhat is the tmap package?\nThe tmap package provides you with many handy functions to create your own thematic maps like choropleth maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "Importing the data",
    "text": "Importing the data\n\nDownloading the data\nThe links of the data i used are here (download shp format) and here\n\n\nImporting Geospatial Data into R\nAs learnt in the previous page, we use st_read() function of the sf package to read in the data.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWhen we realtiple features (geographical entities), with 15 fields, or attributes (such as temperature, precipitation for example).\nLet us examine it further by just printing mpsz (the variable we have stored the data in, that is of sf data object).\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nWe can also use glimpse() or head().\n\n\nImporting Attribute Data into R\nNow let us import the aspatial or attribute data into R.\n\nWhat is aspatial/attribute data?\nIt is data that’s not related to shape/location or coordinates but provides more context to the data. For example, if the data is about Airbnb, it tells you the number of rooms, the pricing, the number of people living in each Airbnb house.\nLet’s import it:\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nNow, let’s view it:\n\nlist(popdata) \n\n[[1]]\n# A tibble: 984,656 × 7\n   PA         SZ                     AG     Sex     TOD                Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 1- and 2-Ro…     0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 3-Room Flats    10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 4-Room Flats    30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 5-Room and …    50  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HUDC Flats (exc…     0  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Landed Properti…     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Condominiums an…    40  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Others               0  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 1- and 2-Ro…     0  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 3-Room Flats    10  2011\n# ℹ 984,646 more rows\n\n\n\n\n\nData Preparation\nWe need to prepare data to be in the form of a data table (like a normal sql table) before we can prepare a choropleth map.\nTo prepare the data, we use a few methods. i will go through them here before we actually execute them.\nThese are the methods we will go through:\n\npivot_wider() - tidyr package\nmutate() - dplyr package\ngroup_by() - dplyr package\nselect() - dplyr package\nfilter() - dplyr package\n\n\npivot_wider()\nIt helps transform data from long format to wide format.\nLong format: There are more rows and less columns. Here data is normalised and there are many rows for one subject. This can make it hard to compare the different subjects, and is not very good for visualization.\nHere is how a long format table could look like:\n\nHere there are multiple rows if you want to see the amount of sales in a particular month , or for a particular product. It is not very conducive for comparisons.\nWide format: There are less rows and more columns.\n\nHere there are lesser rows (usually there are more rows but in this case it worked out to still being 3 columns). And it is clearer as to how much sales there is per product per month.\nHow it’s used:\nwide_data &lt;- long_data %&gt;% pivot_wider(names_from = Product, values_from = Sales)\nnames_from: is the argument where you specify the column that will be used to create columns in the wide format\nvalues_from: specifies the column containing the values that will be used to file the new wide format columns\n\n\nmutate()\nmutate() is used to execute operations on existing columns and transform them, create new columns, or transform/create data using conditional statements.\n\nHere we see that we create a new column called Grade and if the score is greater than 90, we populate it with A , if not B. We then process existing data by increasing age by 1.\n\n\nfilter()\nThis method is used to filter rows based on a condition. Here is how it is used:\n\nHere we filter the rows and include rows in the data frame ONLY if the score was equal to or greater than 90.\n\n\nselect()\nThis is like the select query in sql, and you use this to select columns you are interested in.\n\n\n\ngroup_by()\nHere you group the data into groups due to a column, like gender for instance. You can then do group wide operations.\n\n\n\nData Wrangling\nNow this is the code we are supposed to run to prepare the data. Before we prepare the data let’s take a step back.\nOur purpose here is to build a choropleth map that shows you the distribution of the dependency variable across the country/ per region. The dependency variable is calculated like so: DEPENDENCY = (YOUNG + AGED) /`ECONOMY ACTIVE. Thus, we need to know the number of people who are young, aged and economy active in each region. Hence, we have to make sure we make rows that tell us these values per region - that requires group by the two values PA and SZ. We can also group_by AG first so we can see the number of people per age group in each location.\nI have added the explanation for each line of code above that code.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  # we then just want to display columns that are these\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\nCode walkthrough\n\nfilter(Time == 2020) %&gt;%\n\nHere, we are only selecting the rows that have the value 2020 under the time category.\nHere’s a sample data set to help you understand.\n\n\ngroup_by(PA, SZ, AG) %&gt;%\n\nIn group by, we make different groups, each with a unique combination of PA, SZ, and AG. Any row in the dataset that matches that group’s combination of PA, SZ, and AG will be in that group. Hence, each group will have different number of rows. All of the columns of the row will still be there when just executing a group_by(). When grouping, we can do group wide operations, instead of data wide.\n\nsummarise(POP = sum(Pop)) %&gt;%\n\nWe now have the data in groups, with each group having different number of rows.\nWe then add up all the population figures of all the rows in each group and store them in a new column called pop. Now, since the population values in all rows in each group are added together, we have one row per group. Each group has its own combination of pa, sz and ag and its aggragated total summary for population. All the other columns like sex and tod are discarded. You chose to add the population values of all rows together, and did not mention what to do with the other rows, hence they are discarded!\nIn the picture below, you can see that the number of rows have decreased as there were some groups with more than 1 row, and when the population values were added, they were summarised into a row.\nWe now know the number of people per age group per region. This is vital because we have different categories such as young, aged and economy active that we need to compute. Each young, aged and economy active category would consitute of different age categories. Having various different age categories allows us to pick and choose the varying age categories we want to compute to find out the population for each of the young, aged and economy active categories for each region.\n\n\npivot_wider(names_from=AG, values_from=POP) %&gt;%\n\nTo make it easier to compute the population values for each young, aged and economy active category per region, we should make the age categories column names. Then, we can make the population the values under each age category. As illustrated below, we can easily see the number of people per age category per region.\n\n\nmutate(YOUNG = rowSums(.[3:6]) +rowSums(.[12])) %&gt;%\n\nAs we said before, there are different age categories , like 0-4 being one column 5-9 being another column. Hence, we add up populations under columns 3 to 6 in each row as that is the age range that we think is young. After calculating that for each row, we create a column called young and populate it.\n\n\nmutate(ECONOMY ACTIVE = rowSums(.[7:11])+ rowSums(.[13:15]))%&gt;%\n\nnext we want to find out what is the total number of pople in each subzone that are economically active. so we want to add up the values under age range categories that we think are eco active in each row and then make a eco active column and populate it underneath that\n\nmutate(AGED=rowSums(.[16:21])) %&gt;%\n\nDo the same thing for total number of people for each subzone\n\nmutate(TOTAL=rowSums(.[3:21])) %&gt;%\n\nDo the same thing for total number of people for each subzone\n\nmutate(DEPENDENCY = (YOUNG + AGED) /ECONOMY ACTIVE) %&gt;%\n\nwe then calculate the dependency\n\nselect(PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY)\n\nwe then just select the columns we want\n\n\n\n\n\nJoining attribute and geographical data\nThe values in PA and SZ are made up of lower and upper case so lets make them all uppercase\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNow let’s join them based on one common column that is SZ - it is present in both the geospatial and attribute data.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nLet’s write it into a file. Remember to create the directory and file data/rds/mpszpop2020.rds before executing this.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-On Exercise 2 : Thematic Mapping and GeoVisualisation with R",
    "section": "Choropleth Mapping Geospatial Data using tmap",
    "text": "Choropleth Mapping Geospatial Data using tmap\nYou can do this two ways\n\nPlotting a thematic map quickly by using qtm()\nPlotting highly customisable thematic map by using tmap elements\n\n\nUsing qtm()\nWhen we say fill = “DEPENDENCY”, we mean that the colors of the choropleth map would vary based on the values of dependency.\nThis method is quick but reduces the scope for customization.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\nUsing tmap()\nWe can start of with learning about using tm_shape() and tm_fill().\nWe are showing a geographical distribution of dependency.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nIf we wanted to customise more, and use tm_borders,\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nIf we wanted ultimate customisation, these are the functions and arguments available.\nstyle= quantile shows that we use quantile to classify the data and come up with categories/classes. This means there are four categories with the number of data points each category being equal.\nThe palette=blues is the theme of the map.\nThe layout method often focuses on the aesthetics of the map and is quite self explanatory.\ntm_compass() adds a compass to the map.\ntm_scale_bar() adds the scale to show the relationship between the real measurements to the measurements on the screen.\ntm_grid() adds grid lines to show longitutde and latitude.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nHere we have used tmap and used tm_shape() + tm_fill(). tm_fill() automatically draws out polygons in your map and fills them with the color necessiated by its relevant value.\nLet’s say you wanted to draw other shapes in your map other than polygons. You could do that with tm_lines() or tm_raster()\nBut let’s say we wanted to say outright that we wanted to draw out polygons. We can use tm_polygons()\n\n\nUsing tm_polygons()\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\nRemember: we have to do tm_shape first to load our data in.\nIf we wanted to also say what variable we wanted to show a geographical distribution of :\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\nDrawing a choropleth map using tm_fill() and *tm_border()*\nWritten right underneath the tmap section for better flow.\n\n\nData classification methods of tmap\nThere are different ways to classify data into categories.\n\nPlotting choropleth maps with built-in classification methods\nHere we are using jenks, which means it looks for natural clusters in the data and then groups them together. And we are looking to divide the data into 5 natural clusters.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can also use equal, where the interval in data values is equal. But this will not be good when the data is skewed in one direction as there might not be any data points in many of the intervals.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nDIY (1)\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\nLet’s try sd:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s try quantile:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nI can see that quantile shows more of a geographic distribution. sd shows a lesser range- perhaps the sd was too huge. Hence, there were large number of data points per category and consequently, the number of categories was also less - showing less of a range.\n\n\nDIY (2)\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\nLet’s try quantile.\nLet’s start with 6 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s start with 6 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 7,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can see the map when the classes are 5,6 and 7. As it increases from 5 to 6, we get a greater nuance in the geographic distribution of the dependency column. However, when we go from 6 to 7, there is not much of an increase in nuance. The difference in category boundaries are very minimal. Hence, the ideal number of classes would be 6.\n\n\nPlotting choropleth maps with custom breaks\nIn the methods we used before, the breakpoints were set automatically by them. If we wanted to define the boundaries of each category ourselves, we can do that too. However, to do that, we need more information about the data to understand it. Getting the data’s mean/quantile values, minimum, median, can help with setting those boundaries.\nSo let’s get those values through the use of this method.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nNow let’s choose our breakpoints and plot the choropleth map.\nOur breakpoints are at 0, 0.6. 0.7, 0., 0.9, 1.00.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nColor Scheme\nNow on to the fun part! We get to delve into the color scheme of things\n\nUsing ColourBrewer palette\nLet’s try the blue palette.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s try the green palette.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nMap Layouts\nWhen we talk about map layouts, we want to control how a map looks. We want to ensure that all aspects of a map are present. This includes the title, the scale bar, the compass, legend, margins and aspect ratios. We also can control the style of the map.\n\nMap Style\nThis refers to tmap_style(), not the style argument in your tm_fill where you declare the type of data classification you choose to employ.\nIt controls how your map would look like. These are the arguments you could use:\nThe available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \nIf we were to use classic:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\nIf we used dark,\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"cobalt\")\n\n\n\n\n\n\nMap Legend\nLet’s try adding the legend first.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nLet’s go through what the legend part of the code means.\nlegend.hist= TRUE means that we are going to include a histogram like legend. This will allow the viewer to see the distribution of values in the form of a histogram as well.\nlegend.is.portrait = TRUE means that the legend/histogram will be in portrait orientation.\nlegend.hist.z=0.1 means the legend will be slightly behind the map.\n\n\nCartographic furniture\nThis refers to adding of the compass, scale bar and grid lines that we talked about earlier.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\nDrawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arranged side-by-side or vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\nBy assigning multiple values to at least one of the aesthetic arguments\nHere you want both to have the data classification of equal.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nNow, you want each of them to have different data classifications, and different looks.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nIn these two sets of graphs (4), the two maps in each set are showcasing different variables across Singapore . In the first set, we show the distribution of young and then the distribution of old.\nNow what if we wanted the maps to be linked to each other, as in, show the distribution of the same variable?\n\n\nBy defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nHere, we show the distribution of the same dependency variable across multiple regions.\n\n\nBy creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\nMappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "here we are doing spatial point analysis where we are basically studying and analysing the spread of points in a space.\nIt helps us answer tje following questions:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "IS415-GAA",
    "section": "",
    "text": "here we are doing spatial point analysis where we are basically studying and analysing the spread of points in a space.\nIt helps us answer tje following questions:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#data",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#data",
    "title": "IS415-GAA",
    "section": "Data",
    "text": "Data\n\nchildcare\nMP14_SUBZONE_WEB_PL\nCostalOutline"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#installing-and-loading-the-r-packages",
    "title": "IS415-GAA",
    "section": "Installing and loading the R packages",
    "text": "Installing and loading the R packages\nWe need to install and load the R packages into the R environment to use them\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)\n\nIf you aren’t able to install maptools, do this:\n\ninstall.packages(\"maptools\", repos=\"http://R-Forge.R-project.org\")\n\nWarning: package 'maptools' is in use and will not be installed"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#spatial-data-wrangling",
    "title": "IS415-GAA",
    "section": "Spatial Data Wrangling",
    "text": "Spatial Data Wrangling\n\nImporting the spatial data\nWe will use the st_read() function of sf package to import geospatial datasets into R.\nLet’s import the first one of ChildCareServices:\n\nchildcare_sf &lt;- st_read(\"data/ChildCareServices.geojson\")\n\nReading layer `ChildCareServices' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe can see that the CRS is not what we want let’s transform it to SVY21\n\nchildcare_sf &lt;- st_transform(childcare_sf, crs = 3414)\n\nLet’s print out childcare_sf to see what is the CRS.\n\nst_geometry(childcare_sf)\n\nGeometry set for 1925 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (40985.94 33848.38 0)\n\n\nPOINT Z (28308.65 45530.47 0)\n\n\nPOINT Z (17828.84 36607.36 0)\n\n\nPOINT Z (25579.73 29221.89 0)\n\n\nPOINT Z (38981.02 32483.41 0)\n\n\nLet’s import coastal outline.\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nWhen we look at the coordinate reference system of coastal outline, we see that the user input is SVY21 but the correct EPSG code is 9001 instead of 3414.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSo here we change it to 3414.\nReminder we don’t use st_transform() because the CRS is already SVY21, it’s just the ESPG code that is wrong!\n\nsg_sf &lt;- st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow let’s recheck if the coordiante system and ESPG code match.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNow let’s import MP_14_SUBZONE_WEB_PL.\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hand-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nLet’s check the coordinate system, it has to be SVY21 so that it is projected coordinate system, and the ESPG code has to match the SVY21.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince it’s 9001 and not 3414, let’s change the code.\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nLet’s check.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nMapping the Geospatial data sets\n\ncol_names &lt;- names(childcare_sf)\nprint(col_names)\n\n[1] \"Name\"        \"Description\" \"geometry\"   \n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +\n  tm_shape(childcare_sf) +  \n  tm_dots()"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "title": "IS415-GAA",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\nAlthough simple feature data frame is gaining popularity again sp’s Spatial* classes, there are, however, many geospatial analysis packages require the input geospatial data in sp’s Spatial* classes. In this section, you will learn how to convert simple feature data frame to sp’s Spatial* class.\n\nConverting sf data frames to sp’s Spatial* class\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\n#print(as.data.frame(childcare))\n\n\n#childcare\n\n\n#mpsz\n\n\n#sg\n\n\n\nConverting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. \nSpatial* classes -&gt; Spatial -&gt; ppp\nLet’s do spatial* classes -&gt; spatial first\nRemeber to use the correct type of shape\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nWhat are the differences between Spatial* classes and generic sp object?\nIn summary, you would use Spatial* classes when you have simple spatial data without additional attributes, and you want a straightforward representation of points, lines, or polygons. On the other hand, if your spatial data includes associated attributes and you need to perform in-depth analysis, you would use generic sp objects like SpatialPointsDataFrame or SpatialPolygonsDataFrame.\nFor example, if you only need to plot the locations of childcare centers on a map, you can use the SpatialPoints class. However, if you want to perform statistical analysis on the childcare data, including attributes such as capacity or age group, you would convert it into a SpatialPointsDataFrame, which allows you to work with both spatial and attribute data seamlessly.\n\n\nConverting the generic sp format into spatstat’s ppp format\nsp -&gt; ppp. And now you can put it into spatstat.\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1925 points\nwindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\nwhat’s the difference between plotting a geojson with spatial points and plotting the same data thats converted to ppp format\nPlotting a GeoJSON file with spatial points typically results in a standard spatial point map. Each point is displayed as a symbol or marker on the map, and you can customize the appearance of the points, such as color, size, and shape.\nConverting data to ppp format is typically done when you intend to perform spatial point process analysis. In this context, a point pattern represents the locations of events or objects of interest (e.g., tree locations, disease cases). ppp objects are used in the spatstat package for advanced spatial point pattern analysis. This includes tasks like assessing spatial clustering, estimating intensity, performing K-functions analysis, and simulating point patterns under different models.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\nHandling duplicated points\nDuplicates, in this context, are multiple points that occupy exactly the same location in space.\nCoincident points are points that are so close to each other that they are considered to occupy the same location within a certain tolerance threshold.\nThese duplicates or coincident points can occur for various reasons, such as measurement errors, data collection methods, or the nature of the phenomenon being studied.\nLet’s check if there are any duplicates in the data:\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nThe multiplicity() function is a function or method typically provided by spatial point pattern analysis software or packages like spatstat. Its purpose is to calculate the multiplicity of points in a point pattern. Multiplicity refers to the number of points that occupy the same location (coincident points) at each location where such coincidences occur.\n\n# Count the number of coincident\n#points in the childcare_ppp point pattern\nmultiplicity(childcare_ppp)\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\nThere are three different approaches to address the issue of duplicate points in spatial point pattern analysis:\n\nDeleting Duplicates: This is the simplest approach, where you remove the duplicate points from your dataset. However, this method comes with a drawback, as it may result in the loss of valuable point events. If each point represents a meaningful observation, deleting duplicates can lead to the omission of important data.\nJittering: The second solution involves adding a small random perturbation to the duplicate points. This perturbation is often referred to as “jitter,” and it introduces a slight variation in the spatial locations of duplicate points, ensuring that they do not occupy the exact same space. Jittering is a way to retain all points while avoiding the issue of perfect overlap.\nAttaching Duplicates as Marks: The third solution is to treat each point as “unique” and then attach the duplicates of the points as marks or attributes of the points. In this approach, duplicate points are not removed or perturbed; instead, they are associated with additional information or attributes. This allows you to preserve all observations while acknowledging their duplications. Analytical techniques that consider these marks can be applied to study the spatial pattern or relationships among points.\n\n\nJittering\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nLet’s check if there are any duplicate points\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nCreating owin object\nThe owin object is essentially a spatial window that limits the analysis to a specific polygonal region. It provides a framework for handling point patterns within this spatial window. This is particularly important when you want to account for the geographic boundaries of the study area in your analysis.\n\n# this is from generic spatia lclass to owin\nsg_owin &lt;- as(sg_sp, \"owin\")\n\n\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\n\nCombining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "",
    "text": "Hello! In this page, i will be describing how i performed data wrangling - which is basically cleaning and transforming raw data into a more structured and usable format or later analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Installing and loading R packages",
    "text": "Installing and loading R packages\nIn this section, I will install and load ‘tidyverse’ and ‘sf’ packages.\n\nWhat are the sf and tidyverse packages?\nLet me give you a break down.\n\nTidyverse Package\nImagine you have a pile of dirty data that you need to handle. The Tidyverse package helps you handle your data. It actually has a bunch of packages within it to help handle data. It can do the following:\n\nreadr - reading and writing data into or out of a spreadsheet\ntidyr - organizing and tidying up your data\nggplot2 - visualizing your data\ndpylr - mainpulating your data, like doing some basic math to it.\n\n\n\nSF Package\nSF package provides us with tools to work with data related to maps and geospatial data. It can\n\nRead and write geospatial data from and into files.\nManipulate data - like cut out a specific area on a map\nVisualize data\n\nNow let’s load the packages into our environment.\n\n# Loads the p_load function on pacman which checks if packages are available, and then loads them into the R environment.\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\n\nImporting the geospatial data in shapefile format\nHere we import the geospatial data which is in shapefile format as a a polygon feature data frame.\n\nWhat is a shapefile and what is a polygon feature data frame?\n\nShapefile\nShapefile format stores geographic location and attribute information of geographic features.\n\n\nPolygon feature data frame\nThink of polygons as shapes that represent areas on a map.\nData frames store details about the polygons (think area) on tables.\nSo polygon feature data frames store data about areas on the map.\n\n#st_read is a function from the SF package which helps with the handling of data. We read the data into the variable mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n layer  = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\nImporting polyline feature data in shapefile form\n\nWhat is a polyline feature data frame?\nA polyline is made up of connected points and can represent things such as roads, rivers, or hiking trails.\nFeature Data Frames store information about these lines, like what is the name of the road, how long is it, what’s its surface?\nA polyline feature data frame stores information on lines that represent routes or rivers on a map.\nNow let’s import the polyline feature data\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\nImporting GIS data in kml format\n\nWhat is a GIS data and kml format ?\n\nkml format\nIt is keyhole markup language used to describe places and features on a digital map. You can define shapes like drawing a line to show a hiking trail or a polygon to show a lake. You can also attach information to places.\n\n\nGIS data\nA map has information like shapes, paths, data and locations. GIS data is when all this information is organized in a computer friendly way. People use these data to analyse the environment, plan cities and much more.\nNow let’s import GIS data in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Checking out the contents of a simple feature data frame",
    "text": "Checking out the contents of a simple feature data frame\n\nst_geometry\nShapes represent areas on a map. The data.frame in the package sf contains a column, and that column contains a list of those shapes in the specific class called ‘sfc’.\nLet’s execute this command\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThis commands tells you a few things:\n\nThe types of shapes you’re dealing with. Multipolygon means its an area with multiple connected lines.\nThe bounding box/ range of coordinates that coer the same\nAlso the first 5 shapes in the column of the data frame\n\n\n\nglimpse\nLet’s execute this command\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThis command gives you a glimpse into the dataset.\nit tells you the following things:\n\nthe number of rows\nthe number of columns\nwhat columns are there\ndata type of each column\nfirst few values of each column\n\n\n\nhead()\nLet’s execute this command\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThis provides you with complete information (columns and the number of values u want)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Plotting Data",
    "text": "Plotting Data\nNow, let’s plot the data in our mpsz as a visualization. We use the plot() function for it.\nThis provides the entire visualization.\n\nplot(mpsz)\n\n\n\n\nIf you want to just plot the different shapes in the map, we can do this:\n\nplot(st_geometry(mpsz))\n\n\n\n\nIf you want to plot just based off of one column/attribute, you can do this. Each color reprsents the a row.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Working with projection",
    "text": "Working with projection\nThere are multiple ways you can study geography. You can study it if it were on a flat piece of paper or curved 3d way on your laptop screen.\nWhen there are two different ways of expressing geography, the way the data is, is differnet. If you want to use two sets of geospatial data, you want to ensure the data has the same projection, i.e. represents locations on the earth’s surface the same way. Hence, you will have to translate one of the maps to the same projection of another.\n\nWorking with projection\nOne of the common issues that can happen is that the coordinate system of a geospatial data is mising or incorrect. To check and input the correct coordinate system, we execute the following command to check the coordinate reference system.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nthen check at the end of the print if the ESPG code corresponds correctly to the coordinate system. Here, svy21 should correspond to 3414 not 9001. So we change it!\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow let’s double check if the ESPG code is correct\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nWorking with projection\nSometimes we change projection of a geospatial data to one that is congrunet with the type of analysis we are making.\nFor example, geographic coordinate system may not be appropriate if the analysis needs to use distance or/and area measurements.\nlet’s do some transformation here.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\n##Importing and Converting An Aspatial Data\n\n\nWhat is aspatial data?\nLet’s back track. Spatial data refers to physical location, shapes and positions of the objects on the earth’s surface.\nAspatial data refers to characteristics or properties of those objects. Airbnb is asptial data, so it focuses on what kind of house is it, how many bed rooms how many bathrooms, maybe its rental per night.\n\n\nImport spatial data\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nLet’s explore the data.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n###Creating a simple feature data frame from an aspatial data frame\nLet’s do some conversion : transform one coordinate system to another.\nFirst code line, we convert the aspatial data from to a simple feature data frame. Then we change the coordinate system.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\nHere, we will be learning about buffering and point in polygon.\n###Buffering\n####What is bufferring\nLet’s say there is a point of interest like a cycling path You want to analyse a certain amount of area around it, and the amount would be the buffer. Let’s say buffer is 5, you would want to study the area in a 5 mile radius around it.\nLet’s have another working scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nLet’s create a data frame with a buffer zone around the cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nYou created the buffer in the previous command , now you can calculate the total area of the buffer by doing so.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nNow the summation of the buffer land and the exisiting cycling path- total land involved.\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n###Point-in-polygon count\n####What is Point-in-polygon count\nIt refers to counting the number of points in an area (polygon)\nLet’s say, a pre-school service group wants to find out the numbers of pre-schools in each Planning Subzone.\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nZone with most preschools\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nCalculate density of presch\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n##Exploratory Data Analysis (EDA)\nLet’s visualize our data to get a better idea of it.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\n\n\n\nHello! In this page, i will be describing how i performed data wrangling - which is basically cleaning and transforming raw data into a more structured and usable format or later analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#installing-and-loading-r-packages-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Installing and loading R packages",
    "text": "Installing and loading R packages\nIn this section, I will install and load ‘tidyverse’ and ‘sf’ packages.\n\nWhat are the sf and tidyverse packages?\nLet me give you a break down.\n\nTidyverse Package\nImagine you have a pile of dirty data that you need to handle. The Tidyverse package helps you handle your data. It actually has a bunch of packages within it to help handle data. It can do the following:\n\nreadr - reading and writing data into or out of a spreadsheet\ntidyr - organizing and tidying up your data\nggplot2 - visualizing your data\ndpylr - mainpulating your data, like doing some basic math to it.\n\n\n\nSF Package\nSF package provides us with tools to work with data related to maps and geospatial data. It can\n\nRead and write geospatial data from and into files.\nManipulate data - like cut out a specific area on a map\nVisualize data\n\nNow let’s load the packages into our environment.\n\n# Loads the p_load function on pacman which checks if packages are available, and then loads them into the R environment.\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#importing-geospatial-data-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\n\nImporting the geospatial data in shapefile format\nHere we import the geospatial data which is in shapefile format as a a polygon feature data frame.\n\nWhat is a shapefile and what is a polygon feature data frame?\n\nShapefile\nShapefile format stores geographic location and attribute information of geographic features.\n\n\nPolygon feature data frame\nThink of polygons as shapes that represent areas on a map.\nData frames store details about the polygons (think area) on tables.\nSo polygon feature data frames store data about areas on the map.\n\n#st_read is a function from the SF package which helps with the handling of data. We read the data into the variable mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n layer  = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\nImporting polyline feature data in shapefile form\n\nWhat is a polyline feature data frame?\nA polyline is made up of connected points and can represent things such as roads, rivers, or hiking trails.\nFeature Data Frames store information about these lines, like what is the name of the road, how long is it, what’s its surface?\nA polyline feature data frame stores information on lines that represent routes or rivers on a map.\nNow let’s import the polyline feature data\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\nImporting GIS data in kml format\n\nWhat is a GIS data and kml format ?\n\nkml format\nIt is keyhole markup language used to describe places and features on a digital map. You can define shapes like drawing a line to show a hiking trail or a polygon to show a lake. You can also attach information to places.\n\n\nGIS data\nA map has information like shapes, paths, data and locations. GIS data is when all this information is organized in a computer friendly way. People use these data to analyse the environment, plan cities and much more.\nNow let’s import GIS data in kml format.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\shaysnutss\\IS1455-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#checking-out-the-contents-of-a-simple-feature-data-frame-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Checking out the contents of a simple feature data frame",
    "text": "Checking out the contents of a simple feature data frame\n\nst_geometry\nShapes represent areas on a map. The data.frame in the package sf contains a column, and that column contains a list of those shapes in the specific class called ‘sfc’.\nLet’s execute this command\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThis commands tells you a few things:\n\nThe types of shapes you’re dealing with. Multipolygon means its an area with multiple connected lines.\nThe bounding box/ range of coordinates that coer the same\nAlso the first 5 shapes in the column of the data frame\n\n\n\nglimpse\nLet’s execute this command\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThis command gives you a glimpse into the dataset.\nit tells you the following things:\n\nthe number of rows\nthe number of columns\nwhat columns are there\ndata type of each column\nfirst few values of each column\n\n\n\nhead()\nLet’s execute this command\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThis provides you with complete information (columns and the number of values u want)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#plotting-data-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Plotting Data",
    "text": "Plotting Data\nNow, let’s plot the data in our mpsz as a visualization. We use the plot() function for it.\nThis provides the entire visualization.\n\nplot(mpsz)\n\n\n\n\nIf you want to just plot the different shapes in the map, we can do this:\n\nplot(st_geometry(mpsz))\n\n\n\n\nIf you want to plot just based off of one column/attribute, you can do this. Each color reprsents the a row.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection-3",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#working-with-projection-3",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Working with projection",
    "text": "Working with projection\nThere are multiple ways you can study geography. You can study it if it were on a flat piece of paper or curved 3d way on your laptop screen.\nWhen there are two different ways of expressing geography, the way the data is, is differnet. If you want to use two sets of geospatial data, you want to ensure the data has the same projection, i.e. represents locations on the earth’s surface the same way. Hence, you will have to translate one of the maps to the same projection of another.\n\nWorking with projection\nOne of the common issues that can happen is that the coordinate system of a geospatial data is mising or incorrect. To check and input the correct coordinate system, we execute the following command to check the coordinate reference system.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nthen check at the end of the print if the ESPG code corresponds correctly to the coordinate system. Here, svy21 should correspond to 3414 not 9001. So we change it!\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow let’s double check if the ESPG code is correct\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nWorking with projection\nSometimes we change projection of a geospatial data to one that is congrunet with the type of analysis we are making.\nFor example, geographic coordinate system may not be appropriate if the analysis needs to use distance or/and area measurements.\nlet’s do some transformation here.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\n##Importing and Converting An Aspatial Data\n\n\nWhat is aspatial data?\nLet’s back track. Spatial data refers to physical location, shapes and positions of the objects on the earth’s surface.\nAspatial data refers to characteristics or properties of those objects. Airbnb is asptial data, so it focuses on what kind of house is it, how many bed rooms how many bathrooms, maybe its rental per night.\n\n\nImport spatial data\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nLet’s explore the data.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n###Creating a simple feature data frame from an aspatial data frame\nLet’s do some conversion : transform one coordinate system to another.\nFirst code line, we convert the aspatial data from to a simple feature data frame. Then we change the coordinate system.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-On_Ex01.html#geoprocessing-with-sf-package-1",
    "title": "Hands-On Exercise 1 : Geospatial Wrangling With R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\nHere, we will be learning about buffering and point in polygon.\n###Buffering\n####What is bufferring\nLet’s say there is a point of interest like a cycling path You want to analyse a certain amount of area around it, and the amount would be the buffer. Let’s say buffer is 5, you would want to study the area in a 5 mile radius around it.\nLet’s have another working scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nLet’s create a data frame with a buffer zone around the cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nYou created the buffer in the previous command , now you can calculate the total area of the buffer by doing so.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nNow the summation of the buffer land and the exisiting cycling path- total land involved.\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n###Point-in-polygon count\n####What is Point-in-polygon count\nIt refers to counting the number of points in an area (polygon)\nLet’s say, a pre-school service group wants to find out the numbers of pre-schools in each Planning Subzone.\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nZone with most preschools\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nCalculate density of presch\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n##Exploratory Data Analysis (EDA)\nLet’s visualize our data to get a better idea of it.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class-Ex02/In-class_Ex02.html",
    "title": "In-class exercise 2 : R for geospatial data science",
    "section": "",
    "text": "Hey friends! Let’s learn about a few package:"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#loading-packages",
    "href": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#loading-packages",
    "title": "In-class exercise 2 : R for geospatial data science",
    "section": "Loading packages",
    "text": "Loading packages\nThis is a very important step as we have to load the packages before we can use them.\n\npacman::p_load(sf, tmap, tidyverse,lubridate,arrow)"
  },
  {
    "objectID": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#importing-the-data",
    "href": "In-class_Ex/In-class-Ex02/In-class_Ex02.html#importing-the-data",
    "title": "In-class exercise 2 : R for geospatial data science",
    "section": "Importing the data",
    "text": "Importing the data\n\nImporting Geospatial Data into R\nAs learnt in the previous page, we use st_read() function of the sf package to read in the data.\n\ndf &lt;- read_parquet(\"../../data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n\n\n\nConversion of data type\nHere we convert the int data type to date time data type. We are not using mutate, as we are over writing the data field in the file.\n\ndf$pingtimestamp &lt;-as_datetime(df$pingtimestamp)\n\n\n# get origin\norigin_df &lt;- df %&gt;% #use df\n  group_by(trj_id) %&gt;% #group according to trj_id\n  arrange(pingtimestamp) %&gt;% #sort according to timestamp asc (default)\n  filter(row_number()==1) %&gt;% #the first coordinate for every trip should be the origin\n  mutate(weekday = wday(pingtimestamp, label=TRUE, abbr=TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\neach trip will have multiple rows because every minute the new location one be sent to the server . so when we arrange it, the first row is the origin location.\n\n# get end\ndestination_df &lt;- df %&gt;% #use df\n  group_by(trj_id) %&gt;% #group according to trj_id\n  arrange(desc(pingtimestamp)) %&gt;% #sort according to timestamp asc (default)\n  filter(row_number()==1) %&gt;% #the first coordinate for every trip should be the origin\n  mutate(weekday = wday(pingtimestamp, label=TRUE, abbr=TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n# he writes in rds if he still wants to write in r\nwrite_rds(origin_df, \"../../data/rds/origin_df.rds\")\nwrite_rds(destination_df,\n          \"../../data/rds/destination_df.rds\")\n\n#import data\n\norigin_df &lt;- read_rds(\"../../data/rds/origin_df.rds\")\ndestination_df &lt;- read_rds(\"../../data/rds/destination_df.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hand-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "IS415-GAA",
    "section": "First-order Spatial Point Patterns Analysis",
    "text": "First-order Spatial Point Patterns Analysis\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics\n\n\nKernel Density Estimation"
  }
]